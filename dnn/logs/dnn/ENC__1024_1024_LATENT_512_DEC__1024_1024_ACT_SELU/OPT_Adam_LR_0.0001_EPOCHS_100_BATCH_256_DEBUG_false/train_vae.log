Setting up environment...
Environment set up.
Training deep variational multidecoder...
Constructing model...
Done constructing model.
DNNVariationalMultidecoder (
  (activation): SELU
  (encoder): Sequential (
    (lin_0): Linear (880 -> 1024)
    (bn_0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)
    (SELU_0): SELU
    (lin_1): Linear (1024 -> 1024)
    (bn_1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)
    (SELU_1): SELU
  )
  (latent_mu): Sequential (
    (lin): Linear (1024 -> 512)
    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)
    (SELU): SELU
  )
  (latent_logvar): Sequential (
    (lin): Linear (1024 -> 512)
    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)
    (SELU): SELU
  )
  (decoder_ihm): Sequential (
    (lin_0): Linear (512 -> 1024)
    (SELU_0): SELU
    (lin_1): Linear (1024 -> 1024)
    (SELU_1): SELU
    (lin_final): Linear (1024 -> 880)
  )
  (decoder_sdm1): Sequential (
    (lin_0): Linear (512 -> 1024)
    (SELU_0): SELU
    (lin_1): Linear (1024 -> 1024)
    (SELU_1): SELU
    (lin_final): Linear (1024 -> 880)
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 1.432239
Train epoch 1: [2000/18806 (10.6%)]	Loss: 1.144333
Train epoch 1: [3000/18806 (16.0%)]	Loss: 1.051098
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.969685
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.901001
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.844983
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.800943
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.766271
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.734479
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.709313
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.685716
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.666492
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.642698
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.621719
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.607354
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.598529
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.587869
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.579881
====> Epoch 1: Average train loss 0.574903
====> Dev set loss: 0.384043
New best dev set loss: 0.384043
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.381574
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.353542
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.388832
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.391504
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.388758
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.384204
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.382453
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.383437
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.382264
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.382627
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.381707
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.381896
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.375720
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.370758
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.369604
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.372051
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.371515
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.372332
====> Epoch 2: Average train loss 0.373880
====> Dev set loss: 0.352561
New best dev set loss: 0.352561
Saved checkpoint for model
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.337847
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.314345
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.345858
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.349182
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.346912
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.342893
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.342546
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.344857
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.345050
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.346879
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.346829
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.347697
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.342892
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.339120
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.339092
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.342250
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.341976
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.343343
====> Epoch 3: Average train loss 0.345421
====> Dev set loss: 0.355454
No improvement in 1 epochs (best dev set loss: 0.352561)
Not saving checkpoint; no improvement made
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.326625
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.305030
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.335220
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.336731
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.334621
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.331652
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.331143
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.333846
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.334287
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.336652
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.336837
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.337602
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.333400
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.329907
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.330343
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.333575
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.333286
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.334479
====> Epoch 4: Average train loss 0.336614
====> Dev set loss: 0.361620
No improvement in 2 epochs (best dev set loss: 0.352561)
Not saving checkpoint; no improvement made
Train epoch 5: [1000/18806 (5.3%)]	Loss: 0.319374
Train epoch 5: [2000/18806 (10.6%)]	Loss: 0.299863
Train epoch 5: [3000/18806 (16.0%)]	Loss: 0.329843
Train epoch 5: [4000/18806 (21.3%)]	Loss: 0.331117
Train epoch 5: [5000/18806 (26.6%)]	Loss: 0.329899
Train epoch 5: [6000/18806 (31.9%)]	Loss: 0.327008
Train epoch 5: [7000/18806 (37.2%)]	Loss: 0.326494
Train epoch 5: [8000/18806 (42.5%)]	Loss: 0.329373
Train epoch 5: [9000/18806 (47.9%)]	Loss: 0.330237
Train epoch 5: [10000/18806 (53.2%)]	Loss: 0.332242
Train epoch 5: [11000/18806 (58.5%)]	Loss: 0.332226
Train epoch 5: [12000/18806 (63.8%)]	Loss: 0.333166
Train epoch 5: [13000/18806 (69.1%)]	Loss: 0.329091
Train epoch 5: [14000/18806 (74.4%)]	Loss: 0.325768
Train epoch 5: [15000/18806 (79.8%)]	Loss: 0.325889
Train epoch 5: [16000/18806 (85.1%)]	Loss: 0.329246
Train epoch 5: [17000/18806 (90.4%)]	Loss: 0.329132
Train epoch 5: [18000/18806 (95.7%)]	Loss: 0.330633
====> Epoch 5: Average train loss 0.332792
====> Dev set loss: 0.363659
No improvement in 3 epochs (best dev set loss: 0.352561)
STOPPING EARLY
Trained deep variational multidecoder.
