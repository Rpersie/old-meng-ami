{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../cnn\")\n",
    "sys.path.append(\"../utils\")\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import seaborn as sns; sns.set()\n",
    "\n",
    "from cnn_md import CNNMultidecoder, CNNVariationalMultidecoder\n",
    "from cnn_md import CNNAdversarialMultidecoder, CNNAdversarialVariationalMultidecoder\n",
    "from hao_data import HaoEvalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise ratio 0.25\n",
      "Using experiment ENC_C_256_256_K_3_3_P_3_3_F_2048_2048/LATENT_128/DEC_F_2048_2048_C_256_256_K_3_3_P_3_3/ACT_SELU_BN_false_WEIGHT_INIT_xavier_uniform/OPT_Adam_LR_0.0001_EPOCHS_25_BATCH_256_DEBUG_false\n"
     ]
    }
   ],
   "source": [
    "# Set up environment variables for the model we want to examine\n",
    "# NOT necessarily the current environment variables!!\n",
    "\n",
    "feat_dim=80\n",
    "left_context=5\n",
    "right_context=5\n",
    "\n",
    "optimizer=\"Adam\"\n",
    "learning_rate=\"0.0001\" # Use string instead of float to prevent Python's auto-formatting...\n",
    "epochs=25\n",
    "batch_size=256\n",
    "\n",
    "enc_channels=[256, 256]\n",
    "enc_kernels=[3, 3]\n",
    "enc_pools=[3, 3]\n",
    "enc_fc=[2048, 2048]\n",
    "\n",
    "latent_dim=128\n",
    "\n",
    "dec_fc=[2048, 2048]\n",
    "dec_channels=[256, 256]\n",
    "dec_kernels=[3, 3]\n",
    "dec_pools=[3, 3]\n",
    "\n",
    "decoder_classes=[\"ihm\", \"sdm1\"]\n",
    "\n",
    "use_batch_norm=False\n",
    "use_batch_norm_str = \"true\" if use_batch_norm else \"false\"\n",
    "activation=\"SELU\"\n",
    "weight_init=\"xavier_uniform\"\n",
    "\n",
    "enc_channels_delim=\"_\" + \"_\".join(map(str, enc_channels))\n",
    "if len(enc_channels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_channels_delim=\"_\"\n",
    "enc_kernels_delim=\"_\" + \"_\".join(map(str, enc_kernels))\n",
    "if len(enc_kernels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_kernels_delim=\"_\"\n",
    "enc_pools_delim=\"_\" + \"_\".join(map(str, enc_pools))\n",
    "if len(enc_pools) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_pools_delim=\"_\"\n",
    "enc_fc_delim=\"_\" + \"_\".join(map(str, enc_fc))\n",
    "if len(enc_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    enc_fc_delim=\"_\"\n",
    "    \n",
    "dec_fc_delim=\"_\" + \"_\".join(map(str, dec_fc))\n",
    "if len(dec_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_fc_delim=\"_\"\n",
    "dec_channels_delim=\"_\" + \"_\".join(map(str, dec_channels))\n",
    "if len(dec_channels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_channels_delim=\"_\"\n",
    "dec_kernels_delim=\"_\" + \"_\".join(map(str, dec_kernels))\n",
    "if len(dec_kernels) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_kernels_delim=\"_\"\n",
    "dec_pools_delim=\"_\" + \"_\".join(map(str, dec_pools))\n",
    "if len(dec_pools) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    dec_pools_delim=\"_\"\n",
    "\n",
    "debug_model = False\n",
    "debug_str = \"true\" if debug_model else \"false\"\n",
    "expt_name = \"ENC_C%s_K%s_P%s_F%s/LATENT_%d/DEC_F%s_C%s_K%s_P%s/ACT_%s_BN_%s_WEIGHT_INIT_%s/OPT_%s_LR_%s_EPOCHS_%d_BATCH_%d_DEBUG_%s\" % (enc_channels_delim,\n",
    "                                                                                                                                        enc_kernels_delim, \n",
    "                                                                                                                                        enc_pools_delim, \n",
    "                                                                                                                                        enc_fc_delim,\n",
    "                                                                                                                                        latent_dim,\n",
    "                                                                                                                                        dec_fc_delim,\n",
    "                                                                                                                                        dec_channels_delim,\n",
    "                                                                                                                                        dec_kernels_delim,                                                                                                                   dec_pools_delim,\n",
    "                                                                                                                                        activation,\n",
    "                                                                                                                                        use_batch_norm_str,\n",
    "                                                                                                                                        weight_init,\n",
    "                                                                                                                                        optimizer,\n",
    "                                                                                                                                        learning_rate,\n",
    "                                                                                                                                        epochs,\n",
    "                                                                                                                                        batch_size,\n",
    "                                                                                                                                        debug_str)\n",
    "\n",
    "time_dim = (left_context + right_context + 1)\n",
    "freq_dim = feat_dim\n",
    "\n",
    "noise_ratio=0.25\n",
    "print(\"Noise ratio %s\" % str(noise_ratio))\n",
    "\n",
    "print(\"Using experiment %s\" % expt_name)\n",
    "\n",
    "dataset = \"ami-0.1\"\n",
    "\n",
    "adv_fc = [256]\n",
    "adv_fc_delim=\"_\" + \"_\".join(map(str, adv_fc))\n",
    "if len(adv_fc) == 0:\n",
    "     # need to recreate bash join behavior with empty array\n",
    "    adv_fc_delim=\"_\"\n",
    "adv_activation = \"Sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up baseline dev datasets\n"
     ]
    }
   ],
   "source": [
    "# Set up datasets for IHM, SDM1 baselines (dev set only)\n",
    "dataset_name = \"ami-0.1\"\n",
    "current_feats = \"/data/sls/r/u/atitus5/meng/%s\" % dataset_name\n",
    "ihm_baseline = HaoEvalDataset(os.path.join(current_feats, \"ihm-dev-norm.blogmel.scp\"))\n",
    "sdm1_baseline = HaoEvalDataset(os.path.join(current_feats, \"sdm1-dev-norm.blogmel.scp\"))\n",
    "print(\"Set up baseline dev datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF DATA AUGMENTATION NOT RUN YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNMultidecoder(\n",
       "  (encoder_conv): Sequential(\n",
       "    (conv2d_0): Conv2d (1, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (SELU_0): SELU\n",
       "    (maxpool2d_0): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))\n",
       "    (conv2d_1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (SELU_1): SELU\n",
       "    (maxpool2d_1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))\n",
       "  )\n",
       "  (encoder_fc): Sequential(\n",
       "    (lin_0): Linear(in_features=14336, out_features=2048)\n",
       "    (SELU_0): SELU\n",
       "    (lin_1): Linear(in_features=2048, out_features=2048)\n",
       "    (SELU_1): SELU\n",
       "    (lin_final): Linear(in_features=2048, out_features=128)\n",
       "    (SELU_final): SELU\n",
       "  )\n",
       "  (decoder_fc_ihm): Sequential(\n",
       "    (lin_0): Linear(in_features=128, out_features=2048)\n",
       "    (SELU_0): SELU\n",
       "    (lin_1): Linear(in_features=2048, out_features=2048)\n",
       "    (SELU_1): SELU\n",
       "    (lin_final): Linear(in_features=2048, out_features=14336)\n",
       "    (SELU_final): SELU\n",
       "  )\n",
       "  (decoder_deconv_ihm): Sequential(\n",
       "    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))\n",
       "    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (SELU_0): SELU\n",
       "    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))\n",
       "    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (SELU_1): SELU\n",
       "  )\n",
       "  (decoder_fc_sdm1): Sequential(\n",
       "    (lin_0): Linear(in_features=128, out_features=2048)\n",
       "    (SELU_0): SELU\n",
       "    (lin_1): Linear(in_features=2048, out_features=2048)\n",
       "    (SELU_1): SELU\n",
       "    (lin_final): Linear(in_features=2048, out_features=14336)\n",
       "    (SELU_final): SELU\n",
       "  )\n",
       "  (decoder_deconv_sdm1): Sequential(\n",
       "    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))\n",
       "    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (SELU_0): SELU\n",
       "    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))\n",
       "    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
       "    (SELU_1): SELU\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type = \"ae\"\n",
    "adversarial = False\n",
    "checkpoint_dir = \"/data/sls/scratch/atitus5/meng/models/cnn/%s/%s\" % (dataset,\n",
    "                                                                      expt_name)\n",
    "\n",
    "if adversarial:\n",
    "    checkpoint_file = \"%s/best_cnn_adversarial_fc_%s_act_%s_%s_ratio%s_md.pth.tar\" % (checkpoint_dir,\n",
    "                                                                      adv_fc_delim,\n",
    "                                                                      adv_activation,\n",
    "                                                                      model_type,\n",
    "                                                                      str(noise_ratio))\n",
    "    '''\n",
    "    checkpoint_file = \"%s/best_cnn_fc_%s_act_%s_%s_ratio%s_md.pth.tar\" % (checkpoint_dir,\n",
    "                                                                      adv_fc_delim,\n",
    "                                                                      adv_activation,\n",
    "                                                                      model_type,\n",
    "                                                                      str(noise_ratio))\n",
    "    '''\n",
    "    \n",
    "    if model_type == \"ae\":\n",
    "        model = CNNAdversarialMultidecoder(freq_dim=freq_dim,\n",
    "                                splicing=[left_context, right_context], \n",
    "                                enc_channel_sizes=enc_channels,\n",
    "                                enc_kernel_sizes=enc_kernels,\n",
    "                                enc_pool_sizes=enc_pools,\n",
    "                                enc_fc_sizes=enc_fc,\n",
    "                                latent_dim=latent_dim,\n",
    "                                dec_fc_sizes=dec_fc,\n",
    "                                dec_channel_sizes=dec_channels,\n",
    "                                dec_kernel_sizes=dec_kernels,\n",
    "                                dec_pool_sizes=dec_pools,\n",
    "                                activation=activation,\n",
    "                                decoder_classes=decoder_classes,\n",
    "                                use_batch_norm=use_batch_norm,\n",
    "                                weight_init=weight_init,\n",
    "                                adv_fc_sizes=adv_fc,\n",
    "                                adv_activation=adv_activation)\n",
    "    elif model_type == \"vae\":\n",
    "        model = CNNAdversarialVariationalMultidecoder(freq_dim=freq_dim,\n",
    "                                splicing=[left_context, right_context], \n",
    "                                enc_channel_sizes=enc_channels,\n",
    "                                enc_kernel_sizes=enc_kernels,\n",
    "                                enc_pool_sizes=enc_pools,\n",
    "                                enc_fc_sizes=enc_fc,\n",
    "                                latent_dim=latent_dim,\n",
    "                                dec_fc_sizes=dec_fc,\n",
    "                                dec_channel_sizes=dec_channels,\n",
    "                                dec_kernel_sizes=dec_kernels,\n",
    "                                dec_pool_sizes=dec_pools,\n",
    "                                activation=activation,\n",
    "                                decoder_classes=decoder_classes,\n",
    "                                use_batch_norm=use_batch_norm,\n",
    "                                weight_init=weight_init,\n",
    "                                adv_fc_sizes=adv_fc,\n",
    "                                adv_activation=adv_activation)\n",
    "else:\n",
    "    checkpoint_file = \"%s/best_cnn_%s_ratio%s_md.pth.tar\" % (checkpoint_dir,\n",
    "                                                             model_type,\n",
    "                                                             str(noise_ratio))\n",
    "    \n",
    "    if model_type == \"ae\":\n",
    "        model = CNNMultidecoder(freq_dim=freq_dim,\n",
    "                                splicing=[left_context, right_context], \n",
    "                                enc_channel_sizes=enc_channels,\n",
    "                                enc_kernel_sizes=enc_kernels,\n",
    "                                enc_pool_sizes=enc_pools,\n",
    "                                enc_fc_sizes=enc_fc,\n",
    "                                latent_dim=latent_dim,\n",
    "                                dec_fc_sizes=dec_fc,\n",
    "                                dec_channel_sizes=dec_channels,\n",
    "                                dec_kernel_sizes=dec_kernels,\n",
    "                                dec_pool_sizes=dec_pools,\n",
    "                                activation=activation,\n",
    "                                decoder_classes=decoder_classes,\n",
    "                                use_batch_norm=use_batch_norm,\n",
    "                                weight_init=weight_init)\n",
    "    elif model_type == \"vae\":\n",
    "        model = CNNVariationalMultidecoder(freq_dim=freq_dim,\n",
    "                                splicing=[left_context, right_context], \n",
    "                                enc_channel_sizes=enc_channels,\n",
    "                                enc_kernel_sizes=enc_kernels,\n",
    "                                enc_pool_sizes=enc_pools,\n",
    "                                enc_fc_sizes=enc_fc,\n",
    "                                latent_dim=latent_dim,\n",
    "                                dec_fc_sizes=dec_fc,\n",
    "                                dec_channel_sizes=dec_channels,\n",
    "                                dec_kernel_sizes=dec_kernels,\n",
    "                                dec_pool_sizes=dec_pools,\n",
    "                                activation=activation,\n",
    "                                decoder_classes=decoder_classes,\n",
    "                                use_batch_norm=use_batch_norm,\n",
    "                                weight_init=weight_init)\n",
    "        \n",
    "        \n",
    "checkpoint = torch.load(checkpoint_file, map_location=lambda storage,loc: storage)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augmentFeats(model, feats, decoder_class):\n",
    "    feats_numpy = feats.reshape((-1, freq_dim))\n",
    "    num_frames = feats_numpy.shape[0]\n",
    "    decoded_feats = np.empty((num_frames, freq_dim))\n",
    "    for i in range(num_frames):\n",
    "        frame_spliced = np.zeros((time_dim, freq_dim))\n",
    "        frame_spliced[left_context - min(i, left_context):left_context, :] = feats_numpy[i - min(i, left_context):i, :]\n",
    "        frame_spliced[left_context, :] = feats_numpy[i, :]\n",
    "        frame_spliced[left_context + 1:left_context + 1 + min(num_frames - i - 1, right_context), :] = feats_numpy[i + 1:i + 1 + min(num_frames - i - 1, right_context), :]\n",
    "        frame_tensor = Variable(torch.FloatTensor(frame_spliced))\n",
    "\n",
    "        recon_frames = model.forward_decoder(frame_tensor, decoder_class)\n",
    "        recon_frames_numpy = recon_frames.cpu().data.numpy().reshape((-1, freq_dim))\n",
    "        decoded_feats[i, :] = recon_frames_numpy[left_context:left_context + 1, :]\n",
    "    return decoded_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdb6a4cd01a41ada8a82d46ee7423cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotParallelUtts>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color_map = \"coolwarm\"\n",
    "color_map = \"viridis\"\n",
    "def plotParallelUtts(utt_id_idx):\n",
    "    fig, axarr = plt.subplots(6, sharex=True)\n",
    "    \n",
    "    fig.set_size_inches(8.5, 11)\n",
    "    \n",
    "    # IHM baseline\n",
    "    ihm_baseline_utt_id = ihm_baseline.utt_ids[utt_id_idx]\n",
    "    ihm_baseline_feats = ihm_baseline.feats_for_uttid(ihm_baseline_utt_id)\n",
    "    axarr[0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0].imshow(np.transpose(ihm_baseline_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0].set_title(\"IHM\")\n",
    "    \n",
    "    # SDM1 baseline\n",
    "    sdm1_baseline_utt_id = sdm1_baseline.utt_ids[utt_id_idx]\n",
    "    sdm1_baseline_feats = sdm1_baseline.feats_for_uttid(sdm1_baseline_utt_id)\n",
    "    axarr[1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1].imshow(np.transpose(sdm1_baseline_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1].set_title(\"SDM1\")\n",
    "    \n",
    "    # IHM->IHM\n",
    "    ihm_ihm_feats = augmentFeats(model, ihm_baseline_feats, \"ihm\")\n",
    "    axarr[2].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2].imshow(np.transpose(ihm_ihm_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[2].set_title(\"IHM>IHM\")\n",
    "    \n",
    "    # IHM->SDM1\n",
    "    ihm_sdm1_feats = augmentFeats(model, ihm_baseline_feats, \"sdm1\")\n",
    "    axarr[3].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[3].imshow(np.transpose(ihm_sdm1_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[3].set_title(\"IHM>SDM1\")\n",
    "    \n",
    "    # SDM1->SDM1\n",
    "    sdm1_sdm1_feats = augmentFeats(model, sdm1_baseline_feats, \"sdm1\")\n",
    "    axarr[4].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[4].imshow(np.transpose(sdm1_sdm1_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[4].set_title(\"SDM1>SDM1\")\n",
    "    \n",
    "    # SDM1->IHM\n",
    "    sdm1_ihm_feats = augmentFeats(model, sdm1_baseline_feats, \"ihm\")\n",
    "    axarr[5].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[5].imshow(np.transpose(sdm1_ihm_feats), origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[5].set_title(\"SDM1>IHM\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig.savefig(\"%s_idx%d.eps\" % (ihm_baseline_utt_id, utt_id_idx))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# 43, 251 are good utterances (long + variations between IHM and SDM1)\n",
    "interact(plotParallelUtts, utt_id_idx=range(len(ihm_baseline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF DATA AUGMENTATION ALREADY RAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up augmented dev datasets\n"
     ]
    }
   ],
   "source": [
    "# Set up augmented datasets for IHM->IHM, IHM->SDM1, SDM1->SDM1, SDM1->IHM (dev set only)\n",
    "model_type = \"ae\"\n",
    "adversarial = True\n",
    "augmented_data_base_dir = \"/data/sls/scratch/atitus5/meng/augmented_data/cnn/%s/%s\" % (dataset,\n",
    "                                                                                       expt_name)\n",
    "\n",
    "if adversarial:\n",
    "    augmented_data_dir = \"%s/adversarial_fc_%s_act_%s_%s_ratio%s\" % (augmented_data_base_dir,\n",
    "                                                                     adv_fc_delim,\n",
    "                                                                     adv_activation,\n",
    "                                                                     model_type,\n",
    "                                                                     str(noise_ratio))\n",
    "else:\n",
    "    augmented_data_dir = \"%s/%s_ratio%s\" % (augmented_data_base_dir,\n",
    "                                            model_type,\n",
    "                                            str(noise_ratio))\n",
    "\n",
    "ihm_ihm = HaoEvalDataset(os.path.join(augmented_data_dir, \"dev-src_ihm-tar_ihm.scp\"))\n",
    "ihm_sdm1 = HaoEvalDataset(os.path.join(augmented_data_dir, \"dev-src_ihm-tar_sdm1.scp\"))\n",
    "sdm1_sdm1 = HaoEvalDataset(os.path.join(augmented_data_dir, \"dev-src_sdm1-tar_sdm1.scp\"))\n",
    "sdm1_ihm = HaoEvalDataset(os.path.join(augmented_data_dir, \"dev-src_sdm1-tar_ihm.scp\"))\n",
    "print(\"Set up augmented dev datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853711e961d84850ab858321f6ab3ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plotParallelUtts>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# color_map = \"coolwarm\"\n",
    "color_map = \"viridis\"\n",
    "def plotParallelUtts(utt_id_idx):\n",
    "    fig, axarr = plt.subplots(6, sharex=True)\n",
    "    \n",
    "    fig.set_size_inches(8.5, 11)\n",
    "    \n",
    "    # IHM baseline\n",
    "    ihm_baseline_utt_id = ihm_baseline.utt_ids[utt_id_idx]\n",
    "    ihm_baseline_feats = np.transpose(ihm_baseline.feats_for_uttid(ihm_baseline_utt_id))\n",
    "    axarr[0].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[0].imshow(ihm_baseline_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[0].set_title(\"IHM\")\n",
    "    \n",
    "    # SDM1 baseline\n",
    "    sdm1_baseline_utt_id = sdm1_baseline.utt_ids[utt_id_idx]\n",
    "    sdm1_baseline_feats = np.transpose(sdm1_baseline.feats_for_uttid(sdm1_baseline_utt_id))\n",
    "    axarr[1].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[1].imshow(sdm1_baseline_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[1].set_title(\"SDM1\")\n",
    "    \n",
    "    # IHM->IHM baseline\n",
    "    ihm_ihm_utt_id = ihm_ihm.utt_ids[utt_id_idx]\n",
    "    ihm_ihm_feats = np.transpose(ihm_ihm.feats_for_uttid(ihm_ihm_utt_id))\n",
    "    axarr[2].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[2].imshow(ihm_ihm_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[2].set_title(\"IHM>IHM\")\n",
    "    \n",
    "    # IHM->SDM1 baseline\n",
    "    ihm_sdm1_utt_id = ihm_sdm1.utt_ids[utt_id_idx]\n",
    "    ihm_sdm1_feats = np.transpose(ihm_sdm1.feats_for_uttid(ihm_sdm1_utt_id))\n",
    "    axarr[3].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[3].imshow(ihm_sdm1_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[3].set_title(\"IHM>SDM1\")\n",
    "    \n",
    "    # SDM1->SDM1 baseline\n",
    "    sdm1_sdm1_utt_id = sdm1_sdm1.utt_ids[utt_id_idx]\n",
    "    sdm1_sdm1_feats = np.transpose(sdm1_sdm1.feats_for_uttid(sdm1_sdm1_utt_id))\n",
    "    axarr[4].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[4].imshow(sdm1_sdm1_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[4].set_title(\"SDM1>SDM1\")\n",
    "    \n",
    "    # SDM1->IHM baseline\n",
    "    sdm1_ihm_utt_id = sdm1_ihm.utt_ids[utt_id_idx]\n",
    "    sdm1_ihm_feats = np.transpose(sdm1_ihm.feats_for_uttid(sdm1_ihm_utt_id))\n",
    "    axarr[5].axis('off')    # Pretty-up the resulting output by removing gridlines\n",
    "    axarr[5].imshow(sdm1_ihm_feats, origin='lower', cmap=color_map, aspect='auto', interpolation='none')\n",
    "    axarr[5].set_title(\"SDM1>IHM\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    fig.savefig(\"%s_idx%d.png\" % (ihm_baseline_utt_id, utt_id_idx))\n",
    "\n",
    "# 43, 251 are good utterances (long + variations between IHM and SDM1)\n",
    "interact(plotParallelUtts, utt_id_idx=range(len(ihm_baseline)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
