Setting up environment...
Environment set up.
Training deep multidecoder...
Constructing model...
Done constructing model.
DNNMultidecoder (
  (activation): SELU
  (encoder): Sequential (
    (lin_0): Linear (880 -> 1024)
    (bn_0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)
    (SELU_0): SELU
    (lin_final): Linear (1024 -> 512)
  )
  (decoder_ihm): Sequential (
    (lin_0): Linear (512 -> 1024)
    (SELU_0): SELU
    (lin_final): Linear (1024 -> 880)
  )
  (decoder_sdm1): Sequential (
    (lin_0): Linear (512 -> 1024)
    (SELU_0): SELU
    (lin_final): Linear (1024 -> 880)
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 0.232880
Train epoch 1: [2000/18806 (10.6%)]	Loss: 0.186220
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.193198
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.185906
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.176460
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.168253
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.161197
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.157791
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.154122
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.152448
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.149879
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.146886
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.142627
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.138442
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.137331
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.138172
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.137344
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.137364
====> Epoch 1: Average train loss 0.137041
====> Dev set loss: 0.094784
New best dev set loss: 0.094784
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.106432
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.091016
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.105200
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.106628
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.104957
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.102641
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.100074
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.100453
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.100378
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.100675
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.100344
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.099621
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.097548
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.095492
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.095587
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.097660
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.098150
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.099176
====> Epoch 2: Average train loss 0.099787
====> Dev set loss: 0.101223
No improvement in 1 epochs (best dev set loss: 0.094784)
Not saving checkpoint; no improvement made
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.088335
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.075815
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.088738
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.090421
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.089503
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.087497
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.085785
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.086889
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.087096
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.087933
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.087737
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.087368
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.085459
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.083775
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.083877
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.086383
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.086829
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.087920
====> Epoch 3: Average train loss 0.088675
====> Dev set loss: 0.095135
No improvement in 2 epochs (best dev set loss: 0.094784)
Not saving checkpoint; no improvement made
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.078647
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.068737
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.080954
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.081925
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.081106
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.079578
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.077988
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.078985
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.079142
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.079861
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.079808
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.079391
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.077958
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.076367
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.076565
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.079097
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.079502
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.080318
====> Epoch 4: Average train loss 0.081250
====> Dev set loss: 0.109594
No improvement in 3 epochs (best dev set loss: 0.094784)
STOPPING EARLY
Trained deep multidecoder.
