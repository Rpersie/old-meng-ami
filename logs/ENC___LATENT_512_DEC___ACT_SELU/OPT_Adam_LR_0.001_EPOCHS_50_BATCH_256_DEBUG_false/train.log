Setting up environment...
Environment set up.
Training deep multidecoder...
Constructing model...
Done constructing model.
DNNMultidecoder (
  (activation): SELU
  (encoder): Sequential (
    (lin_final): Linear (880 -> 512)
  )
  (decoder_ihm): Sequential (
    (lin_final): Linear (512 -> 880)
  )
  (decoder_sdm1): Sequential (
    (lin_final): Linear (512 -> 880)
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 0.102254
Train epoch 1: [2000/18806 (10.6%)]	Loss: 0.070660
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.264372
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.205720
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.169849
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.146069
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.129685
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.116551
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.106977
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.098387
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.093600
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.087308
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.081981
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.077836
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.103313
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.098416
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.093628
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.089344
====> Epoch 1: Average train loss 0.086229
====> Dev set loss: 0.015372
New best dev set loss: 0.015372
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.015370
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.014406
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.015251
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.014727
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.014231
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.013813
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.013426
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.017784
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.017265
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.016673
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.039829
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.037903
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.036006
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.034369
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.034877
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.033540
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.032202
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.031011
====> Epoch 2: Average train loss 0.030155
====> Dev set loss: 0.010462
New best dev set loss: 0.010462
Saved checkpoint for model
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.012065
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.011433
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.066164
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.052863
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.044541
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.038812
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.034679
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.031641
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.043196
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.040229
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.037670
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.035630
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.033794
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.032999
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.106324
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.101385
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.096444
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.091984
====> Epoch 3: Average train loss 0.088715
====> Dev set loss: 0.014362
No improvement in 1 epochs (best dev set loss: 0.010462)
Not saving checkpoint; no improvement made
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.014009
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.013244
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.013921
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.013387
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.012879
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.012465
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.012429
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.012228
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.012497
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.012247
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.049607
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.047138
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.044654
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.042405
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.043492
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.041625
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.039828
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.038210
====> Epoch 4: Average train loss 0.037040
====> Dev set loss: 0.010543
No improvement in 2 epochs (best dev set loss: 0.010462)
Not saving checkpoint; no improvement made
Train epoch 5: [1000/18806 (5.3%)]	Loss: 0.010596
Train epoch 5: [2000/18806 (10.6%)]	Loss: 0.010298
Train epoch 5: [3000/18806 (16.0%)]	Loss: 0.027595
Train epoch 5: [4000/18806 (21.3%)]	Loss: 0.023654
Train epoch 5: [5000/18806 (26.6%)]	Loss: 0.020935
Train epoch 5: [6000/18806 (31.9%)]	Loss: 0.019032
Train epoch 5: [7000/18806 (37.2%)]	Loss: 0.017656
Train epoch 5: [8000/18806 (42.5%)]	Loss: 0.018802
Train epoch 5: [9000/18806 (47.9%)]	Loss: 0.045580
Train epoch 5: [10000/18806 (53.2%)]	Loss: 0.042671
Train epoch 5: [11000/18806 (58.5%)]	Loss: 0.039854
Train epoch 5: [12000/18806 (63.8%)]	Loss: 0.037417
Train epoch 5: [13000/18806 (69.1%)]	Loss: 0.035399
Train epoch 5: [14000/18806 (74.4%)]	Loss: 0.033983
Train epoch 5: [15000/18806 (79.8%)]	Loss: 0.079905
Train epoch 5: [16000/18806 (85.1%)]	Loss: 0.076308
Train epoch 5: [17000/18806 (90.4%)]	Loss: 0.072659
Train epoch 5: [18000/18806 (95.7%)]	Loss: 0.069367
====> Epoch 5: Average train loss 0.066959
====> Dev set loss: 0.012336
No improvement in 3 epochs (best dev set loss: 0.010462)
STOPPING EARLY
Trained deep multidecoder.
