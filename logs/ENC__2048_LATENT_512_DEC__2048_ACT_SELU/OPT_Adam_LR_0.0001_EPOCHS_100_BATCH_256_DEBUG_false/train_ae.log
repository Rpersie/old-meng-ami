Setting up environment...
Environment set up.
Training deep multidecoder...
Constructing model...
Done constructing model.
DNNMultidecoder (
  (activation): SELU
  (encoder): Sequential (
    (lin_0): Linear (880 -> 2048)
    (bn_0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (SELU_0): SELU
    (lin_final): Linear (2048 -> 512)
  )
  (decoder_ihm): Sequential (
    (lin_0): Linear (512 -> 2048)
    (SELU_0): SELU
    (lin_final): Linear (2048 -> 880)
  )
  (decoder_sdm1): Sequential (
    (lin_0): Linear (512 -> 2048)
    (SELU_0): SELU
    (lin_final): Linear (2048 -> 880)
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 0.204452
Train epoch 1: [2000/18806 (10.6%)]	Loss: 0.162915
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.170631
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.164167
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.155317
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.147519
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.140762
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.137519
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.134137
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.132539
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.130270
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.127537
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.123611
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.119706
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.118753
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.119353
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.118794
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.118897
====> Epoch 1: Average train loss 0.118663
====> Dev set loss: 0.081801
New best dev set loss: 0.081801
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.090118
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.076161
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.090168
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.091867
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.090304
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.088195
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.085769
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.086243
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.086142
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.086325
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.086186
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.085587
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.083696
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.081755
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.081871
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.083855
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.084469
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.085480
====> Epoch 2: Average train loss 0.086115
====> Dev set loss: 0.089579
No improvement in 1 epochs (best dev set loss: 0.081801)
Not saving checkpoint; no improvement made
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.075747
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.064113
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.077083
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.078910
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.078002
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.076176
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.074554
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.075605
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.075780
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.076656
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.076587
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.076280
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.074555
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.072954
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.073063
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.075368
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.075863
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.076912
====> Epoch 3: Average train loss 0.077687
====> Dev set loss: 0.083642
No improvement in 2 epochs (best dev set loss: 0.081801)
Not saving checkpoint; no improvement made
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.069027
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.059680
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.071787
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.072662
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.071848
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.070393
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.068878
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.069941
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.070088
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.070792
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.070854
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.070504
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.069186
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.067678
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.067847
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.070082
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.070567
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.071363
====> Epoch 4: Average train loss 0.072299
====> Dev set loss: 0.097274
No improvement in 3 epochs (best dev set loss: 0.081801)
STOPPING EARLY
Trained deep multidecoder.
