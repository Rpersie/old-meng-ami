Setting up environment...
Environment set up.
Training deep variational multidecoder...
Constructing model...
Done constructing model.
DNNVariationalMultidecoder (
  (activation): SELU
  (encoder): Sequential (
    (lin_0): Linear (880 -> 2048)
    (bn_0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (SELU_0): SELU
    (lin_1): Linear (2048 -> 2048)
    (bn_1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (SELU_1): SELU
    (lin_2): Linear (2048 -> 2048)
    (bn_2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (SELU_2): SELU
  )
  (latent_mu): Sequential (
    (lin): Linear (2048 -> 512)
    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)
    (SELU): SELU
  )
  (latent_logvar): Sequential (
    (lin): Linear (2048 -> 512)
    (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True)
    (SELU): SELU
  )
  (decoder_ihm): Sequential (
    (lin_0): Linear (512 -> 2048)
    (SELU_0): SELU
    (lin_1): Linear (2048 -> 2048)
    (SELU_1): SELU
    (lin_2): Linear (2048 -> 2048)
    (SELU_2): SELU
    (lin_final): Linear (2048 -> 880)
  )
  (decoder_sdm1): Sequential (
    (lin_0): Linear (512 -> 2048)
    (SELU_0): SELU
    (lin_1): Linear (2048 -> 2048)
    (SELU_1): SELU
    (lin_2): Linear (2048 -> 2048)
    (SELU_2): SELU
    (lin_final): Linear (2048 -> 880)
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 1.291248
Train epoch 1: [2000/18806 (10.6%)]	Loss: 1.019795
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.930479
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.852628
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.792257
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.745700
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.711117
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.684601
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.660729
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.641862
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.624252
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.609498
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.589786
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.571904
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.560168
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.552350
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.543023
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.535636
====> Epoch 1: Average train loss 0.531076
====> Dev set loss: 0.369448
New best dev set loss: 0.369448
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.344961
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.321299
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.356577
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.359430
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.356261
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.351825
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.349880
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.351570
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.351070
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.351675
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.351031
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.351174
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.345766
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.341472
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.340765
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.343082
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.343227
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.344423
====> Epoch 2: Average train loss 0.346455
====> Dev set loss: 0.362993
New best dev set loss: 0.362993
Saved checkpoint for model
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.316340
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.298790
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.330659
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.334319
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.331684
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.328227
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.328093
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.330852
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.331367
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.332597
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.332481
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.333290
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.328633
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.324998
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.324839
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.327407
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.327380
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.328703
====> Epoch 3: Average train loss 0.330975
====> Dev set loss: 0.364452
No improvement in 1 epochs (best dev set loss: 0.362993)
Not saving checkpoint; no improvement made
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.309101
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.292242
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.322253
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.323857
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.321649
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.319137
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.318897
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.321788
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.322415
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.324134
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.324223
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.324864
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.320734
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.317434
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.317694
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.320307
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.320172
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.321318
====> Epoch 4: Average train loss 0.323522
====> Dev set loss: 0.368841
No improvement in 2 epochs (best dev set loss: 0.362993)
Not saving checkpoint; no improvement made
Train epoch 5: [1000/18806 (5.3%)]	Loss: 0.304381
Train epoch 5: [2000/18806 (10.6%)]	Loss: 0.288442
Train epoch 5: [3000/18806 (16.0%)]	Loss: 0.318014
Train epoch 5: [4000/18806 (21.3%)]	Loss: 0.319227
Train epoch 5: [5000/18806 (26.6%)]	Loss: 0.317627
Train epoch 5: [6000/18806 (31.9%)]	Loss: 0.315105
Train epoch 5: [7000/18806 (37.2%)]	Loss: 0.314786
Train epoch 5: [8000/18806 (42.5%)]	Loss: 0.317738
Train epoch 5: [9000/18806 (47.9%)]	Loss: 0.318450
Train epoch 5: [10000/18806 (53.2%)]	Loss: 0.319638
Train epoch 5: [11000/18806 (58.5%)]	Loss: 0.319552
Train epoch 5: [12000/18806 (63.8%)]	Loss: 0.320463
Train epoch 5: [13000/18806 (69.1%)]	Loss: 0.316506
Train epoch 5: [14000/18806 (74.4%)]	Loss: 0.313367
Train epoch 5: [15000/18806 (79.8%)]	Loss: 0.313344
Train epoch 5: [16000/18806 (85.1%)]	Loss: 0.315973
Train epoch 5: [17000/18806 (90.4%)]	Loss: 0.316023
Train epoch 5: [18000/18806 (95.7%)]	Loss: 0.317359
====> Epoch 5: Average train loss 0.319630
====> Dev set loss: 0.367187
No improvement in 3 epochs (best dev set loss: 0.362993)
STOPPING EARLY
Trained deep variational multidecoder.
