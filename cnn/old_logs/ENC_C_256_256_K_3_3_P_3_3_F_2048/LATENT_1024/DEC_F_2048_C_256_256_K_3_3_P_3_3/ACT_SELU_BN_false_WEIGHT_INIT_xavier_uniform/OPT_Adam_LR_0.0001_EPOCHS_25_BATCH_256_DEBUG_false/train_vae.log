Running training with mode vae
Noising 25.000% of input features
Constructing model...
Done constructing model.
CNNVariationalMultidecoder (
  (encoder_conv): Sequential (
    (conv2d_0): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_0): SELU
    (maxpool2d_0): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_1): SELU
    (maxpool2d_1): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential (
    (lin_0): Linear (14336 -> 2048)
    (SELU_0): SELU
  )
  (decoder_fc_ihm): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (SELU_0): SELU
    (lin_final): Linear (2048 -> 14336)
    (SELU_final): SELU
  )
  (decoder_deconv_ihm): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (decoder_fc_sdm1): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (SELU_0): SELU
    (lin_final): Linear (2048 -> 14336)
    (SELU_final): SELU
  )
  (decoder_deconv_sdm1): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (latent_mu): Sequential (
    (lin): Linear (2048 -> 1024)
    (SELU): SELU
  )
  (latent_logvar): Sequential (
    (lin): Linear (2048 -> 1024)
    (SELU): SELU
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Completed setup in 171.991 seconds
Starting training!

STARTING EPOCH 1
Train epoch 1: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.716
===> backtranslation_recon_loss: 0.740
===> autoencoding_kld: 0.197
===> backtranslation_kld: 0.149
===> Total for class ihm: 1.802
=> Class sdm1
===> autoencoding_recon_loss: 0.699
===> backtranslation_recon_loss: 0.696
===> autoencoding_kld: 0.187
===> backtranslation_kld: 0.151
===> Total for class sdm1: 1.733
TOTAL: 3.535
Train epoch 1: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.627
===> backtranslation_recon_loss: 0.653
===> autoencoding_kld: 0.178
===> backtranslation_kld: 0.145
===> Total for class ihm: 1.603
=> Class sdm1
===> autoencoding_recon_loss: 0.616
===> backtranslation_recon_loss: 0.611
===> autoencoding_kld: 0.158
===> backtranslation_kld: 0.145
===> Total for class sdm1: 1.529
TOTAL: 3.133
Train epoch 1: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.591
===> backtranslation_recon_loss: 0.624
===> autoencoding_kld: 0.178
===> backtranslation_kld: 0.145
===> Total for class ihm: 1.538
=> Class sdm1
===> autoencoding_recon_loss: 0.574
===> backtranslation_recon_loss: 0.573
===> autoencoding_kld: 0.155
===> backtranslation_kld: 0.153
===> Total for class sdm1: 1.455
TOTAL: 2.992
Train epoch 1: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.563
===> backtranslation_recon_loss: 0.600
===> autoencoding_kld: 0.180
===> backtranslation_kld: 0.148
===> Total for class ihm: 1.491
=> Class sdm1
===> autoencoding_recon_loss: 0.556
===> backtranslation_recon_loss: 0.556
===> autoencoding_kld: 0.157
===> backtranslation_kld: 0.159
===> Total for class sdm1: 1.428
TOTAL: 2.918
Train epoch 1: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.545
===> backtranslation_recon_loss: 0.585
===> autoencoding_kld: 0.180
===> backtranslation_kld: 0.149
===> Total for class ihm: 1.460
=> Class sdm1
===> autoencoding_recon_loss: 0.542
===> backtranslation_recon_loss: 0.540
===> autoencoding_kld: 0.157
===> backtranslation_kld: 0.160
===> Total for class sdm1: 1.399
TOTAL: 2.859
Train epoch 1: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.533
===> backtranslation_recon_loss: 0.576
===> autoencoding_kld: 0.186
===> backtranslation_kld: 0.157
===> Total for class ihm: 1.452
=> Class sdm1
===> autoencoding_recon_loss: 0.530
===> backtranslation_recon_loss: 0.530
===> autoencoding_kld: 0.164
===> backtranslation_kld: 0.169
===> Total for class sdm1: 1.394
TOTAL: 2.847
Train epoch 1: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.519
===> backtranslation_recon_loss: 0.562
===> autoencoding_kld: 0.184
===> backtranslation_kld: 0.156
===> Total for class ihm: 1.422
=> Class sdm1
===> autoencoding_recon_loss: 0.520
===> backtranslation_recon_loss: 0.521
===> autoencoding_kld: 0.162
===> backtranslation_kld: 0.168
===> Total for class sdm1: 1.372
TOTAL: 2.793
Train epoch 1: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.510
===> backtranslation_recon_loss: 0.554
===> autoencoding_kld: 0.184
===> backtranslation_kld: 0.156
===> Total for class ihm: 1.403
=> Class sdm1
===> autoencoding_recon_loss: 0.512
===> backtranslation_recon_loss: 0.513
===> autoencoding_kld: 0.160
===> backtranslation_kld: 0.167
===> Total for class sdm1: 1.352
TOTAL: 2.755
Train epoch 1: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.502
===> backtranslation_recon_loss: 0.547
===> autoencoding_kld: 0.184
===> backtranslation_kld: 0.154
===> Total for class ihm: 1.387
=> Class sdm1
===> autoencoding_recon_loss: 0.506
===> backtranslation_recon_loss: 0.506
===> autoencoding_kld: 0.161
===> backtranslation_kld: 0.171
===> Total for class sdm1: 1.345
TOTAL: 2.732
Train epoch 1: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.495
===> backtranslation_recon_loss: 0.538
===> autoencoding_kld: 0.180
===> backtranslation_kld: 0.151
===> Total for class ihm: 1.363
=> Class sdm1
===> autoencoding_recon_loss: 0.498
===> backtranslation_recon_loss: 0.498
===> autoencoding_kld: 0.156
===> backtranslation_kld: 0.166
===> Total for class sdm1: 1.318
TOTAL: 2.681
Train epoch 1: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.487
===> backtranslation_recon_loss: 0.531
===> autoencoding_kld: 0.178
===> backtranslation_kld: 0.149
===> Total for class ihm: 1.345
=> Class sdm1
===> autoencoding_recon_loss: 0.492
===> backtranslation_recon_loss: 0.492
===> autoencoding_kld: 0.154
===> backtranslation_kld: 0.165
===> Total for class sdm1: 1.303
TOTAL: 2.649
Train epoch 1: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.481
===> backtranslation_recon_loss: 0.524
===> autoencoding_kld: 0.175
===> backtranslation_kld: 0.147
===> Total for class ihm: 1.327
=> Class sdm1
===> autoencoding_recon_loss: 0.485
===> backtranslation_recon_loss: 0.485
===> autoencoding_kld: 0.150
===> backtranslation_kld: 0.162
===> Total for class sdm1: 1.283
TOTAL: 2.610
Train epoch 1: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.476
===> backtranslation_recon_loss: 0.519
===> autoencoding_kld: 0.174
===> backtranslation_kld: 0.146
===> Total for class ihm: 1.316
=> Class sdm1
===> autoencoding_recon_loss: 0.479
===> backtranslation_recon_loss: 0.479
===> autoencoding_kld: 0.148
===> backtranslation_kld: 0.161
===> Total for class sdm1: 1.266
TOTAL: 2.582
Train epoch 1: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.471
===> backtranslation_recon_loss: 0.513
===> autoencoding_kld: 0.172
===> backtranslation_kld: 0.144
===> Total for class ihm: 1.300
=> Class sdm1
===> autoencoding_recon_loss: 0.474
===> backtranslation_recon_loss: 0.474
===> autoencoding_kld: 0.146
===> backtranslation_kld: 0.159
===> Total for class sdm1: 1.253
TOTAL: 2.553
Train epoch 1: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.466
===> backtranslation_recon_loss: 0.508
===> autoencoding_kld: 0.170
===> backtranslation_kld: 0.143
===> Total for class ihm: 1.287
=> Class sdm1
===> autoencoding_recon_loss: 0.469
===> backtranslation_recon_loss: 0.469
===> autoencoding_kld: 0.143
===> backtranslation_kld: 0.157
===> Total for class sdm1: 1.238
TOTAL: 2.525
Train epoch 1: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.462
===> backtranslation_recon_loss: 0.503
===> autoencoding_kld: 0.168
===> backtranslation_kld: 0.141
===> Total for class ihm: 1.274
=> Class sdm1
===> autoencoding_recon_loss: 0.463
===> backtranslation_recon_loss: 0.464
===> autoencoding_kld: 0.141
===> backtranslation_kld: 0.155
===> Total for class sdm1: 1.223
TOTAL: 2.496
Train epoch 1: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.459
===> backtranslation_recon_loss: 0.501
===> autoencoding_kld: 0.169
===> backtranslation_kld: 0.142
===> Total for class ihm: 1.271
=> Class sdm1
===> autoencoding_recon_loss: 0.462
===> backtranslation_recon_loss: 0.462
===> autoencoding_kld: 0.144
===> backtranslation_kld: 0.159
===> Total for class sdm1: 1.226
TOTAL: 2.497
Train epoch 1: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.455
===> backtranslation_recon_loss: 0.495
===> autoencoding_kld: 0.166
===> backtranslation_kld: 0.140
===> Total for class ihm: 1.256
=> Class sdm1
===> autoencoding_recon_loss: 0.457
===> backtranslation_recon_loss: 0.457
===> autoencoding_kld: 0.141
===> backtranslation_kld: 0.156
===> Total for class sdm1: 1.211
TOTAL: 2.467

EPOCH 1 TRAIN (6101.658s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.452
===> backtranslation_recon_loss: 0.492
===> autoencoding_kld: 0.165
===> backtranslation_kld: 0.140
===> Total for class ihm: 1.248
=> Class sdm1
===> autoencoding_recon_loss: 0.453
===> backtranslation_recon_loss: 0.452
===> autoencoding_kld: 0.139
===> backtranslation_kld: 0.155
===> Total for class sdm1: 1.199
TOTAL: 2.448

EPOCH 1 DEV (223.283s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.317
===> autoencoding_kld: 0.111
===> backtranslation_kld: 0.092
===> Total for class ihm: 0.806
=> Class sdm1
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.306
===> autoencoding_kld: 0.084
===> backtranslation_kld: 0.101
===> Total for class sdm1: 0.774
TOTAL: 1.580

New best dev set loss: 1.579859
Saved checkpoint for model

STARTING EPOCH 2
Train epoch 2: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.379
===> backtranslation_recon_loss: 0.415
===> autoencoding_kld: 0.147
===> backtranslation_kld: 0.128
===> Total for class ihm: 1.070
=> Class sdm1
===> autoencoding_recon_loss: 0.378
===> backtranslation_recon_loss: 0.382
===> autoencoding_kld: 0.107
===> backtranslation_kld: 0.131
===> Total for class sdm1: 0.998
TOTAL: 2.069
Train epoch 2: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.372
===> backtranslation_recon_loss: 0.407
===> autoencoding_kld: 0.136
===> backtranslation_kld: 0.117
===> Total for class ihm: 1.032
=> Class sdm1
===> autoencoding_recon_loss: 0.377
===> backtranslation_recon_loss: 0.378
===> autoencoding_kld: 0.105
===> backtranslation_kld: 0.126
===> Total for class sdm1: 0.985
TOTAL: 2.017
Train epoch 2: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.377
===> backtranslation_recon_loss: 0.413
===> autoencoding_kld: 0.140
===> backtranslation_kld: 0.120
===> Total for class ihm: 1.050
=> Class sdm1
===> autoencoding_recon_loss: 0.380
===> backtranslation_recon_loss: 0.379
===> autoencoding_kld: 0.109
===> backtranslation_kld: 0.130
===> Total for class sdm1: 0.998
TOTAL: 2.048
Train epoch 2: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.374
===> backtranslation_recon_loss: 0.408
===> autoencoding_kld: 0.137
===> backtranslation_kld: 0.118
===> Total for class ihm: 1.037
=> Class sdm1
===> autoencoding_recon_loss: 0.379
===> backtranslation_recon_loss: 0.382
===> autoencoding_kld: 0.108
===> backtranslation_kld: 0.129
===> Total for class sdm1: 0.998
TOTAL: 2.035
Train epoch 2: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.375
===> backtranslation_recon_loss: 0.411
===> autoencoding_kld: 0.140
===> backtranslation_kld: 0.124
===> Total for class ihm: 1.050
=> Class sdm1
===> autoencoding_recon_loss: 0.381
===> backtranslation_recon_loss: 0.386
===> autoencoding_kld: 0.112
===> backtranslation_kld: 0.133
===> Total for class sdm1: 1.013
TOTAL: 2.064
Train epoch 2: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.374
===> backtranslation_recon_loss: 0.408
===> autoencoding_kld: 0.140
===> backtranslation_kld: 0.124
===> Total for class ihm: 1.046
=> Class sdm1
===> autoencoding_recon_loss: 0.379
===> backtranslation_recon_loss: 0.383
===> autoencoding_kld: 0.111
===> backtranslation_kld: 0.132
===> Total for class sdm1: 1.005
TOTAL: 2.051
Train epoch 2: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.369
===> backtranslation_recon_loss: 0.403
===> autoencoding_kld: 0.136
===> backtranslation_kld: 0.121
===> Total for class ihm: 1.029
=> Class sdm1
===> autoencoding_recon_loss: 0.376
===> backtranslation_recon_loss: 0.381
===> autoencoding_kld: 0.108
===> backtranslation_kld: 0.128
===> Total for class sdm1: 0.993
TOTAL: 2.022
Train epoch 2: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.366
===> backtranslation_recon_loss: 0.400
===> autoencoding_kld: 0.134
===> backtranslation_kld: 0.119
===> Total for class ihm: 1.019
=> Class sdm1
===> autoencoding_recon_loss: 0.374
===> backtranslation_recon_loss: 0.380
===> autoencoding_kld: 0.107
===> backtranslation_kld: 0.126
===> Total for class sdm1: 0.986
TOTAL: 2.005
Train epoch 2: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.366
===> backtranslation_recon_loss: 0.402
===> autoencoding_kld: 0.136
===> backtranslation_kld: 0.122
===> Total for class ihm: 1.025
=> Class sdm1
===> autoencoding_recon_loss: 0.375
===> backtranslation_recon_loss: 0.381
===> autoencoding_kld: 0.109
===> backtranslation_kld: 0.129
===> Total for class sdm1: 0.994
TOTAL: 2.020
Train epoch 2: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.362
===> backtranslation_recon_loss: 0.397
===> autoencoding_kld: 0.133
===> backtranslation_kld: 0.118
===> Total for class ihm: 1.011
=> Class sdm1
===> autoencoding_recon_loss: 0.372
===> backtranslation_recon_loss: 0.378
===> autoencoding_kld: 0.107
===> backtranslation_kld: 0.125
===> Total for class sdm1: 0.982
TOTAL: 1.993
Train epoch 2: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.363
===> backtranslation_recon_loss: 0.399
===> autoencoding_kld: 0.133
===> backtranslation_kld: 0.118
===> Total for class ihm: 1.013
=> Class sdm1
===> autoencoding_recon_loss: 0.370
===> backtranslation_recon_loss: 0.378
===> autoencoding_kld: 0.107
===> backtranslation_kld: 0.125
===> Total for class sdm1: 0.980
TOTAL: 1.992
Train epoch 2: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.360
===> backtranslation_recon_loss: 0.396
===> autoencoding_kld: 0.130
===> backtranslation_kld: 0.115
===> Total for class ihm: 1.001
=> Class sdm1
===> autoencoding_recon_loss: 0.368
===> backtranslation_recon_loss: 0.375
===> autoencoding_kld: 0.104
===> backtranslation_kld: 0.122
===> Total for class sdm1: 0.968
TOTAL: 1.970
Train epoch 2: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.358
===> backtranslation_recon_loss: 0.395
===> autoencoding_kld: 0.128
===> backtranslation_kld: 0.113
===> Total for class ihm: 0.995
=> Class sdm1
===> autoencoding_recon_loss: 0.365
===> backtranslation_recon_loss: 0.373
===> autoencoding_kld: 0.102
===> backtranslation_kld: 0.120
===> Total for class sdm1: 0.961
TOTAL: 1.955
Train epoch 2: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.357
===> backtranslation_recon_loss: 0.394
===> autoencoding_kld: 0.127
===> backtranslation_kld: 0.112
===> Total for class ihm: 0.990
=> Class sdm1
===> autoencoding_recon_loss: 0.364
===> backtranslation_recon_loss: 0.373
===> autoencoding_kld: 0.101
===> backtranslation_kld: 0.119
===> Total for class sdm1: 0.957
TOTAL: 1.947
Train epoch 2: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.355
===> backtranslation_recon_loss: 0.393
===> autoencoding_kld: 0.126
===> backtranslation_kld: 0.111
===> Total for class ihm: 0.985
=> Class sdm1
===> autoencoding_recon_loss: 0.363
===> backtranslation_recon_loss: 0.372
===> autoencoding_kld: 0.100
===> backtranslation_kld: 0.117
===> Total for class sdm1: 0.953
TOTAL: 1.938
Train epoch 2: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.353
===> backtranslation_recon_loss: 0.391
===> autoencoding_kld: 0.124
===> backtranslation_kld: 0.109
===> Total for class ihm: 0.977
=> Class sdm1
===> autoencoding_recon_loss: 0.361
===> backtranslation_recon_loss: 0.370
===> autoencoding_kld: 0.099
===> backtranslation_kld: 0.116
===> Total for class sdm1: 0.946
TOTAL: 1.923
Train epoch 2: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.353
===> backtranslation_recon_loss: 0.391
===> autoencoding_kld: 0.123
===> backtranslation_kld: 0.109
===> Total for class ihm: 0.976
=> Class sdm1
===> autoencoding_recon_loss: 0.361
===> backtranslation_recon_loss: 0.370
===> autoencoding_kld: 0.098
===> backtranslation_kld: 0.115
===> Total for class sdm1: 0.945
TOTAL: 1.920
Train epoch 2: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.351
===> backtranslation_recon_loss: 0.390
===> autoencoding_kld: 0.121
===> backtranslation_kld: 0.107
===> Total for class ihm: 0.969
=> Class sdm1
===> autoencoding_recon_loss: 0.359
===> backtranslation_recon_loss: 0.369
===> autoencoding_kld: 0.097
===> backtranslation_kld: 0.113
===> Total for class sdm1: 0.938
TOTAL: 1.907

EPOCH 2 TRAIN (6153.004s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.350
===> backtranslation_recon_loss: 0.389
===> autoencoding_kld: 0.120
===> backtranslation_kld: 0.107
===> Total for class ihm: 0.967
=> Class sdm1
===> autoencoding_recon_loss: 0.358
===> backtranslation_recon_loss: 0.368
===> autoencoding_kld: 0.096
===> backtranslation_kld: 0.113
===> Total for class sdm1: 0.935
TOTAL: 1.902

EPOCH 2 DEV (223.215s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.243
===> backtranslation_recon_loss: 0.294
===> autoencoding_kld: 0.077
===> backtranslation_kld: 0.067
===> Total for class ihm: 0.682
=> Class sdm1
===> autoencoding_recon_loss: 0.257
===> backtranslation_recon_loss: 0.288
===> autoencoding_kld: 0.062
===> backtranslation_kld: 0.074
===> Total for class sdm1: 0.680
TOTAL: 1.362

New best dev set loss: 1.362318
Saved checkpoint for model

STARTING EPOCH 3
Train epoch 3: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.322
===> backtranslation_recon_loss: 0.363
===> autoencoding_kld: 0.090
===> backtranslation_kld: 0.086
===> Total for class ihm: 0.861
=> Class sdm1
===> autoencoding_recon_loss: 0.339
===> backtranslation_recon_loss: 0.357
===> autoencoding_kld: 0.079
===> backtranslation_kld: 0.091
===> Total for class sdm1: 0.867
TOTAL: 1.728
Train epoch 3: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.324
===> backtranslation_recon_loss: 0.366
===> autoencoding_kld: 0.092
===> backtranslation_kld: 0.086
===> Total for class ihm: 0.869
=> Class sdm1
===> autoencoding_recon_loss: 0.341
===> backtranslation_recon_loss: 0.353
===> autoencoding_kld: 0.078
===> backtranslation_kld: 0.090
===> Total for class sdm1: 0.861
TOTAL: 1.730
Train epoch 3: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.321
===> backtranslation_recon_loss: 0.365
===> autoencoding_kld: 0.090
===> backtranslation_kld: 0.083
===> Total for class ihm: 0.859
=> Class sdm1
===> autoencoding_recon_loss: 0.335
===> backtranslation_recon_loss: 0.348
===> autoencoding_kld: 0.075
===> backtranslation_kld: 0.087
===> Total for class sdm1: 0.846
TOTAL: 1.704
Train epoch 3: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.320
===> backtranslation_recon_loss: 0.363
===> autoencoding_kld: 0.088
===> backtranslation_kld: 0.082
===> Total for class ihm: 0.853
=> Class sdm1
===> autoencoding_recon_loss: 0.337
===> backtranslation_recon_loss: 0.353
===> autoencoding_kld: 0.075
===> backtranslation_kld: 0.087
===> Total for class sdm1: 0.852
TOTAL: 1.704
Train epoch 3: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.319
===> backtranslation_recon_loss: 0.363
===> autoencoding_kld: 0.088
===> backtranslation_kld: 0.082
===> Total for class ihm: 0.852
=> Class sdm1
===> autoencoding_recon_loss: 0.337
===> backtranslation_recon_loss: 0.353
===> autoencoding_kld: 0.074
===> backtranslation_kld: 0.086
===> Total for class sdm1: 0.849
TOTAL: 1.701
Train epoch 3: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.318
===> backtranslation_recon_loss: 0.363
===> autoencoding_kld: 0.087
===> backtranslation_kld: 0.082
===> Total for class ihm: 0.850
=> Class sdm1
===> autoencoding_recon_loss: 0.335
===> backtranslation_recon_loss: 0.352
===> autoencoding_kld: 0.073
===> backtranslation_kld: 0.085
===> Total for class sdm1: 0.846
TOTAL: 1.696
Train epoch 3: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.317
===> backtranslation_recon_loss: 0.362
===> autoencoding_kld: 0.086
===> backtranslation_kld: 0.081
===> Total for class ihm: 0.846
=> Class sdm1
===> autoencoding_recon_loss: 0.336
===> backtranslation_recon_loss: 0.354
===> autoencoding_kld: 0.073
===> backtranslation_kld: 0.085
===> Total for class sdm1: 0.847
TOTAL: 1.693
Train epoch 3: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.315
===> backtranslation_recon_loss: 0.360
===> autoencoding_kld: 0.085
===> backtranslation_kld: 0.080
===> Total for class ihm: 0.841
=> Class sdm1
===> autoencoding_recon_loss: 0.335
===> backtranslation_recon_loss: 0.353
===> autoencoding_kld: 0.072
===> backtranslation_kld: 0.084
===> Total for class sdm1: 0.843
TOTAL: 1.684
Train epoch 3: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.315
===> backtranslation_recon_loss: 0.361
===> autoencoding_kld: 0.085
===> backtranslation_kld: 0.080
===> Total for class ihm: 0.842
=> Class sdm1
===> autoencoding_recon_loss: 0.334
===> backtranslation_recon_loss: 0.353
===> autoencoding_kld: 0.072
===> backtranslation_kld: 0.084
===> Total for class sdm1: 0.843
TOTAL: 1.685
Train epoch 3: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.314
===> backtranslation_recon_loss: 0.360
===> autoencoding_kld: 0.085
===> backtranslation_kld: 0.080
===> Total for class ihm: 0.838
=> Class sdm1
===> autoencoding_recon_loss: 0.334
===> backtranslation_recon_loss: 0.353
===> autoencoding_kld: 0.071
===> backtranslation_kld: 0.083
===> Total for class sdm1: 0.841
TOTAL: 1.679
Train epoch 3: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.313
===> backtranslation_recon_loss: 0.360
===> autoencoding_kld: 0.084
===> backtranslation_kld: 0.080
===> Total for class ihm: 0.837
=> Class sdm1
===> autoencoding_recon_loss: 0.334
===> backtranslation_recon_loss: 0.352
===> autoencoding_kld: 0.071
===> backtranslation_kld: 0.084
===> Total for class sdm1: 0.840
TOTAL: 1.676
Train epoch 3: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.311
===> backtranslation_recon_loss: 0.358
===> autoencoding_kld: 0.083
===> backtranslation_kld: 0.079
===> Total for class ihm: 0.831
=> Class sdm1
===> autoencoding_recon_loss: 0.332
===> backtranslation_recon_loss: 0.350
===> autoencoding_kld: 0.070
===> backtranslation_kld: 0.082
===> Total for class sdm1: 0.834
TOTAL: 1.665
Train epoch 3: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.310
===> backtranslation_recon_loss: 0.357
===> autoencoding_kld: 0.083
===> backtranslation_kld: 0.078
===> Total for class ihm: 0.828
=> Class sdm1
===> autoencoding_recon_loss: 0.330
===> backtranslation_recon_loss: 0.348
===> autoencoding_kld: 0.069
===> backtranslation_kld: 0.082
===> Total for class sdm1: 0.828
TOTAL: 1.656
Train epoch 3: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.309
===> backtranslation_recon_loss: 0.357
===> autoencoding_kld: 0.082
===> backtranslation_kld: 0.077
===> Total for class ihm: 0.825
=> Class sdm1
===> autoencoding_recon_loss: 0.329
===> backtranslation_recon_loss: 0.348
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.081
===> Total for class sdm1: 0.826
TOTAL: 1.651
Train epoch 3: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.308
===> backtranslation_recon_loss: 0.357
===> autoencoding_kld: 0.082
===> backtranslation_kld: 0.077
===> Total for class ihm: 0.823
=> Class sdm1
===> autoencoding_recon_loss: 0.329
===> backtranslation_recon_loss: 0.348
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.081
===> Total for class sdm1: 0.825
TOTAL: 1.649
Train epoch 3: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.307
===> backtranslation_recon_loss: 0.356
===> autoencoding_kld: 0.081
===> backtranslation_kld: 0.076
===> Total for class ihm: 0.820
=> Class sdm1
===> autoencoding_recon_loss: 0.328
===> backtranslation_recon_loss: 0.346
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.080
===> Total for class sdm1: 0.822
TOTAL: 1.642
Train epoch 3: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.307
===> backtranslation_recon_loss: 0.356
===> autoencoding_kld: 0.080
===> backtranslation_kld: 0.076
===> Total for class ihm: 0.819
=> Class sdm1
===> autoencoding_recon_loss: 0.327
===> backtranslation_recon_loss: 0.347
===> autoencoding_kld: 0.067
===> backtranslation_kld: 0.080
===> Total for class sdm1: 0.821
TOTAL: 1.640
Train epoch 3: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.305
===> backtranslation_recon_loss: 0.355
===> autoencoding_kld: 0.080
===> backtranslation_kld: 0.075
===> Total for class ihm: 0.816
=> Class sdm1
===> autoencoding_recon_loss: 0.326
===> backtranslation_recon_loss: 0.346
===> autoencoding_kld: 0.067
===> backtranslation_kld: 0.079
===> Total for class sdm1: 0.818
TOTAL: 1.633

EPOCH 3 TRAIN (6161.109s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.305
===> backtranslation_recon_loss: 0.355
===> autoencoding_kld: 0.080
===> backtranslation_kld: 0.075
===> Total for class ihm: 0.815
=> Class sdm1
===> autoencoding_recon_loss: 0.325
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.066
===> backtranslation_kld: 0.079
===> Total for class sdm1: 0.816
TOTAL: 1.631

EPOCH 3 DEV (223.024s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.240
===> backtranslation_recon_loss: 0.294
===> autoencoding_kld: 0.065
===> backtranslation_kld: 0.061
===> Total for class ihm: 0.659
=> Class sdm1
===> autoencoding_recon_loss: 0.243
===> backtranslation_recon_loss: 0.274
===> autoencoding_kld: 0.052
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.629
TOTAL: 1.288

New best dev set loss: 1.288114
Saved checkpoint for model

STARTING EPOCH 4
Train epoch 4: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.351
===> autoencoding_kld: 0.071
===> backtranslation_kld: 0.068
===> Total for class ihm: 0.779
=> Class sdm1
===> autoencoding_recon_loss: 0.314
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.062
===> backtranslation_kld: 0.075
===> Total for class sdm1: 0.795
TOTAL: 1.573
Train epoch 4: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.285
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.069
===> backtranslation_kld: 0.065
===> Total for class ihm: 0.763
=> Class sdm1
===> autoencoding_recon_loss: 0.307
===> backtranslation_recon_loss: 0.334
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.071
===> Total for class sdm1: 0.770
TOTAL: 1.533
Train epoch 4: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.287
===> backtranslation_recon_loss: 0.347
===> autoencoding_kld: 0.070
===> backtranslation_kld: 0.066
===> Total for class ihm: 0.770
=> Class sdm1
===> autoencoding_recon_loss: 0.308
===> backtranslation_recon_loss: 0.335
===> autoencoding_kld: 0.060
===> backtranslation_kld: 0.073
===> Total for class sdm1: 0.776
TOTAL: 1.546
Train epoch 4: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.070
===> backtranslation_kld: 0.066
===> Total for class ihm: 0.766
=> Class sdm1
===> autoencoding_recon_loss: 0.309
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.060
===> backtranslation_kld: 0.072
===> Total for class sdm1: 0.779
TOTAL: 1.545
Train epoch 4: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.069
===> backtranslation_kld: 0.066
===> Total for class ihm: 0.765
=> Class sdm1
===> autoencoding_recon_loss: 0.309
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.060
===> backtranslation_kld: 0.072
===> Total for class sdm1: 0.779
TOTAL: 1.544
Train epoch 4: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.346
===> autoencoding_kld: 0.070
===> backtranslation_kld: 0.066
===> Total for class ihm: 0.767
=> Class sdm1
===> autoencoding_recon_loss: 0.309
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.072
===> Total for class sdm1: 0.778
TOTAL: 1.545
Train epoch 4: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.285
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.069
===> backtranslation_kld: 0.065
===> Total for class ihm: 0.762
=> Class sdm1
===> autoencoding_recon_loss: 0.308
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.071
===> Total for class sdm1: 0.775
TOTAL: 1.538
Train epoch 4: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.069
===> backtranslation_kld: 0.065
===> Total for class ihm: 0.760
=> Class sdm1
===> autoencoding_recon_loss: 0.308
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.070
===> Total for class sdm1: 0.775
TOTAL: 1.534
Train epoch 4: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.065
===> Total for class ihm: 0.761
=> Class sdm1
===> autoencoding_recon_loss: 0.308
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.070
===> Total for class sdm1: 0.775
TOTAL: 1.536
Train epoch 4: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.065
===> Total for class ihm: 0.759
=> Class sdm1
===> autoencoding_recon_loss: 0.308
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.070
===> Total for class sdm1: 0.773
TOTAL: 1.532
Train epoch 4: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.069
===> backtranslation_kld: 0.065
===> Total for class ihm: 0.762
=> Class sdm1
===> autoencoding_recon_loss: 0.309
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.071
===> Total for class sdm1: 0.777
TOTAL: 1.539
Train epoch 4: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.283
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.065
===> Total for class ihm: 0.759
=> Class sdm1
===> autoencoding_recon_loss: 0.307
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.070
===> Total for class sdm1: 0.773
TOTAL: 1.532
Train epoch 4: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.282
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.065
===> Total for class ihm: 0.757
=> Class sdm1
===> autoencoding_recon_loss: 0.306
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.070
===> Total for class sdm1: 0.769
TOTAL: 1.526
Train epoch 4: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.282
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.064
===> Total for class ihm: 0.756
=> Class sdm1
===> autoencoding_recon_loss: 0.305
===> backtranslation_recon_loss: 0.335
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.069
===> Total for class sdm1: 0.768
TOTAL: 1.523
Train epoch 4: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.283
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.064
===> Total for class ihm: 0.759
=> Class sdm1
===> autoencoding_recon_loss: 0.307
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.070
===> Total for class sdm1: 0.772
TOTAL: 1.531
Train epoch 4: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.283
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.064
===> Total for class ihm: 0.757
=> Class sdm1
===> autoencoding_recon_loss: 0.306
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.069
===> Total for class sdm1: 0.768
TOTAL: 1.526
Train epoch 4: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.283
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.064
===> Total for class ihm: 0.759
=> Class sdm1
===> autoencoding_recon_loss: 0.306
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.069
===> Total for class sdm1: 0.770
TOTAL: 1.529
Train epoch 4: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.282
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.068
===> backtranslation_kld: 0.064
===> Total for class ihm: 0.756
=> Class sdm1
===> autoencoding_recon_loss: 0.305
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.069
===> Total for class sdm1: 0.768
TOTAL: 1.524

EPOCH 4 TRAIN (6157.104s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.282
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.067
===> backtranslation_kld: 0.063
===> Total for class ihm: 0.755
=> Class sdm1
===> autoencoding_recon_loss: 0.304
===> backtranslation_recon_loss: 0.335
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.069
===> Total for class sdm1: 0.765
TOTAL: 1.519

EPOCH 4 DEV (224.537s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.230
===> backtranslation_recon_loss: 0.298
===> autoencoding_kld: 0.062
===> backtranslation_kld: 0.057
===> Total for class ihm: 0.647
=> Class sdm1
===> autoencoding_recon_loss: 0.235
===> backtranslation_recon_loss: 0.282
===> autoencoding_kld: 0.050
===> backtranslation_kld: 0.060
===> Total for class sdm1: 0.627
TOTAL: 1.274

New best dev set loss: 1.273886
Saved checkpoint for model

STARTING EPOCH 5
Train epoch 5: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.288
===> backtranslation_recon_loss: 0.359
===> autoencoding_kld: 0.071
===> backtranslation_kld: 0.071
===> Total for class ihm: 0.789
=> Class sdm1
===> autoencoding_recon_loss: 0.315
===> backtranslation_recon_loss: 0.359
===> autoencoding_kld: 0.065
===> backtranslation_kld: 0.088
===> Total for class sdm1: 0.827
TOTAL: 1.615
Train epoch 5: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.278
===> backtranslation_recon_loss: 0.347
===> autoencoding_kld: 0.066
===> backtranslation_kld: 0.064
===> Total for class ihm: 0.755
=> Class sdm1
===> autoencoding_recon_loss: 0.301
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.074
===> Total for class sdm1: 0.774
TOTAL: 1.529
Train epoch 5: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.276
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.065
===> backtranslation_kld: 0.062
===> Total for class ihm: 0.748
=> Class sdm1
===> autoencoding_recon_loss: 0.298
===> backtranslation_recon_loss: 0.335
===> autoencoding_kld: 0.056
===> backtranslation_kld: 0.070
===> Total for class sdm1: 0.759
TOTAL: 1.507
Train epoch 5: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.277
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.065
===> backtranslation_kld: 0.062
===> Total for class ihm: 0.748
=> Class sdm1
===> autoencoding_recon_loss: 0.302
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.071
===> Total for class sdm1: 0.770
TOTAL: 1.518
Train epoch 5: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.275
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.065
===> backtranslation_kld: 0.062
===> Total for class ihm: 0.744
=> Class sdm1
===> autoencoding_recon_loss: 0.301
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.056
===> backtranslation_kld: 0.069
===> Total for class sdm1: 0.765
TOTAL: 1.509
Train epoch 5: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.276
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.065
===> backtranslation_kld: 0.063
===> Total for class ihm: 0.749
=> Class sdm1
===> autoencoding_recon_loss: 0.303
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.070
===> Total for class sdm1: 0.772
TOTAL: 1.521
Train epoch 5: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.274
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.062
===> Total for class ihm: 0.741
=> Class sdm1
===> autoencoding_recon_loss: 0.302
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.056
===> backtranslation_kld: 0.068
===> Total for class sdm1: 0.766
TOTAL: 1.507
Train epoch 5: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.273
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.061
===> Total for class ihm: 0.737
=> Class sdm1
===> autoencoding_recon_loss: 0.301
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.056
===> backtranslation_kld: 0.067
===> Total for class sdm1: 0.763
TOTAL: 1.500
Train epoch 5: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.273
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.061
===> Total for class ihm: 0.737
=> Class sdm1
===> autoencoding_recon_loss: 0.300
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.067
===> Total for class sdm1: 0.761
TOTAL: 1.498
Train epoch 5: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.272
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.063
===> backtranslation_kld: 0.061
===> Total for class ihm: 0.734
=> Class sdm1
===> autoencoding_recon_loss: 0.300
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.066
===> Total for class sdm1: 0.758
TOTAL: 1.492
Train epoch 5: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.273
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.062
===> Total for class ihm: 0.739
=> Class sdm1
===> autoencoding_recon_loss: 0.301
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.067
===> Total for class sdm1: 0.762
TOTAL: 1.502
Train epoch 5: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.272
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.061
===> Total for class ihm: 0.736
=> Class sdm1
===> autoencoding_recon_loss: 0.300
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.066
===> Total for class sdm1: 0.757
TOTAL: 1.493
Train epoch 5: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.275
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.065
===> backtranslation_kld: 0.063
===> Total for class ihm: 0.747
=> Class sdm1
===> autoencoding_recon_loss: 0.303
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.067
===> Total for class sdm1: 0.766
TOTAL: 1.513
Train epoch 5: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.275
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.062
===> Total for class ihm: 0.744
=> Class sdm1
===> autoencoding_recon_loss: 0.302
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.067
===> Total for class sdm1: 0.763
TOTAL: 1.507
Train epoch 5: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.273
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.062
===> Total for class ihm: 0.741
=> Class sdm1
===> autoencoding_recon_loss: 0.300
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.056
===> backtranslation_kld: 0.066
===> Total for class sdm1: 0.759
TOTAL: 1.499
Train epoch 5: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.273
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.061
===> Total for class ihm: 0.740
=> Class sdm1
===> autoencoding_recon_loss: 0.299
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.056
===> backtranslation_kld: 0.066
===> Total for class sdm1: 0.757
TOTAL: 1.497
Train epoch 5: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.273
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.064
===> backtranslation_kld: 0.061
===> Total for class ihm: 0.740
=> Class sdm1
===> autoencoding_recon_loss: 0.299
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.065
===> Total for class sdm1: 0.756
TOTAL: 1.496
Train epoch 5: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.273
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.063
===> backtranslation_kld: 0.061
===> Total for class ihm: 0.738
=> Class sdm1
===> autoencoding_recon_loss: 0.299
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.065
===> Total for class sdm1: 0.754
TOTAL: 1.492

EPOCH 5 TRAIN (6166.733s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.272
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.063
===> backtranslation_kld: 0.060
===> Total for class ihm: 0.737
=> Class sdm1
===> autoencoding_recon_loss: 0.298
===> backtranslation_recon_loss: 0.335
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.065
===> Total for class sdm1: 0.752
TOTAL: 1.489

EPOCH 5 DEV (223.244s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.221
===> backtranslation_recon_loss: 0.307
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.050
===> Total for class ihm: 0.633
=> Class sdm1
===> autoencoding_recon_loss: 0.237
===> backtranslation_recon_loss: 0.285
===> autoencoding_kld: 0.045
===> backtranslation_kld: 0.056
===> Total for class sdm1: 0.623
TOTAL: 1.255

New best dev set loss: 1.255361
Saved checkpoint for model

STARTING EPOCH 6
Train epoch 6: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.267
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.062
===> backtranslation_kld: 0.058
===> Total for class ihm: 0.730
=> Class sdm1
===> autoencoding_recon_loss: 0.290
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.051
===> backtranslation_kld: 0.063
===> Total for class sdm1: 0.741
TOTAL: 1.471
Train epoch 6: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.266
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.056
===> Total for class ihm: 0.721
=> Class sdm1
===> autoencoding_recon_loss: 0.288
===> backtranslation_recon_loss: 0.332
===> autoencoding_kld: 0.050
===> backtranslation_kld: 0.060
===> Total for class sdm1: 0.730
TOTAL: 1.451
Train epoch 6: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.266
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.720
=> Class sdm1
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.329
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.724
TOTAL: 1.443
Train epoch 6: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.266
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.056
===> Total for class ihm: 0.719
=> Class sdm1
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.334
===> autoencoding_kld: 0.050
===> backtranslation_kld: 0.060
===> Total for class sdm1: 0.732
TOTAL: 1.451
Train epoch 6: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.717
=> Class sdm1
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.334
===> autoencoding_kld: 0.050
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.732
TOTAL: 1.449
Train epoch 6: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.718
=> Class sdm1
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.334
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.731
TOTAL: 1.449
Train epoch 6: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.717
=> Class sdm1
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.733
TOTAL: 1.450
Train epoch 6: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.264
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.716
=> Class sdm1
===> autoencoding_recon_loss: 0.290
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.735
TOTAL: 1.451
Train epoch 6: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.719
=> Class sdm1
===> autoencoding_recon_loss: 0.291
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.736
TOTAL: 1.455
Train epoch 6: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.264
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.716
=> Class sdm1
===> autoencoding_recon_loss: 0.290
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.735
TOTAL: 1.451
Train epoch 6: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.266
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.058
===> backtranslation_kld: 0.056
===> Total for class ihm: 0.721
=> Class sdm1
===> autoencoding_recon_loss: 0.291
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.738
TOTAL: 1.459
Train epoch 6: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.719
=> Class sdm1
===> autoencoding_recon_loss: 0.290
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.735
TOTAL: 1.454
Train epoch 6: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.264
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.717
=> Class sdm1
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.732
TOTAL: 1.450
Train epoch 6: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.342
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.719
=> Class sdm1
===> autoencoding_recon_loss: 0.290
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.733
TOTAL: 1.452
Train epoch 6: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.264
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.718
=> Class sdm1
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.058
===> Total for class sdm1: 0.732
TOTAL: 1.450
Train epoch 6: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.264
===> backtranslation_recon_loss: 0.341
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.054
===> Total for class ihm: 0.717
=> Class sdm1
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.335
===> autoencoding_kld: 0.048
===> backtranslation_kld: 0.058
===> Total for class sdm1: 0.731
TOTAL: 1.448
Train epoch 6: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.722
=> Class sdm1
===> autoencoding_recon_loss: 0.291
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.737
TOTAL: 1.459
Train epoch 6: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.721
=> Class sdm1
===> autoencoding_recon_loss: 0.290
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.735
TOTAL: 1.456

EPOCH 6 TRAIN (6158.585s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.265
===> backtranslation_recon_loss: 0.343
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.719
=> Class sdm1
===> autoencoding_recon_loss: 0.289
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.733
TOTAL: 1.452

EPOCH 6 DEV (223.464s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.209
===> backtranslation_recon_loss: 0.304
===> autoencoding_kld: 0.050
===> backtranslation_kld: 0.047
===> Total for class ihm: 0.611
=> Class sdm1
===> autoencoding_recon_loss: 0.228
===> backtranslation_recon_loss: 0.283
===> autoencoding_kld: 0.042
===> backtranslation_kld: 0.050
===> Total for class sdm1: 0.603
TOTAL: 1.214

New best dev set loss: 1.214341
Saved checkpoint for model

STARTING EPOCH 7
Train epoch 7: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.253
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.053
===> backtranslation_kld: 0.051
===> Total for class ihm: 0.694
=> Class sdm1
===> autoencoding_recon_loss: 0.280
===> backtranslation_recon_loss: 0.328
===> autoencoding_kld: 0.046
===> backtranslation_kld: 0.055
===> Total for class sdm1: 0.710
TOTAL: 1.403
Train epoch 7: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.264
===> backtranslation_recon_loss: 0.347
===> autoencoding_kld: 0.059
===> backtranslation_kld: 0.062
===> Total for class ihm: 0.732
=> Class sdm1
===> autoencoding_recon_loss: 0.290
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.051
===> backtranslation_kld: 0.059
===> Total for class sdm1: 0.740
TOTAL: 1.472
Train epoch 7: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.262
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.057
===> backtranslation_kld: 0.058
===> Total for class ihm: 0.722
=> Class sdm1
===> autoencoding_recon_loss: 0.285
===> backtranslation_recon_loss: 0.334
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.058
===> Total for class sdm1: 0.726
TOTAL: 1.447
Train epoch 7: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.262
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.056
===> backtranslation_kld: 0.057
===> Total for class ihm: 0.720
=> Class sdm1
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.730
TOTAL: 1.450
Train epoch 7: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.261
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.056
===> backtranslation_kld: 0.056
===> Total for class ihm: 0.717
=> Class sdm1
===> autoencoding_recon_loss: 0.285
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.048
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.729
TOTAL: 1.446
Train epoch 7: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.261
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.716
=> Class sdm1
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.048
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.729
TOTAL: 1.445
Train epoch 7: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.260
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.714
=> Class sdm1
===> autoencoding_recon_loss: 0.285
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.048
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.729
TOTAL: 1.443
Train epoch 7: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.261
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.055
===> Total for class ihm: 0.715
=> Class sdm1
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.058
===> Total for class sdm1: 0.733
TOTAL: 1.448
Train epoch 7: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.261
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.054
===> Total for class ihm: 0.716
=> Class sdm1
===> autoencoding_recon_loss: 0.287
===> backtranslation_recon_loss: 0.340
===> autoencoding_kld: 0.048
===> backtranslation_kld: 0.058
===> Total for class sdm1: 0.733
TOTAL: 1.448
Train epoch 7: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.260
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.054
===> Total for class ihm: 0.713
=> Class sdm1
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.339
===> autoencoding_kld: 0.048
===> backtranslation_kld: 0.058
===> Total for class sdm1: 0.730
TOTAL: 1.443
Train epoch 7: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.260
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.055
===> backtranslation_kld: 0.054
===> Total for class ihm: 0.714
=> Class sdm1
===> autoencoding_recon_loss: 0.286
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.048
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.729
TOTAL: 1.443
Train epoch 7: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.260
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.054
===> Total for class ihm: 0.711
=> Class sdm1
===> autoencoding_recon_loss: 0.285
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.047
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.726
TOTAL: 1.437
Train epoch 7: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.259
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.053
===> Total for class ihm: 0.711
=> Class sdm1
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.047
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.724
TOTAL: 1.435
Train epoch 7: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.259
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.053
===> Total for class ihm: 0.710
=> Class sdm1
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.047
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.724
TOTAL: 1.434
Train epoch 7: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.259
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.053
===> Total for class ihm: 0.710
=> Class sdm1
===> autoencoding_recon_loss: 0.283
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.047
===> backtranslation_kld: 0.056
===> Total for class sdm1: 0.722
TOTAL: 1.432
Train epoch 7: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.260
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.053
===> Total for class ihm: 0.712
=> Class sdm1
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.047
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.725
TOTAL: 1.437
Train epoch 7: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.260
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.053
===> Total for class ihm: 0.712
=> Class sdm1
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.047
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.724
TOTAL: 1.436
Train epoch 7: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.259
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.053
===> Total for class ihm: 0.711
=> Class sdm1
===> autoencoding_recon_loss: 0.284
===> backtranslation_recon_loss: 0.336
===> autoencoding_kld: 0.047
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.723
TOTAL: 1.434

EPOCH 7 TRAIN (6164.941s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.259
===> backtranslation_recon_loss: 0.345
===> autoencoding_kld: 0.054
===> backtranslation_kld: 0.052
===> Total for class ihm: 0.710
=> Class sdm1
===> autoencoding_recon_loss: 0.283
===> backtranslation_recon_loss: 0.335
===> autoencoding_kld: 0.046
===> backtranslation_kld: 0.057
===> Total for class sdm1: 0.721
TOTAL: 1.431

EPOCH 7 DEV (222.604s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.210
===> backtranslation_recon_loss: 0.307
===> autoencoding_kld: 0.049
===> backtranslation_kld: 0.046
===> Total for class ihm: 0.612
=> Class sdm1
===> autoencoding_recon_loss: 0.228
===> backtranslation_recon_loss: 0.287
===> autoencoding_kld: 0.041
===> backtranslation_kld: 0.049
===> Total for class sdm1: 0.605
TOTAL: 1.217

No improvement in 1 epochs (best dev set loss: 1.214341)
Not saving checkpoint; no improvement made

STARTING EPOCH 8
Train epoch 8: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.250
===> backtranslation_recon_loss: 0.337
===> autoencoding_kld: 0.052
===> backtranslation_kld: 0.050
===> Total for class ihm: 0.689
=> Class sdm1
===> autoencoding_recon_loss: 0.276
===> backtranslation_recon_loss: 0.327
===> autoencoding_kld: 0.044
===> backtranslation_kld: 0.053
===> Total for class sdm1: 0.700
TOTAL: 1.389
Train epoch 8: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.251
===> backtranslation_recon_loss: 0.338
===> autoencoding_kld: 0.051
===> backtranslation_kld: 0.049
===> Total for class ihm: 0.690
=> Class sdm1
===> autoencoding_recon_loss: 0.277
===> backtranslation_recon_loss: 0.329
===> autoencoding_kld: 0.044
===> backtranslation_kld: 0.053
===> Total for class sdm1: 0.703
TOTAL: 1.393
Train epoch 8: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.254
===> backtranslation_recon_loss: 0.344
===> autoencoding_kld: 0.052
===> backtranslation_kld: 0.050
===> Total for class ihm: 0.700
=> Class sdm1
===> autoencoding_recon_loss: 0.279
===> backtranslation_recon_loss: 0.331
===> autoencoding_kld: 0.045
===> backtranslation_kld: 0.054
===> Total for class sdm1: 0.708
TOTAL: 1.408
Train epoch 8: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 86.498
===> backtranslation_recon_loss: 3510181279465042.000
===> autoencoding_kld: 32254437010.283
===> backtranslation_kld: 17169964713793491566592.000
===> Total for class ihm: 17169968224007025065984.000
=> Class sdm1
===> autoencoding_recon_loss: 0.763
===> backtranslation_recon_loss: 46035743872295.680
===> autoencoding_kld: 87159883.792
===> backtranslation_kld: 550474603409096835072.000
===> Total for class sdm1: 550474649444927864832.000
TOTAL: 17720442873451953258496.000
Train epoch 8: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 7235.452
===> backtranslation_recon_loss: 2826507928884144.500
===> autoencoding_kld: 125290386038.117
===> backtranslation_kld: 67887518218168140038144.000
===> Total for class ihm: 67887521044801360232448.000
=> Class sdm1
===> autoencoding_recon_loss: 1.417
===> backtranslation_recon_loss: 37201354157531.445
===> autoencoding_kld: 463060522.807
===> backtranslation_kld: 444838065269476229120.000
===> Total for class sdm1: 444838102471293468672.000
TOTAL: 68332359147272649310208.000
Train epoch 8: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 7294.920
===> backtranslation_recon_loss: 2384424550528457.500
===> autoencoding_kld: 199946636810.811
===> backtranslation_kld: 94592953765987956555776.000
===> Total for class ihm: 94592956150612452442112.000
=> Class sdm1
===> autoencoding_recon_loss: 1.747
===> backtranslation_recon_loss: 30772720954156.719
===> autoencoding_kld: 17711141375.280
===> backtranslation_kld: 367996616748482166784.000
===> Total for class sdm1: 367996647538914230272.000
TOTAL: 94960952798151373225984.000
Train epoch 8: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 6812.625
===> backtranslation_recon_loss: 2088577386248965.750
===> autoencoding_kld: 219946180950.596
===> backtranslation_kld: 104004048086972218998784.000
===> Total for class ihm: 104004050175769551306752.000
=> Class sdm1
===> autoencoding_recon_loss: 2.030
===> backtranslation_recon_loss: 26246046733272.004
===> autoencoding_kld: 15196229550.736
===> backtranslation_kld: 313899635039634849792.000
===> Total for class sdm1: 313899661300877819904.000
TOTAL: 104317949837070424866816.000
Train epoch 8: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 5959.830
===> backtranslation_recon_loss: 1820768468249730.750
===> autoencoding_kld: 233282956328.538
===> backtranslation_kld: 104400330784784944988160.000
===> Total for class ihm: 104400332605786704314368.000
=> Class sdm1
===> autoencoding_recon_loss: 2.242
===> backtranslation_recon_loss: 23116431097067.055
===> autoencoding_kld: 13440021814.885
===> backtranslation_kld: 290570733870142554112.000
===> Total for class sdm1: 290570757000013676544.000
TOTAL: 104690903362786715238400.000
Train epoch 8: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 6588.108
===> backtranslation_recon_loss: 1627398285154915.750
===> autoencoding_kld: 214462125898.027
===> backtranslation_kld: 102074690727463715078144.000
===> Total for class ihm: 102074692355076468506624.000
=> Class sdm1
===> autoencoding_recon_loss: 2.409
===> backtranslation_recon_loss: 20446989145389.113
===> autoencoding_kld: 12148071091.659
===> backtranslation_kld: 291444601717762064384.000
===> Total for class sdm1: 291444622176899268608.000
TOTAL: 102366136977253367545856.000
Train epoch 8: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 5925.534
===> backtranslation_recon_loss: 1477060300793791.500
===> autoencoding_kld: 202263260325.753
===> backtranslation_kld: 95557479909758641111040.000
===> Total for class ihm: 95557481387021198950400.000
=> Class sdm1
===> autoencoding_recon_loss: 2.495
===> backtranslation_recon_loss: 18508506123443.078
===> autoencoding_kld: 11363610836.754
===> backtranslation_kld: 776251508114173198336.000
===> Total for class sdm1: 776251526634042949632.000
TOTAL: 96333732913655245176832.000
Train epoch 8: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 5550.765
===> backtranslation_recon_loss: 1339044675204074.000
===> autoencoding_kld: 246748177857.404
===> backtranslation_kld: 96667010537556558217216.000
===> Total for class ihm: 96667011876847989293056.000
=> Class sdm1
===> autoencoding_recon_loss: 28.284
===> backtranslation_recon_loss: 16915636321513.033
===> autoencoding_kld: 11501145689.693
===> backtranslation_kld: 3467629884297503047680.000
===> Total for class sdm1: 3467629901224640774144.000
TOTAL: 100134641778072636882944.000
Train epoch 8: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 5095.174
===> backtranslation_recon_loss: 1433362884124243.000
===> autoencoding_kld: 229912144694.782
===> backtranslation_kld: 99315011110419608633344.000
===> Total for class ihm: 99315012544012398624768.000
=> Class sdm1
===> autoencoding_recon_loss: 26.228
===> backtranslation_recon_loss: 16339763264011.172
===> autoencoding_kld: 10605955118.730
===> backtranslation_kld: 9624491081684635090944.000
===> Total for class sdm1: 9624491098035005161472.000
TOTAL: 108939503642047407980544.000
Train epoch 8: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 4708.114
===> backtranslation_recon_loss: 1328226420474525.000
===> autoencoding_kld: 239503629589.483
===> backtranslation_kld: 105581541443303454539776.000
===> Total for class ihm: 105581542771769386991616.000
=> Class sdm1
===> autoencoding_recon_loss: 24.496
===> backtranslation_recon_loss: 15263611245897.752
===> autoencoding_kld: 9787959336.462
===> backtranslation_kld: 15125451223400806612992.000
===> Total for class sdm1: 15125451238674205245440.000
TOTAL: 120706994010443590139904.000
Train epoch 8: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 4395.039
===> backtranslation_recon_loss: 1238488065634521.000
===> autoencoding_kld: 239869855599.547
===> backtranslation_kld: 109556066541862628884480.000
===> Total for class ihm: 109556067780590571618304.000
=> Class sdm1
===> autoencoding_recon_loss: 22.949
===> backtranslation_recon_loss: 15596289530550.426
===> autoencoding_kld: 9057904843.251
===> backtranslation_kld: 19423566663025506123776.000
===> Total for class sdm1: 19423566678630854557696.000
TOTAL: 128979634459221426176000.000
Train epoch 8: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 4097.914
===> backtranslation_recon_loss: 1154425473151807.750
===> autoencoding_kld: 231553137231.531
===> backtranslation_kld: 113251499380923726561280.000
===> Total for class ihm: 113251500535580754706432.000
=> Class sdm1
===> autoencoding_recon_loss: 21.698
===> backtranslation_recon_loss: 14643482014437.465
===> autoencoding_kld: 8511396979.589
===> backtranslation_kld: 21853284874179213000704.000
===> Total for class sdm1: 21853284888831204524032.000
TOTAL: 135104785424411963424768.000
Train epoch 8: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3841.871
===> backtranslation_recon_loss: 1117504875681383.750
===> autoencoding_kld: 241530657997.676
===> backtranslation_kld: 117948381483998927388672.000
===> Total for class ihm: 117948382601745325359104.000
=> Class sdm1
===> autoencoding_recon_loss: 20.579
===> backtranslation_recon_loss: 14994626820242.119
===> autoencoding_kld: 8114525201.822
===> backtranslation_kld: 23492249123133052682240.000
===> Total for class sdm1: 23492249138135792877568.000
TOTAL: 141440631739881109848064.000
Train epoch 8: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3619.572
===> backtranslation_recon_loss: 1052999669708870.000
===> autoencoding_kld: 232119344261.091
===> backtranslation_kld: 121409211861425266360320.000
===> Total for class ihm: 121409212914657061240832.000
=> Class sdm1
===> autoencoding_recon_loss: 19.568
===> backtranslation_recon_loss: 14099186507738.121
===> autoencoding_kld: 7648970164.783
===> backtranslation_kld: 23010720494905435619328.000
===> Total for class sdm1: 23010720509012272480256.000
TOTAL: 144419933423669329526784.000
Train epoch 8: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3429.234
===> backtranslation_recon_loss: 1013665120135219.000
===> autoencoding_kld: 222938314772.863
===> backtranslation_kld: 128287702897479596900352.000
===> Total for class ihm: 128287703911367662632960.000
=> Class sdm1
===> autoencoding_recon_loss: 18.662
===> backtranslation_recon_loss: 35958779508066.625
===> autoencoding_kld: 7219700533.884
===> backtranslation_kld: 23259947632420259364864.000
===> Total for class sdm1: 23259947668386256781312.000
TOTAL: 151547651579753915219968.000

EPOCH 8 TRAIN (6165.184s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3286.836
===> backtranslation_recon_loss: 971553491400325.375
===> autoencoding_kld: 219260417400.722
===> backtranslation_kld: 133112296981548096290816.000
===> Total for class ihm: 133112297953320853569536.000
=> Class sdm1
===> autoencoding_recon_loss: 17.998
===> backtranslation_recon_loss: 39352646371196.016
===> autoencoding_kld: 7136811303.968
===> backtranslation_kld: 23914755358561644052480.000
===> Total for class sdm1: 23914755397921428996096.000
TOTAL: 157027053351242278371328.000

EPOCH 8 DEV (222.318s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 5.061
===> backtranslation_recon_loss: 4.239
===> autoencoding_kld: 27283179268.257
===> backtranslation_kld: 199815640294287334178816.000
===> Total for class ihm: 199815640294314613932032.000
=> Class sdm1
===> autoencoding_recon_loss: 3.893
===> backtranslation_recon_loss: 4.135
===> autoencoding_kld: 366866507.690
===> backtranslation_kld: 38147848955037069869056.000
===> Total for class sdm1: 38147848955037438967808.000
TOTAL: 237963489249352069677056.000

No improvement in 2 epochs (best dev set loss: 1.214341)
Not saving checkpoint; no improvement made

STARTING EPOCH 9
Train epoch 9: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 4.790
===> backtranslation_recon_loss: 23638400409.939
===> autoencoding_kld: 232732107987.506
===> backtranslation_kld: 167854266702470418792448.000
===> Total for class ihm: 167854266702726774652928.000
=> Class sdm1
===> autoencoding_recon_loss: 3.736
===> backtranslation_recon_loss: 64626136385592.812
===> autoencoding_kld: 42015880295.097
===> backtranslation_kld: 41722785367609617416192.000
===> Total for class sdm1: 41722785432277765586944.000
TOTAL: 209577052135004557017088.000
Train epoch 9: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 12.270
===> backtranslation_recon_loss: 2345805875637.889
===> autoencoding_kld: 425608150026.243
===> backtranslation_kld: 160950150720374339272704.000
===> Total for class ihm: 160950150723145767583744.000
=> Class sdm1
===> autoencoding_recon_loss: 3.774
===> backtranslation_recon_loss: 49408532411303.016
===> autoencoding_kld: 20959178568.618
===> backtranslation_kld: 41137285057513829433344.000
===> Total for class sdm1: 41137285106943324585984.000
TOTAL: 202087435830089092169728.000
Train epoch 9: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 9.799
===> backtranslation_recon_loss: 2197474043466.398
===> autoencoding_kld: 309846081437.535
===> backtranslation_kld: 169576319847452882501632.000
===> Total for class ihm: 169576319849960203878400.000
=> Class sdm1
===> autoencoding_recon_loss: 3.876
===> backtranslation_recon_loss: 46619728134627.492
===> autoencoding_kld: 472121795859845.188
===> backtranslation_kld: 60757065211952062529536.000
===> Total for class sdm1: 60757065730693590417408.000
TOTAL: 230333385580653785907200.000
Train epoch 9: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 8.336
===> backtranslation_recon_loss: 6051696627667.952
===> autoencoding_kld: 242835030527.324
===> backtranslation_kld: 182278646120896597590016.000
===> Total for class ihm: 182278646127191140597760.000
=> Class sdm1
===> autoencoding_recon_loss: 3.973
===> backtranslation_recon_loss: 62061399275265.641
===> autoencoding_kld: 356935506145483.312
===> backtranslation_kld: 69839825842802312347648.000
===> Total for class sdm1: 69839826261799214252032.000
TOTAL: 252118472388990363238400.000
Train epoch 9: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 7.605
===> backtranslation_recon_loss: 7480475838948.637
===> autoencoding_kld: 204621825906.954
===> backtranslation_kld: 182275162208146064146432.000
===> Total for class ihm: 182275162215831169925120.000
=> Class sdm1
===> autoencoding_recon_loss: 4.109
===> backtranslation_recon_loss: 52026588595513.367
===> autoencoding_kld: 286009417016289.000
===> backtranslation_kld: 63325901913663343689728.000
===> Total for class sdm1: 63325902251699348701184.000
TOTAL: 245601064467530501849088.000
Train epoch 9: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 8.018
===> backtranslation_recon_loss: 7392779927461.998
===> autoencoding_kld: 176275913117.528
===> backtranslation_kld: 187108736360478924603392.000
===> Total for class ihm: 187108736368047965601792.000
=> Class sdm1
===> autoencoding_recon_loss: 4.097
===> backtranslation_recon_loss: 44074716235570.117
===> autoencoding_kld: 239158915892877.688
===> backtranslation_kld: 68998603355332385177600.000
===> Total for class sdm1: 68998603638566016778240.000
TOTAL: 256107340006613973991424.000
Train epoch 9: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 7.587
===> backtranslation_recon_loss: 13486596927589.029
===> autoencoding_kld: 156136596490.419
===> backtranslation_kld: 186538482690475281088512.000
===> Total for class ihm: 186538482704118009823232.000
=> Class sdm1
===> autoencoding_recon_loss: 4.134
===> backtranslation_recon_loss: 44126726151900.414
===> autoencoding_kld: 203380856149521.031
===> backtranslation_kld: 70262578059960674942976.000
===> Total for class sdm1: 70262578307468256870400.000
TOTAL: 256801061011586291859456.000
Train epoch 9: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 14.061
===> backtranslation_recon_loss: 14392714380463.973
===> autoencoding_kld: 143372787318.808
===> backtranslation_kld: 187688334990218188816384.000
===> Total for class ihm: 187688335004754270748672.000
=> Class sdm1
===> autoencoding_recon_loss: 4.162
===> backtranslation_recon_loss: 39494671340687.531
===> autoencoding_kld: 176914534927851.281
===> backtranslation_kld: 75953727210715544027136.000
===> Total for class sdm1: 75953727427124752547840.000
TOTAL: 263642062431879040073728.000
Train epoch 9: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.372
===> backtranslation_recon_loss: 12966625266640.799
===> autoencoding_kld: 128981777752.493
===> backtranslation_kld: 198210005269906186043392.000
===> Total for class ihm: 198210005283001809764352.000
=> Class sdm1
===> autoencoding_recon_loss: 4.174
===> backtranslation_recon_loss: 36361496530351.320
===> autoencoding_kld: 158180109949817.375
===> backtranslation_kld: 80845161650919089111040.000
===> Total for class sdm1: 80845161845460689747968.000
TOTAL: 279055167128462533066752.000
Train epoch 9: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 16.110
===> backtranslation_recon_loss: 12315696889073.820
===> autoencoding_kld: 117475134404.713
===> backtranslation_kld: 203342187324654238040064.000
===> Total for class ihm: 203342187337087396610048.000
=> Class sdm1
===> autoencoding_recon_loss: 4.162
===> backtranslation_recon_loss: 36533589459645.281
===> autoencoding_kld: 142517493101507.219
===> backtranslation_kld: 89972652985722444185600.000
===> Total for class sdm1: 89972653164773523849216.000
TOTAL: 293314840501860937236480.000
Train epoch 9: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.124
===> backtranslation_recon_loss: 13691900638199.414
===> autoencoding_kld: 114964742539.558
===> backtranslation_kld: 206548733051470532837376.000
===> Total for class ihm: 206548733065277409853440.000
=> Class sdm1
===> autoencoding_recon_loss: 4.175
===> backtranslation_recon_loss: 33320010984587.594
===> autoencoding_kld: 129464927510880.188
===> backtranslation_kld: 99369877974540544376832.000
===> Total for class sdm1: 99369878137325475594240.000
TOTAL: 305918611202602952556544.000
Train epoch 9: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 14.521
===> backtranslation_recon_loss: 12680949276917.832
===> autoencoding_kld: 108880225439.599
===> backtranslation_kld: 210967576551329472970752.000
===> Total for class ihm: 210967576564119315152896.000
=> Class sdm1
===> autoencoding_recon_loss: 4.158
===> backtranslation_recon_loss: 30496062599071.895
===> autoencoding_kld: 118464126191524.531
===> backtranslation_kld: 106666421396122873364480.000
===> Total for class sdm1: 106666421545083059830784.000
TOTAL: 317633998109202358206464.000
Train epoch 9: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 13.840
===> backtranslation_recon_loss: 11741219736258.186
===> autoencoding_kld: 104884237171.386
===> backtranslation_kld: 216132733774867348848640.000
===> Total for class ihm: 216132733786713439076352.000
=> Class sdm1
===> autoencoding_recon_loss: 4.158
===> backtranslation_recon_loss: 28423968180656.512
===> autoencoding_kld: 109421619883725.703
===> backtranslation_kld: 112993387126673551392768.000
===> Total for class sdm1: 112993387264519134248960.000
TOTAL: 329126121051232573325312.000
Train epoch 9: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 170.380
===> backtranslation_recon_loss: 10966726026414.887
===> autoencoding_kld: 109430926576.252
===> backtranslation_kld: 221351949859276590153728.000
===> Total for class ihm: 221351949870352740384768.000
=> Class sdm1
===> autoencoding_recon_loss: 4.171
===> backtranslation_recon_loss: 26332064772302.113
===> autoencoding_kld: 101314047625553.156
===> backtranslation_kld: 118722826280115279757312.000
===> Total for class sdm1: 118722826407761389027328.000
TOTAL: 340074776278114146189312.000
Train epoch 9: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3722.341
===> backtranslation_recon_loss: 13040134567456.455
===> autoencoding_kld: 104836804009.349
===> backtranslation_kld: 226752295121258205413376.000
===> Total for class ihm: 226752295134403187703808.000
=> Class sdm1
===> autoencoding_recon_loss: 4.174
===> backtranslation_recon_loss: 25227783410461.344
===> autoencoding_kld: 94727153370524.141
===> backtranslation_kld: 125139965230683487469568.000
===> Total for class sdm1: 125139965350638417608704.000
TOTAL: 351892260485041605312512.000
Train epoch 9: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3593.128
===> backtranslation_recon_loss: 12228682599406.012
===> autoencoding_kld: 108561393414.877
===> backtranslation_kld: 231913217561807655272448.000
===> Total for class ihm: 231913217574144915275776.000
=> Class sdm1
===> autoencoding_recon_loss: 4.169
===> backtranslation_recon_loss: 28268361628340.613
===> autoencoding_kld: 88811199032206.281
===> backtranslation_kld: 132385144846780693741568.000
===> Total for class sdm1: 132385144963860260716544.000
TOTAL: 364298362538005209546752.000
Train epoch 9: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3378.321
===> backtranslation_recon_loss: 63936581468923.141
===> autoencoding_kld: 103991304352.867
===> backtranslation_kld: 236587877443001418514432.000
===> Total for class ihm: 236587877507041998143488.000
=> Class sdm1
===> autoencoding_recon_loss: 5.381
===> backtranslation_recon_loss: 30395268731529.953
===> autoencoding_kld: 83689088074350.766
===> backtranslation_kld: 138617885080357806538752.000
===> Total for class sdm1: 138617885194442170695680.000
TOTAL: 375205762701484152061952.000
Train epoch 9: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3196.901
===> backtranslation_recon_loss: 93420836712259.812
===> autoencoding_kld: 98927077598.822
===> backtranslation_kld: 240923672583601756569600.000
===> Total for class ihm: 240923672677121515323392.000
=> Class sdm1
===> autoencoding_recon_loss: 5.313
===> backtranslation_recon_loss: 28699511351753.555
===> autoencoding_kld: 79020063499352.234
===> backtranslation_kld: 143935878164461438107648.000
===> Total for class sdm1: 143935878272181013053440.000
TOTAL: 384859550949302545154048.000

EPOCH 9 TRAIN (6160.826s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 3060.921
===> backtranslation_recon_loss: 89437011972896.391
===> autoencoding_kld: 95574296743.223
===> backtranslation_kld: 243782895145548668469248.000
===> Total for class ihm: 243782895235081254731776.000
=> Class sdm1
===> autoencoding_recon_loss: 5.259
===> backtranslation_recon_loss: 29571556452575.312
===> autoencoding_kld: 75617043146582.219
===> backtranslation_kld: 148347648650593030897664.000
===> Total for class sdm1: 148347648755781628592128.000
TOTAL: 392130543990862866546688.000

EPOCH 9 DEV (223.065s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 6.370
===> backtranslation_recon_loss: 4.078
===> autoencoding_kld: 7384474571.036
===> backtranslation_kld: 314511346767530769252352.000
===> Total for class ihm: 314511346767538151227392.000
=> Class sdm1
===> autoencoding_recon_loss: 4.294
===> backtranslation_recon_loss: 4.139
===> autoencoding_kld: 95875898.104
===> backtranslation_kld: 218296514335111561347072.000
===> Total for class sdm1: 218296514335111662010368.000
TOTAL: 532807861102649779683328.000

No improvement in 3 epochs (best dev set loss: 1.214341)
STOPPING EARLY
Computing reconstruction loss...
Loaded checkpoint; best model ready now.

TRAINING SET
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.199
===> backtranslation_recon_loss: 0.298
===> Total for class ihm: 0.497
=> Class sdm1
===> autoencoding_recon_loss: 0.187
===> backtranslation_recon_loss: 0.293
===> Total for class sdm1: 0.480
TOTAL: 0.976

DEV SET
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.203
===> backtranslation_recon_loss: 0.304
===> Total for class ihm: 0.508
=> Class sdm1
===> autoencoding_recon_loss: 0.181
===> backtranslation_recon_loss: 0.283
===> Total for class sdm1: 0.464
TOTAL: 0.972

Completed training run in 59450.882 seconds
