Setting up environment...
Environment set up.
Training convolutional variational multidecoder...
Constructing model...
Done constructing model.
CNNVariationalMultidecoder (
  (encoder_conv): Sequential (
    (conv2d_0): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_0): SELU
    (maxpool2d_0): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_1): SELU
    (maxpool2d_1): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential (
    (lin_0): Linear (14336 -> 2048)
    (SELU_0): SELU
  )
  (decoder_fc_ihm): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (SELU_0): SELU
    (lin_final): Linear (2048 -> 14336)
    (SELU_final): SELU
  )
  (decoder_deconv_ihm): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (decoder_fc_sdm1): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (SELU_0): SELU
    (lin_final): Linear (2048 -> 14336)
    (SELU_final): SELU
  )
  (decoder_deconv_sdm1): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (latent_mu): Sequential (
    (lin): Linear (2048 -> 1024)
    (SELU): SELU
  )
  (latent_logvar): Sequential (
    (lin): Linear (2048 -> 1024)
    (SELU): SELU
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 0.684185
Train epoch 1: [2000/18806 (10.6%)]	Loss: 0.628405
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.584658
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.559896
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.571441
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.549774
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.535592
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.521461
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.520583
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.510393
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.505381
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.499205
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.493732
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.507495
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.500853
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.494041
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.488998
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.486828
====> Epoch 1: Average train loss 0.482725 (['ihm: 0.511283', 'sdm1: 0.454168'])
====> Dev set loss: 0.299112 (['ihm: 0.307834', 'sdm1: 0.290390'])
New best dev set loss: 0.299112
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.496317
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.450700
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.429309
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.419599
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.425400
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.417932
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.418752
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.412970
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.416614
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.411540
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.407704
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.412217
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.407807
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.404780
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.401801
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.416916
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.415223
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.411750
====> Epoch 2: Average train loss 0.408822 (['ihm: 0.437106', 'sdm1: 0.380539'])
====> Dev set loss: 0.268795 (['ihm: 0.278231', 'sdm1: 0.259358'])
New best dev set loss: 0.268795
Saved checkpoint for model
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.344897
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.346694
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.391544
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.382427
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.375729
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.368875
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.368692
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.363060
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.360578
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.357013
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.358027
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.355067
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.352135
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.356522
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.353990
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.351675
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.350105
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.349939
====> Epoch 3: Average train loss 0.348230 (['ihm: 0.367027', 'sdm1: 0.329432'])
====> Dev set loss: 0.254586 (['ihm: 0.264230', 'sdm1: 0.244942'])
New best dev set loss: 0.254586
Saved checkpoint for model
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.323858
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.332659
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.325621
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.323846
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.377436
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.367322
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.358827
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.351565
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.346822
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.342423
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.340072
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.339110
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.335599
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.336439
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.334258
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.334242
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.332418
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.330409
====> Epoch 4: Average train loss 0.329212 (['ihm: 0.341482', 'sdm1: 0.316943'])
====> Dev set loss: 0.258503 (['ihm: 0.270525', 'sdm1: 0.246482'])
No improvement in 1 epochs (best dev set loss: 0.254586)
Not saving checkpoint; no improvement made
Train epoch 5: [1000/18806 (5.3%)]	Loss: 0.311434
Train epoch 5: [2000/18806 (10.6%)]	Loss: 0.307849
Train epoch 5: [3000/18806 (16.0%)]	Loss: 0.308698
Train epoch 5: [4000/18806 (21.3%)]	Loss: 0.307220
Train epoch 5: [5000/18806 (26.6%)]	Loss: 0.310569
Train epoch 5: [6000/18806 (31.9%)]	Loss: 0.307500
Train epoch 5: [7000/18806 (37.2%)]	Loss: 0.305321
Train epoch 5: [8000/18806 (42.5%)]	Loss: 0.308511
Train epoch 5: [9000/18806 (47.9%)]	Loss: 0.307761
Train epoch 5: [10000/18806 (53.2%)]	Loss: 0.306525
Train epoch 5: [11000/18806 (58.5%)]	Loss: 0.305587
Train epoch 5: [12000/18806 (63.8%)]	Loss: 0.305542
Train epoch 5: [13000/18806 (69.1%)]	Loss: 0.304069
Train epoch 5: [14000/18806 (74.4%)]	Loss: 0.304409
Train epoch 5: [15000/18806 (79.8%)]	Loss: 0.305779
Train epoch 5: [16000/18806 (85.1%)]	Loss: 0.304860
Train epoch 5: [17000/18806 (90.4%)]	Loss: 0.304612
Train epoch 5: [18000/18806 (95.7%)]	Loss: 0.303845
====> Epoch 5: Average train loss 0.303314 (['ihm: 0.316195', 'sdm1: 0.290432'])
====> Dev set loss: 0.267545 (['ihm: 0.282489', 'sdm1: 0.252600'])
No improvement in 2 epochs (best dev set loss: 0.254586)
Not saving checkpoint; no improvement made
Train epoch 6: [1000/18806 (5.3%)]	Loss: 0.300517
Train epoch 6: [2000/18806 (10.6%)]	Loss: 0.301209
Train epoch 6: [3000/18806 (16.0%)]	Loss: 0.300038
Train epoch 6: [4000/18806 (21.3%)]	Loss: 0.301317
Train epoch 6: [5000/18806 (26.6%)]	Loss: 0.309658
Train epoch 6: [6000/18806 (31.9%)]	Loss: 0.305987
Train epoch 6: [7000/18806 (37.2%)]	Loss: 0.303198
Train epoch 6: [8000/18806 (42.5%)]	Loss: 0.301988
Train epoch 6: [9000/18806 (47.9%)]	Loss: 0.300643
Train epoch 6: [10000/18806 (53.2%)]	Loss: 0.299922
Train epoch 6: [11000/18806 (58.5%)]	Loss: 0.300295
Train epoch 6: [12000/18806 (63.8%)]	Loss: 0.299668
Train epoch 6: [13000/18806 (69.1%)]	Loss: 0.298193
Train epoch 6: [14000/18806 (74.4%)]	Loss: 0.300454
Train epoch 6: [15000/18806 (79.8%)]	Loss: 0.299811
Train epoch 6: [16000/18806 (85.1%)]	Loss: 0.298706
Train epoch 6: [17000/18806 (90.4%)]	Loss: 0.298137
Train epoch 6: [18000/18806 (95.7%)]	Loss: 0.297339
====> Epoch 6: Average train loss 0.296898 (['ihm: 0.310651', 'sdm1: 0.283146'])
====> Dev set loss: 0.258989 (['ihm: 0.271634', 'sdm1: 0.246343'])
No improvement in 3 epochs (best dev set loss: 0.254586)
STOPPING EARLY
Computing reconstruction loss...
Loaded checkpoint; best model ready now.
====> Training set reconstruction loss: 0.256562 (['ihm: 0.261040', 'sdm1: 0.252084'])
====> Dev set reconstruction loss: 0.254586 (['ihm: 0.264230', 'sdm1: 0.244942'])
Trained convolutional variational multidecoder.
