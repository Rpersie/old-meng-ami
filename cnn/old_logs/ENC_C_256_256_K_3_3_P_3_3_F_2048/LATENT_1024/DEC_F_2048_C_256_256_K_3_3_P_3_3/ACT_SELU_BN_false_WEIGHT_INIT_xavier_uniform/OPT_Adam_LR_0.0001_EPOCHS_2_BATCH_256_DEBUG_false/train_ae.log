Running training with mode ae
Profiling code using cProfile
Noising 25.000% of input features
Constructing model...
Done constructing model.
CNNMultidecoder(
  (encoder_conv): Sequential(
    (conv2d_0): Conv2d (1, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_0): SELU
    (maxpool2d_0): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_1): SELU
    (maxpool2d_1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential(
    (lin_0): Linear(in_features=14336, out_features=2048)
    (SELU_0): SELU
    (lin_final): Linear(in_features=2048, out_features=1024)
    (SELU_final): SELU
  )
  (decoder_fc_ihm): Sequential(
    (lin_0): Linear(in_features=1024, out_features=2048)
    (SELU_0): SELU
    (lin_final): Linear(in_features=2048, out_features=14336)
    (SELU_final): SELU
  )
  (decoder_deconv_ihm): Sequential(
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (decoder_fc_sdm1): Sequential(
    (lin_0): Linear(in_features=1024, out_features=2048)
    (SELU_0): SELU
    (lin_final): Linear(in_features=2048, out_features=14336)
    (SELU_final): SELU
  )
  (decoder_deconv_sdm1): Sequential(
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
)
Model has 96185090 trainable parameters
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Completed setup in 176.802 seconds
Starting training!

STARTING EPOCH 1
Train epoch 1: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.335
===> backtranslation_recon_loss: 0.360
===> Total for class ihm: 0.696
=> Class sdm1
===> autoencoding_recon_loss: 0.338
===> backtranslation_recon_loss: 0.388
===> Total for class sdm1: 0.726
TOTAL: 1.421
Train epoch 1: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.242
===> backtranslation_recon_loss: 0.259
===> Total for class ihm: 0.501
=> Class sdm1
===> autoencoding_recon_loss: 0.260
===> backtranslation_recon_loss: 0.297
===> Total for class sdm1: 0.557
TOTAL: 1.058
Train epoch 1: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.203
===> backtranslation_recon_loss: 0.216
===> Total for class ihm: 0.418
=> Class sdm1
===> autoencoding_recon_loss: 0.226
===> backtranslation_recon_loss: 0.255
===> Total for class sdm1: 0.482
TOTAL: 0.900
Train epoch 1: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.178
===> backtranslation_recon_loss: 0.186
===> Total for class ihm: 0.364
=> Class sdm1
===> autoencoding_recon_loss: 0.203
===> backtranslation_recon_loss: 0.225
===> Total for class sdm1: 0.428
TOTAL: 0.793
Train epoch 1: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.163
===> backtranslation_recon_loss: 0.168
===> Total for class ihm: 0.330
=> Class sdm1
===> autoencoding_recon_loss: 0.190
===> backtranslation_recon_loss: 0.207
===> Total for class sdm1: 0.397
TOTAL: 0.728
Train epoch 1: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.151
===> backtranslation_recon_loss: 0.154
===> Total for class ihm: 0.305
=> Class sdm1
===> autoencoding_recon_loss: 0.179
===> backtranslation_recon_loss: 0.192
===> Total for class sdm1: 0.371
TOTAL: 0.676
Train epoch 1: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.142
===> backtranslation_recon_loss: 0.141
===> Total for class ihm: 0.283
=> Class sdm1
===> autoencoding_recon_loss: 0.169
===> backtranslation_recon_loss: 0.178
===> Total for class sdm1: 0.347
TOTAL: 0.630
Train epoch 1: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.134
===> backtranslation_recon_loss: 0.132
===> Total for class ihm: 0.266
=> Class sdm1
===> autoencoding_recon_loss: 0.161
===> backtranslation_recon_loss: 0.167
===> Total for class sdm1: 0.328
TOTAL: 0.594
Train epoch 1: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.128
===> backtranslation_recon_loss: 0.124
===> Total for class ihm: 0.251
=> Class sdm1
===> autoencoding_recon_loss: 0.154
===> backtranslation_recon_loss: 0.158
===> Total for class sdm1: 0.312
TOTAL: 0.564
Train epoch 1: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.122
===> backtranslation_recon_loss: 0.117
===> Total for class ihm: 0.238
=> Class sdm1
===> autoencoding_recon_loss: 0.149
===> backtranslation_recon_loss: 0.150
===> Total for class sdm1: 0.299
TOTAL: 0.537
Train epoch 1: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.111
===> Total for class ihm: 0.228
=> Class sdm1
===> autoencoding_recon_loss: 0.144
===> backtranslation_recon_loss: 0.144
===> Total for class sdm1: 0.288
TOTAL: 0.516
Train epoch 1: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.113
===> backtranslation_recon_loss: 0.106
===> Total for class ihm: 0.218
=> Class sdm1
===> autoencoding_recon_loss: 0.140
===> backtranslation_recon_loss: 0.138
===> Total for class sdm1: 0.277
TOTAL: 0.496
Train epoch 1: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.109
===> backtranslation_recon_loss: 0.101
===> Total for class ihm: 0.211
=> Class sdm1
===> autoencoding_recon_loss: 0.136
===> backtranslation_recon_loss: 0.133
===> Total for class sdm1: 0.269
TOTAL: 0.480
Train epoch 1: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.106
===> backtranslation_recon_loss: 0.097
===> Total for class ihm: 0.203
=> Class sdm1
===> autoencoding_recon_loss: 0.133
===> backtranslation_recon_loss: 0.129
===> Total for class sdm1: 0.261
TOTAL: 0.464
Train epoch 1: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.103
===> backtranslation_recon_loss: 0.094
===> Total for class ihm: 0.196
=> Class sdm1
===> autoencoding_recon_loss: 0.129
===> backtranslation_recon_loss: 0.124
===> Total for class sdm1: 0.253
TOTAL: 0.450
Train epoch 1: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.100
===> backtranslation_recon_loss: 0.091
===> Total for class ihm: 0.191
=> Class sdm1
===> autoencoding_recon_loss: 0.126
===> backtranslation_recon_loss: 0.120
===> Total for class sdm1: 0.247
TOTAL: 0.438
Train epoch 1: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.098
===> backtranslation_recon_loss: 0.088
===> Total for class ihm: 0.186
=> Class sdm1
===> autoencoding_recon_loss: 0.124
===> backtranslation_recon_loss: 0.117
===> Total for class sdm1: 0.241
TOTAL: 0.426
Train epoch 1: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.095
===> backtranslation_recon_loss: 0.086
===> Total for class ihm: 0.181
=> Class sdm1
===> autoencoding_recon_loss: 0.121
===> backtranslation_recon_loss: 0.114
===> Total for class sdm1: 0.236
TOTAL: 0.416

EPOCH 1 TRAIN (5820.495s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.094
===> backtranslation_recon_loss: 0.084
===> Total for class ihm: 0.178
=> Class sdm1
===> autoencoding_recon_loss: 0.120
===> backtranslation_recon_loss: 0.112
===> Total for class sdm1: 0.232
TOTAL: 0.410

EPOCH 1 DEV (192.294s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.055
===> backtranslation_recon_loss: 0.038
===> Total for class ihm: 0.093
=> Class sdm1
===> autoencoding_recon_loss: 0.079
===> backtranslation_recon_loss: 0.057
===> Total for class sdm1: 0.137
TOTAL: 0.229

New best dev set loss: 0.229258
Saved checkpoint for model

STARTING EPOCH 2
Train epoch 2: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.053
===> backtranslation_recon_loss: 0.038
===> Total for class ihm: 0.090
=> Class sdm1
===> autoencoding_recon_loss: 0.077
===> backtranslation_recon_loss: 0.057
===> Total for class sdm1: 0.134
TOTAL: 0.224
Train epoch 2: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.054
===> backtranslation_recon_loss: 0.040
===> Total for class ihm: 0.094
=> Class sdm1
===> autoencoding_recon_loss: 0.080
===> backtranslation_recon_loss: 0.061
===> Total for class sdm1: 0.140
TOTAL: 0.235
Train epoch 2: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.053
===> backtranslation_recon_loss: 0.039
===> Total for class ihm: 0.092
=> Class sdm1
===> autoencoding_recon_loss: 0.079
===> backtranslation_recon_loss: 0.060
===> Total for class sdm1: 0.139
TOTAL: 0.231
Train epoch 2: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.053
===> backtranslation_recon_loss: 0.039
===> Total for class ihm: 0.092
=> Class sdm1
===> autoencoding_recon_loss: 0.078
===> backtranslation_recon_loss: 0.059
===> Total for class sdm1: 0.137
TOTAL: 0.229
Train epoch 2: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.054
===> backtranslation_recon_loss: 0.041
===> Total for class ihm: 0.095
=> Class sdm1
===> autoencoding_recon_loss: 0.080
===> backtranslation_recon_loss: 0.062
===> Total for class sdm1: 0.143
TOTAL: 0.238
Train epoch 2: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.053
===> backtranslation_recon_loss: 0.040
===> Total for class ihm: 0.093
=> Class sdm1
===> autoencoding_recon_loss: 0.079
===> backtranslation_recon_loss: 0.061
===> Total for class sdm1: 0.140
TOTAL: 0.233
Train epoch 2: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.053
===> backtranslation_recon_loss: 0.039
===> Total for class ihm: 0.092
=> Class sdm1
===> autoencoding_recon_loss: 0.078
===> backtranslation_recon_loss: 0.060
===> Total for class sdm1: 0.138
TOTAL: 0.230
Train epoch 2: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.052
===> backtranslation_recon_loss: 0.038
===> Total for class ihm: 0.090
=> Class sdm1
===> autoencoding_recon_loss: 0.078
===> backtranslation_recon_loss: 0.059
===> Total for class sdm1: 0.137
TOTAL: 0.227
Train epoch 2: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.051
===> backtranslation_recon_loss: 0.038
===> Total for class ihm: 0.090
=> Class sdm1
===> autoencoding_recon_loss: 0.077
===> backtranslation_recon_loss: 0.058
===> Total for class sdm1: 0.136
TOTAL: 0.225
Train epoch 2: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.051
===> backtranslation_recon_loss: 0.038
===> Total for class ihm: 0.089
=> Class sdm1
===> autoencoding_recon_loss: 0.077
===> backtranslation_recon_loss: 0.058
===> Total for class sdm1: 0.135
TOTAL: 0.224
Train epoch 2: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.051
===> backtranslation_recon_loss: 0.038
===> Total for class ihm: 0.089
=> Class sdm1
===> autoencoding_recon_loss: 0.076
===> backtranslation_recon_loss: 0.058
===> Total for class sdm1: 0.134
TOTAL: 0.223
Train epoch 2: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.051
===> backtranslation_recon_loss: 0.037
===> Total for class ihm: 0.088
=> Class sdm1
===> autoencoding_recon_loss: 0.076
===> backtranslation_recon_loss: 0.057
===> Total for class sdm1: 0.133
TOTAL: 0.221
Train epoch 2: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.050
===> backtranslation_recon_loss: 0.037
===> Total for class ihm: 0.087
=> Class sdm1
===> autoencoding_recon_loss: 0.076
===> backtranslation_recon_loss: 0.057
===> Total for class sdm1: 0.132
TOTAL: 0.219
Train epoch 2: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.050
===> backtranslation_recon_loss: 0.037
===> Total for class ihm: 0.087
=> Class sdm1
===> autoencoding_recon_loss: 0.075
===> backtranslation_recon_loss: 0.057
===> Total for class sdm1: 0.132
TOTAL: 0.219
Train epoch 2: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.050
===> backtranslation_recon_loss: 0.037
===> Total for class ihm: 0.086
=> Class sdm1
===> autoencoding_recon_loss: 0.075
===> backtranslation_recon_loss: 0.056
===> Total for class sdm1: 0.131
TOTAL: 0.217
Train epoch 2: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.049
===> backtranslation_recon_loss: 0.036
===> Total for class ihm: 0.086
=> Class sdm1
===> autoencoding_recon_loss: 0.075
===> backtranslation_recon_loss: 0.056
===> Total for class sdm1: 0.130
TOTAL: 0.216
Train epoch 2: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.049
===> backtranslation_recon_loss: 0.036
===> Total for class ihm: 0.085
=> Class sdm1
===> autoencoding_recon_loss: 0.074
===> backtranslation_recon_loss: 0.055
===> Total for class sdm1: 0.129
TOTAL: 0.215
Train epoch 2: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.049
===> backtranslation_recon_loss: 0.036
===> Total for class ihm: 0.086
=> Class sdm1
===> autoencoding_recon_loss: 0.074
===> backtranslation_recon_loss: 0.055
===> Total for class sdm1: 0.130
TOTAL: 0.215

EPOCH 2 TRAIN (5819.384s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.049
===> backtranslation_recon_loss: 0.036
===> Total for class ihm: 0.085
=> Class sdm1
===> autoencoding_recon_loss: 0.074
===> backtranslation_recon_loss: 0.055
===> Total for class sdm1: 0.129
TOTAL: 0.215

EPOCH 2 DEV (192.944s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.100
===> backtranslation_recon_loss: 0.100
===> Total for class ihm: 0.201
=> Class sdm1
===> autoencoding_recon_loss: 0.141
===> backtranslation_recon_loss: 0.089
===> Total for class sdm1: 0.230
TOTAL: 0.431

No improvement in 1 epochs (best dev set loss: 0.229258)
Not saving checkpoint; no improvement made
Computing reconstruction loss...
Loaded checkpoint; best model ready now.

TRAINING SET
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.050
===> backtranslation_recon_loss: 0.037
===> Total for class ihm: 0.087
=> Class sdm1
===> autoencoding_recon_loss: 0.043
===> backtranslation_recon_loss: 0.058
===> Total for class sdm1: 0.101
TOTAL: 0.188

DEV SET
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.049
===> backtranslation_recon_loss: 0.038
===> Total for class ihm: 0.086
=> Class sdm1
===> autoencoding_recon_loss: 0.042
===> backtranslation_recon_loss: 0.057
===> Total for class sdm1: 0.099
TOTAL: 0.185

Completed training run in 14175.563 seconds
