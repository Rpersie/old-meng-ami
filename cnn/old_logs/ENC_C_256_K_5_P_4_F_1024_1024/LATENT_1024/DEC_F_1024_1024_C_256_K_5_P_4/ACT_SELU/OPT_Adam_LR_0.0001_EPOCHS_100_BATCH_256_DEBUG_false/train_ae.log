Setting up environment...
Environment set up.
Training convolutional multidecoder...
Constructing model...
Done constructing model.
CNNMultidecoder (
  (encoder_conv): Sequential (
    (conv2d_0): Conv2d(1, 256, kernel_size=(5, 5), stride=(1, 1))
    (batchnorm2d_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (SELU_0): SELU
    (maxpool2d_0): MaxPool2d (size=(1, 4), stride=(1, 4), dilation=(1, 1))
  )
  (encoder_fc): Sequential (
    (lin_0): Linear (34048 -> 1024)
    (SELU_0): SELU
    (lin_1): Linear (1024 -> 1024)
    (SELU_1): SELU
    (lin_final): Linear (1024 -> 1024)
  )
  (decoder_fc_ihm): Sequential (
    (lin_0): Linear (1024 -> 1024)
    (SELU_0): SELU
    (lin_1): Linear (1024 -> 1024)
    (SELU_1): SELU
    (lin_final): Linear (1024 -> 34048)
  )
  (decoder_deconv_ihm): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 4), stride=(1, 4), padding=(0, 0))
    (conv2d_0): Conv2d(256, 1, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))
    (batchnorm2d_0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True)
    (SELU_0): SELU
  )
  (decoder_fc_sdm1): Sequential (
    (lin_0): Linear (1024 -> 1024)
    (SELU_0): SELU
    (lin_1): Linear (1024 -> 1024)
    (SELU_1): SELU
    (lin_final): Linear (1024 -> 34048)
  )
  (decoder_deconv_sdm1): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 4), stride=(1, 4), padding=(0, 0))
    (conv2d_0): Conv2d(256, 1, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))
    (batchnorm2d_0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True)
    (SELU_0): SELU
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 0.665267
Train epoch 1: [2000/18806 (10.6%)]	Loss: 0.575277
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.537661
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.487765
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.438367
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.397567
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.364649
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.338136
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.323100
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.325764
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.366997
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.396920
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.426123
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.449444
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.470126
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.488950
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.473815
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.458288
====> Epoch 1: Average train loss 0.443487
====> Dev set loss: 0.048055
New best dev set loss: 0.048055
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.554122
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.487306
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.423122
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.379399
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.335176
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.301007
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.270664
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.249656
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.241401
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.244706
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.282063
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.308596
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.336436
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.361031
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.379732
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.399023
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.390584
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.379991
====> Epoch 2: Average train loss 0.368268
====> Dev set loss: 0.055935
No improvement in 1 epochs (best dev set loss: 0.048055)
Not saving checkpoint; no improvement made
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.568250
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.495346
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.426715
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.380286
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.335938
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.300642
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.269677
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.247639
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.238675
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.240301
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.271623
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.294559
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.319968
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.341816
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.360264
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.376931
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.368730
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.358785
====> Epoch 3: Average train loss 0.347786
====> Dev set loss: 0.055926
No improvement in 2 epochs (best dev set loss: 0.048055)
Not saving checkpoint; no improvement made
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.538295
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.470428
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.401025
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.358511
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.316201
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.282324
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.252987
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.232487
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.223802
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.224383
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.252640
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.272579
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.295468
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.315132
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.332994
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.348483
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.341618
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.331699
====> Epoch 4: Average train loss 0.321469
====> Dev set loss: 0.051459
No improvement in 3 epochs (best dev set loss: 0.048055)
STOPPING EARLY
Trained convolutional multidecoder.
