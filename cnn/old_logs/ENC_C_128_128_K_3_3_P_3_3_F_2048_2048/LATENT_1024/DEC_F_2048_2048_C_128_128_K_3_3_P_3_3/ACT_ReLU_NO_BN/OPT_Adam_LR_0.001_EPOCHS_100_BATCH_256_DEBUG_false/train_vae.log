Setting up environment...
Environment set up.
Training convolutional variational multidecoder...
Constructing model...
Done constructing model.
CNNVariationalMultidecoder (
  (encoder_conv): Sequential (
    (conv2d_0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1))
    (ReLU_0): ReLU ()
    (maxpool2d_0): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (ReLU_1): ReLU ()
    (maxpool2d_1): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential (
    (lin_0): Linear (7168 -> 2048)
    (ReLU_0): ReLU ()
    (lin_1): Linear (2048 -> 2048)
    (ReLU_1): ReLU ()
  )
  (latent_mu): Sequential (
    (lin): Linear (2048 -> 1024)
    (ReLU): ReLU ()
  )
  (latent_logvar): Sequential (
    (lin): Linear (2048 -> 1024)
    (ReLU): ReLU ()
  )
  (decoder_fc_ihm): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (ReLU_0): ReLU ()
    (lin_1): Linear (2048 -> 2048)
    (ReLU_1): ReLU ()
    (lin_final): Linear (2048 -> 7168)
    (ReLU_final): ReLU ()
  )
  (decoder_deconv_ihm): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (ReLU_0): ReLU ()
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (ReLU_1): ReLU ()
  )
  (decoder_fc_sdm1): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (ReLU_0): ReLU ()
    (lin_1): Linear (2048 -> 2048)
    (ReLU_1): ReLU ()
    (lin_final): Linear (2048 -> 7168)
    (ReLU_final): ReLU ()
  )
  (decoder_deconv_sdm1): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (ReLU_0): ReLU ()
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (ReLU_1): ReLU ()
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 0.989950
Train epoch 1: [2000/18806 (10.6%)]	Loss: 0.947907
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.947609
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.926164
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.900074
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.870364
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.844849
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.824975
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.824802
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.801718
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.773944
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.755146
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.735675
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.717149
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.705107
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.699637
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.693075
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.685964
====> Epoch 1: Average train loss 0.680183
====> Dev set loss: 0.685030
New best dev set loss: 0.685030
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.962335
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.930703
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.930928
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.910612
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.881830
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.853300
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.827616
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.808150
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.808833
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.787097
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.760166
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.742085
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.724330
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.712618
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.703062
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.701117
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.693877
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.686235
====> Epoch 2: Average train loss 0.679803
====> Dev set loss: 0.689870
No improvement in 1 epochs (best dev set loss: 0.685030)
Not saving checkpoint; no improvement made
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.965700
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.930019
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.928115
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.908184
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.879529
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.850706
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.824249
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.804364
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.804960
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.783168
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.754436
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.734907
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.715097
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.701366
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.693700
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.691470
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.684251
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.676525
====> Epoch 3: Average train loss 0.670259
====> Dev set loss: 0.701144
No improvement in 2 epochs (best dev set loss: 0.685030)
Not saving checkpoint; no improvement made
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.962477
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.927776
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.923535
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.903828
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.878368
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.848344
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.822231
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.802909
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.803624
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.782118
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.753695
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.733975
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.714018
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.700232
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.693320
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.690939
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.683790
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.675937
====> Epoch 4: Average train loss 0.669571
====> Dev set loss: 0.725103
No improvement in 3 epochs (best dev set loss: 0.685030)
STOPPING EARLY
Computing reconstruction loss...
Loaded checkpoint; best model ready now.
====> Training set reconstruction loss: 0.731226
====> Dev set reconstruction loss: 0.685030
Trained convolutional variational multidecoder.
