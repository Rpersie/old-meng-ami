Setting up environment...
Environment set up.
Training convolutional multidecoder...
Constructing model...
Done constructing model.
CNNMultidecoder (
  (encoder_conv): Sequential (
    (conv2d_0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1))
    (batchnorm2d_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_0): Tanh ()
    (maxpool2d_0): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (batchnorm2d_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_1): Tanh ()
    (maxpool2d_1): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential (
    (lin_0): Linear (7168 -> 2048)
    (batchnorm1d_0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_0): Tanh ()
    (lin_1): Linear (2048 -> 2048)
    (batchnorm1d_1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_1): Tanh ()
    (lin_final): Linear (2048 -> 1024)
    (Tanh_final): Tanh ()
  )
  (decoder_fc_ihm): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (batchnorm1d_0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_0): Tanh ()
    (lin_1): Linear (2048 -> 2048)
    (batchnorm1d_1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_1): Tanh ()
    (lin_final): Linear (2048 -> 7168)
    (Tanh_final): Tanh ()
  )
  (decoder_deconv_ihm): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (batchnorm2d_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_0): Tanh ()
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (batchnorm2d_1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_1): Tanh ()
  )
  (decoder_fc_sdm1): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (batchnorm1d_0): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_0): Tanh ()
    (lin_1): Linear (2048 -> 2048)
    (batchnorm1d_1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_1): Tanh ()
    (lin_final): Linear (2048 -> 7168)
    (Tanh_final): Tanh ()
  )
  (decoder_deconv_sdm1): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (batchnorm2d_0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_0): Tanh ()
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (batchnorm2d_1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True)
    (Tanh_1): Tanh ()
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 0.594659
Train epoch 1: [2000/18806 (10.6%)]	Loss: 0.540695
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.513626
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.500331
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.489688
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.479349
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.468381
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.461529
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.457196
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.450695
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.445932
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.441218
Train epoch 1: [13000/18806 (69.1%)]	Loss: 0.438922
Train epoch 1: [14000/18806 (74.4%)]	Loss: 0.433343
Train epoch 1: [15000/18806 (79.8%)]	Loss: 0.430668
Train epoch 1: [16000/18806 (85.1%)]	Loss: 0.426860
Train epoch 1: [17000/18806 (90.4%)]	Loss: 0.422988
Train epoch 1: [18000/18806 (95.7%)]	Loss: 0.419556
====> Epoch 1: Average train loss 0.417427
====> Dev set loss: 0.333083
New best dev set loss: 0.333083
Saved checkpoint for model
Train epoch 2: [1000/18806 (5.3%)]	Loss: 0.341209
Train epoch 2: [2000/18806 (10.6%)]	Loss: 0.330273
Train epoch 2: [3000/18806 (16.0%)]	Loss: 0.327224
Train epoch 2: [4000/18806 (21.3%)]	Loss: 0.327607
Train epoch 2: [5000/18806 (26.6%)]	Loss: 0.327195
Train epoch 2: [6000/18806 (31.9%)]	Loss: 0.324766
Train epoch 2: [7000/18806 (37.2%)]	Loss: 0.321616
Train epoch 2: [8000/18806 (42.5%)]	Loss: 0.319600
Train epoch 2: [9000/18806 (47.9%)]	Loss: 0.319077
Train epoch 2: [10000/18806 (53.2%)]	Loss: 0.316746
Train epoch 2: [11000/18806 (58.5%)]	Loss: 0.315484
Train epoch 2: [12000/18806 (63.8%)]	Loss: 0.313596
Train epoch 2: [13000/18806 (69.1%)]	Loss: 0.313481
Train epoch 2: [14000/18806 (74.4%)]	Loss: 0.310770
Train epoch 2: [15000/18806 (79.8%)]	Loss: 0.310573
Train epoch 2: [16000/18806 (85.1%)]	Loss: 0.309318
Train epoch 2: [17000/18806 (90.4%)]	Loss: 0.307958
Train epoch 2: [18000/18806 (95.7%)]	Loss: 0.306738
====> Epoch 2: Average train loss 0.306293
====> Dev set loss: 0.343065
No improvement in 1 epochs (best dev set loss: 0.333083)
Not saving checkpoint; no improvement made
Train epoch 3: [1000/18806 (5.3%)]	Loss: 0.276266
Train epoch 3: [2000/18806 (10.6%)]	Loss: 0.267877
Train epoch 3: [3000/18806 (16.0%)]	Loss: 0.266327
Train epoch 3: [4000/18806 (21.3%)]	Loss: 0.267116
Train epoch 3: [5000/18806 (26.6%)]	Loss: 0.267634
Train epoch 3: [6000/18806 (31.9%)]	Loss: 0.266699
Train epoch 3: [7000/18806 (37.2%)]	Loss: 0.264174
Train epoch 3: [8000/18806 (42.5%)]	Loss: 0.263355
Train epoch 3: [9000/18806 (47.9%)]	Loss: 0.263952
Train epoch 3: [10000/18806 (53.2%)]	Loss: 0.262669
Train epoch 3: [11000/18806 (58.5%)]	Loss: 0.262194
Train epoch 3: [12000/18806 (63.8%)]	Loss: 0.261462
Train epoch 3: [13000/18806 (69.1%)]	Loss: 0.261717
Train epoch 3: [14000/18806 (74.4%)]	Loss: 0.260183
Train epoch 3: [15000/18806 (79.8%)]	Loss: 0.260694
Train epoch 3: [16000/18806 (85.1%)]	Loss: 0.260253
Train epoch 3: [17000/18806 (90.4%)]	Loss: 0.259565
Train epoch 3: [18000/18806 (95.7%)]	Loss: 0.259088
====> Epoch 3: Average train loss 0.259221
====> Dev set loss: 0.263366
New best dev set loss: 0.263366
Saved checkpoint for model
Train epoch 4: [1000/18806 (5.3%)]	Loss: 0.248167
Train epoch 4: [2000/18806 (10.6%)]	Loss: 0.238044
Train epoch 4: [3000/18806 (16.0%)]	Loss: 0.238053
Train epoch 4: [4000/18806 (21.3%)]	Loss: 0.239402
Train epoch 4: [5000/18806 (26.6%)]	Loss: 0.239194
Train epoch 4: [6000/18806 (31.9%)]	Loss: 0.238054
Train epoch 4: [7000/18806 (37.2%)]	Loss: 0.236377
Train epoch 4: [8000/18806 (42.5%)]	Loss: 0.235960
Train epoch 4: [9000/18806 (47.9%)]	Loss: 0.236564
Train epoch 4: [10000/18806 (53.2%)]	Loss: 0.235739
Train epoch 4: [11000/18806 (58.5%)]	Loss: 0.235565
Train epoch 4: [12000/18806 (63.8%)]	Loss: 0.234890
Train epoch 4: [13000/18806 (69.1%)]	Loss: 0.235626
Train epoch 4: [14000/18806 (74.4%)]	Loss: 0.234324
Train epoch 4: [15000/18806 (79.8%)]	Loss: 0.235156
Train epoch 4: [16000/18806 (85.1%)]	Loss: 0.235136
Train epoch 4: [17000/18806 (90.4%)]	Loss: 0.234645
Train epoch 4: [18000/18806 (95.7%)]	Loss: 0.234616
====> Epoch 4: Average train loss 0.234799
====> Dev set loss: 0.327046
No improvement in 1 epochs (best dev set loss: 0.263366)
Not saving checkpoint; no improvement made
Train epoch 5: [1000/18806 (5.3%)]	Loss: 0.224781
Train epoch 5: [2000/18806 (10.6%)]	Loss: 0.217856
Train epoch 5: [3000/18806 (16.0%)]	Loss: 0.219006
Train epoch 5: [4000/18806 (21.3%)]	Loss: 0.219857
Train epoch 5: [5000/18806 (26.6%)]	Loss: 0.220881
Train epoch 5: [6000/18806 (31.9%)]	Loss: 0.219977
Train epoch 5: [7000/18806 (37.2%)]	Loss: 0.218367
Train epoch 5: [8000/18806 (42.5%)]	Loss: 0.219011
Train epoch 5: [9000/18806 (47.9%)]	Loss: 0.218958
Train epoch 5: [10000/18806 (53.2%)]	Loss: 0.218508
Train epoch 5: [11000/18806 (58.5%)]	Loss: 0.218402
Train epoch 5: [12000/18806 (63.8%)]	Loss: 0.218009
Train epoch 5: [13000/18806 (69.1%)]	Loss: 0.218887
Train epoch 5: [14000/18806 (74.4%)]	Loss: 0.217772
Train epoch 5: [15000/18806 (79.8%)]	Loss: 0.218710
Train epoch 5: [16000/18806 (85.1%)]	Loss: 0.218902
Train epoch 5: [17000/18806 (90.4%)]	Loss: 0.218629
Train epoch 5: [18000/18806 (95.7%)]	Loss: 0.218620
====> Epoch 5: Average train loss 0.218930
====> Dev set loss: 0.288386
No improvement in 2 epochs (best dev set loss: 0.263366)
Not saving checkpoint; no improvement made
Train epoch 6: [1000/18806 (5.3%)]	Loss: 0.212399
Train epoch 6: [2000/18806 (10.6%)]	Loss: 0.205966
Train epoch 6: [3000/18806 (16.0%)]	Loss: 0.205157
Train epoch 6: [4000/18806 (21.3%)]	Loss: 0.206457
Train epoch 6: [5000/18806 (26.6%)]	Loss: 0.207825
Train epoch 6: [6000/18806 (31.9%)]	Loss: 0.206897
Train epoch 6: [7000/18806 (37.2%)]	Loss: 0.205619
Train epoch 6: [8000/18806 (42.5%)]	Loss: 0.206229
Train epoch 6: [9000/18806 (47.9%)]	Loss: 0.206039
Train epoch 6: [10000/18806 (53.2%)]	Loss: 0.205769
Train epoch 6: [11000/18806 (58.5%)]	Loss: 0.205578
Train epoch 6: [12000/18806 (63.8%)]	Loss: 0.205499
Train epoch 6: [13000/18806 (69.1%)]	Loss: 0.205991
Train epoch 6: [14000/18806 (74.4%)]	Loss: 0.205466
Train epoch 6: [15000/18806 (79.8%)]	Loss: 0.206080
Train epoch 6: [16000/18806 (85.1%)]	Loss: 0.206391
Train epoch 6: [17000/18806 (90.4%)]	Loss: 0.206147
Train epoch 6: [18000/18806 (95.7%)]	Loss: 0.206197
====> Epoch 6: Average train loss 0.206496
====> Dev set loss: 0.293980
No improvement in 3 epochs (best dev set loss: 0.263366)
STOPPING EARLY
Computing reconstruction loss...
Loaded checkpoint; best model ready now.
====> Training set reconstruction loss: 0.263320
====> Dev set reconstruction loss: 0.263366
Trained convolutional multidecoder.
