Setting up environment...
Environment set up.
Training convolutional multidecoder...
Constructing model...
Done constructing model.
CNNMultidecoder (
  (encoder_conv): Sequential (
    (conv2d_0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1))
    (Tanh_0): Tanh ()
    (maxpool2d_0): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))
    (Tanh_1): Tanh ()
    (maxpool2d_1): MaxPool2d (size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential (
    (lin_0): Linear (7168 -> 2048)
    (Tanh_0): Tanh ()
    (lin_1): Linear (2048 -> 2048)
    (Tanh_1): Tanh ()
    (lin_final): Linear (2048 -> 1024)
    (Tanh_final): Tanh ()
  )
  (decoder_fc_ihm): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (Tanh_0): Tanh ()
    (lin_1): Linear (2048 -> 2048)
    (Tanh_1): Tanh ()
    (lin_final): Linear (2048 -> 7168)
    (Tanh_final): Tanh ()
  )
  (decoder_deconv_ihm): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (Tanh_0): Tanh ()
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (Tanh_1): Tanh ()
  )
  (decoder_fc_sdm1): Sequential (
    (lin_0): Linear (1024 -> 2048)
    (Tanh_0): Tanh ()
    (lin_1): Linear (2048 -> 2048)
    (Tanh_1): Tanh ()
    (lin_final): Linear (2048 -> 7168)
    (Tanh_final): Tanh ()
  )
  (decoder_deconv_sdm1): Sequential (
    (maxunpool2d_0): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (Tanh_0): Tanh ()
    (maxunpool2d_1): MaxUnpool2d (size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d(128, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (Tanh_1): Tanh ()
  )
)
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Starting training!
Train epoch 1: [1000/18806 (5.3%)]	Loss: 0.954659
Train epoch 1: [2000/18806 (10.6%)]	Loss: 0.881684
Train epoch 1: [3000/18806 (16.0%)]	Loss: 0.884671
Train epoch 1: [4000/18806 (21.3%)]	Loss: 0.854054
Train epoch 1: [5000/18806 (26.6%)]	Loss: 0.827618
Train epoch 1: [6000/18806 (31.9%)]	Loss: 0.800669
Train epoch 1: [7000/18806 (37.2%)]	Loss: 0.784749
Train epoch 1: [8000/18806 (42.5%)]	Loss: 0.767149
Train epoch 1: [9000/18806 (47.9%)]	Loss: 0.755979
Train epoch 1: [10000/18806 (53.2%)]	Loss: 0.764184
Train epoch 1: [11000/18806 (58.5%)]	Loss: 0.810513
Train epoch 1: [12000/18806 (63.8%)]	Loss: 0.845371
