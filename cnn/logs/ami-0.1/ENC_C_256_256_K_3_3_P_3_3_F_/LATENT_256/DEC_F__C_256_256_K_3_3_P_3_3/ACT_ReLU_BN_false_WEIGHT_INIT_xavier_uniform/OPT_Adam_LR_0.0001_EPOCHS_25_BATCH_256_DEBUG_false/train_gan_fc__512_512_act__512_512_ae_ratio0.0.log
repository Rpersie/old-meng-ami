Running training with mode ae
Using generative adversarial loss
Noising 0.000% of input features
Constructing model...
Done constructing model.
CNNGANMultidecoder(
  (encoder_conv): Sequential(
    (conv2d_0): Conv2d (1, 256, kernel_size=(3, 3), stride=(1, 1))
    (ReLU_0): ReLU()
    (maxpool2d_0): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
    (ReLU_1): ReLU()
    (maxpool2d_1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential(
    (lin_final): Linear(in_features=14336, out_features=256)
    (ReLU_final): ReLU()
  )
  (decoder_fc_ihm): Sequential(
    (ReLU_final): ReLU()
    (lin_final): Linear(in_features=256, out_features=14336)
  )
  (decoder_deconv_ihm): Sequential(
    (ReLU_0): ReLU()
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (ReLU_1): ReLU()
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
  )
  (decoder_fc_sdm1): Sequential(
    (ReLU_final): ReLU()
    (lin_final): Linear(in_features=256, out_features=14336)
  )
  (decoder_deconv_sdm1): Sequential(
    (ReLU_0): ReLU()
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (ReLU_1): ReLU()
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
  )
  (gan_ihm): Sequential(
    (lin_0): Linear(in_features=880, out_features=512)
    (Sigmoid_0): Sigmoid()
    (lin_1): Linear(in_features=512, out_features=512)
    (Sigmoid_1): Sigmoid()
    (lin_final): Linear(in_features=512, out_features=1)
    (Sigmoid_final): Sigmoid()
  )
  (gan_sdm1): Sequential(
    (lin_0): Linear(in_features=880, out_features=512)
    (Sigmoid_0): Sigmoid()
    (lin_1): Linear(in_features=512, out_features=512)
    (Sigmoid_1): Sigmoid()
    (lin_final): Linear(in_features=512, out_features=1)
    (Sigmoid_final): Sigmoid()
  )
)
Model has 14244868 trainable parameters
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Completed setup in 182.381 seconds
Starting training!

STARTING EPOCH 1
GENERATOR Train epoch 1: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 435.626
===> backtranslation_recon_loss: 506.944
===> gan_loss: -1.384
===> Total for class ihm: 941.186
=> Class sdm1
===> autoencoding_recon_loss: 431.667
===> backtranslation_recon_loss: 484.757
===> gan_loss: -1.373
===> Total for class sdm1: 915.051
TOTAL: 1856.237
GENERATOR Train epoch 1: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 268.042
===> backtranslation_recon_loss: 331.389
===> gan_loss: -1.382
===> Total for class ihm: 598.049
=> Class sdm1
===> autoencoding_recon_loss: 281.127
===> backtranslation_recon_loss: 342.622
===> gan_loss: -1.376
===> Total for class sdm1: 622.373
TOTAL: 1220.422
GENERATOR Train epoch 1: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 199.669
===> backtranslation_recon_loss: 255.071
===> gan_loss: -1.380
===> Total for class ihm: 453.361
=> Class sdm1
===> autoencoding_recon_loss: 213.998
===> backtranslation_recon_loss: 274.582
===> gan_loss: -1.376
===> Total for class sdm1: 487.204
TOTAL: 940.564
GENERATOR Train epoch 1: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 162.643
===> backtranslation_recon_loss: 212.309
===> gan_loss: -1.377
===> Total for class ihm: 373.574
=> Class sdm1
===> autoencoding_recon_loss: 176.662
===> backtranslation_recon_loss: 234.743
===> gan_loss: -1.373
===> Total for class sdm1: 410.032
TOTAL: 783.606
GENERATOR Train epoch 1: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 138.607
===> backtranslation_recon_loss: 184.214
===> gan_loss: -1.372
===> Total for class ihm: 321.449
=> Class sdm1
===> autoencoding_recon_loss: 153.229
===> backtranslation_recon_loss: 208.828
===> gan_loss: -1.371
===> Total for class sdm1: 360.687
TOTAL: 682.135
GENERATOR Train epoch 1: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 121.897
===> backtranslation_recon_loss: 164.115
===> gan_loss: -1.362
===> Total for class ihm: 284.650
=> Class sdm1
===> autoencoding_recon_loss: 136.247
===> backtranslation_recon_loss: 189.701
===> gan_loss: -1.368
===> Total for class sdm1: 324.580
TOTAL: 609.230
GENERATOR Train epoch 1: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 110.080
===> backtranslation_recon_loss: 149.832
===> gan_loss: -1.351
===> Total for class ihm: 258.560
=> Class sdm1
===> autoencoding_recon_loss: 123.887
===> backtranslation_recon_loss: 175.566
===> gan_loss: -1.363
===> Total for class sdm1: 298.090
TOTAL: 556.650
GENERATOR Train epoch 1: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 100.744
===> backtranslation_recon_loss: 138.405
===> gan_loss: -1.339
===> Total for class ihm: 237.810
=> Class sdm1
===> autoencoding_recon_loss: 113.541
===> backtranslation_recon_loss: 163.378
===> gan_loss: -1.356
===> Total for class sdm1: 275.564
TOTAL: 513.374
GENERATOR Train epoch 1: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 93.053
===> backtranslation_recon_loss: 128.829
===> gan_loss: -1.331
===> Total for class ihm: 220.552
=> Class sdm1
===> autoencoding_recon_loss: 105.572
===> backtranslation_recon_loss: 153.843
===> gan_loss: -1.348
===> Total for class sdm1: 258.067
TOTAL: 478.619
GENERATOR Train epoch 1: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 86.602
===> backtranslation_recon_loss: 120.754
===> gan_loss: -1.323
===> Total for class ihm: 206.032
=> Class sdm1
===> autoencoding_recon_loss: 99.231
===> backtranslation_recon_loss: 146.063
===> gan_loss: -1.339
===> Total for class sdm1: 243.954
TOTAL: 449.987
GENERATOR Train epoch 1: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 81.055
===> backtranslation_recon_loss: 113.739
===> gan_loss: -1.318
===> Total for class ihm: 193.476
=> Class sdm1
===> autoencoding_recon_loss: 93.819
===> backtranslation_recon_loss: 139.352
===> gan_loss: -1.334
===> Total for class sdm1: 231.836
TOTAL: 425.312
GENERATOR Train epoch 1: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 76.331
===> backtranslation_recon_loss: 107.687
===> gan_loss: -1.314
===> Total for class ihm: 182.704
=> Class sdm1
===> autoencoding_recon_loss: 88.887
===> backtranslation_recon_loss: 133.086
===> gan_loss: -1.328
===> Total for class sdm1: 220.646
TOTAL: 403.350
GENERATOR Train epoch 1: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 72.776
===> backtranslation_recon_loss: 103.069
===> gan_loss: -1.311
===> Total for class ihm: 174.534
=> Class sdm1
===> autoencoding_recon_loss: 84.869
===> backtranslation_recon_loss: 127.873
===> gan_loss: -1.323
===> Total for class sdm1: 211.419
TOTAL: 385.953
GENERATOR Train epoch 1: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 69.314
===> backtranslation_recon_loss: 98.638
===> gan_loss: -1.308
===> Total for class ihm: 166.644
=> Class sdm1
===> autoencoding_recon_loss: 81.288
===> backtranslation_recon_loss: 123.273
===> gan_loss: -1.318
===> Total for class sdm1: 203.243
TOTAL: 369.886
GENERATOR Train epoch 1: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 66.467
===> backtranslation_recon_loss: 94.988
===> gan_loss: -1.306
===> Total for class ihm: 160.150
=> Class sdm1
===> autoencoding_recon_loss: 77.866
===> backtranslation_recon_loss: 118.792
===> gan_loss: -1.313
===> Total for class sdm1: 195.345
TOTAL: 355.495
GENERATOR Train epoch 1: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 63.923
===> backtranslation_recon_loss: 91.685
===> gan_loss: -1.304
===> Total for class ihm: 154.304
=> Class sdm1
===> autoencoding_recon_loss: 75.006
===> backtranslation_recon_loss: 115.086
===> gan_loss: -1.309
===> Total for class sdm1: 188.784
TOTAL: 343.087
GENERATOR Train epoch 1: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.534
===> backtranslation_recon_loss: 88.577
===> gan_loss: -1.304
===> Total for class ihm: 148.808
=> Class sdm1
===> autoencoding_recon_loss: 72.527
===> backtranslation_recon_loss: 111.857
===> gan_loss: -1.304
===> Total for class sdm1: 183.079
TOTAL: 331.887
GENERATOR Train epoch 1: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.369
===> backtranslation_recon_loss: 85.741
===> gan_loss: -1.302
===> Total for class ihm: 143.808
=> Class sdm1
===> autoencoding_recon_loss: 70.121
===> backtranslation_recon_loss: 108.683
===> gan_loss: -1.300
===> Total for class sdm1: 177.504
TOTAL: 321.311

EPOCH 1 TRAIN (6873.327s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 57.848
===> backtranslation_recon_loss: 83.748
===> gan_loss: -1.301
===> Total for class ihm: 140.296
=> Class sdm1
===> autoencoding_recon_loss: 68.303
===> backtranslation_recon_loss: 106.262
===> gan_loss: -1.297
===> Total for class sdm1: 173.267
TOTAL: 313.563

EPOCH 1 DEV (145.922s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 23.628
===> backtranslation_recon_loss: 39.556
===> gan_loss: -1.330
===> Total for class ihm: 61.854
=> Class sdm1
===> autoencoding_recon_loss: 30.588
===> backtranslation_recon_loss: 55.075
===> gan_loss: -1.305
===> Total for class sdm1: 84.358
TOTAL: 146.212

New best dev set loss: 146.212162
Saved checkpoint for model

STARTING EPOCH 2
GENERATOR Train epoch 2: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 21.020
===> backtranslation_recon_loss: 35.214
===> gan_loss: -1.281
===> Total for class ihm: 54.953
=> Class sdm1
===> autoencoding_recon_loss: 28.420
===> backtranslation_recon_loss: 52.917
===> gan_loss: -1.242
===> Total for class sdm1: 80.095
TOTAL: 135.049
GENERATOR Train epoch 2: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 22.976
===> backtranslation_recon_loss: 38.371
===> gan_loss: -1.283
===> Total for class ihm: 60.064
=> Class sdm1
===> autoencoding_recon_loss: 29.913
===> backtranslation_recon_loss: 54.920
===> gan_loss: -1.243
===> Total for class sdm1: 83.591
TOTAL: 143.655
GENERATOR Train epoch 2: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 21.948
===> backtranslation_recon_loss: 36.848
===> gan_loss: -1.284
===> Total for class ihm: 57.512
=> Class sdm1
===> autoencoding_recon_loss: 29.293
===> backtranslation_recon_loss: 54.271
===> gan_loss: -1.236
===> Total for class sdm1: 82.327
TOTAL: 139.840
GENERATOR Train epoch 2: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 21.439
===> backtranslation_recon_loss: 36.067
===> gan_loss: -1.283
===> Total for class ihm: 56.223
=> Class sdm1
===> autoencoding_recon_loss: 28.526
===> backtranslation_recon_loss: 53.061
===> gan_loss: -1.241
===> Total for class sdm1: 80.346
TOTAL: 136.569
GENERATOR Train epoch 2: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 21.477
===> backtranslation_recon_loss: 36.078
===> gan_loss: -1.282
===> Total for class ihm: 56.273
=> Class sdm1
===> autoencoding_recon_loss: 28.336
===> backtranslation_recon_loss: 52.677
===> gan_loss: -1.239
===> Total for class sdm1: 79.774
TOTAL: 136.047
GENERATOR Train epoch 2: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 21.011
===> backtranslation_recon_loss: 35.345
===> gan_loss: -1.285
===> Total for class ihm: 55.071
=> Class sdm1
===> autoencoding_recon_loss: 27.992
===> backtranslation_recon_loss: 52.080
===> gan_loss: -1.236
===> Total for class sdm1: 78.836
TOTAL: 133.907
GENERATOR Train epoch 2: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 20.786
===> backtranslation_recon_loss: 35.004
===> gan_loss: -1.285
===> Total for class ihm: 54.504
=> Class sdm1
===> autoencoding_recon_loss: 27.806
===> backtranslation_recon_loss: 51.727
===> gan_loss: -1.235
===> Total for class sdm1: 78.298
TOTAL: 132.802
GENERATOR Train epoch 2: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 20.517
===> backtranslation_recon_loss: 34.528
===> gan_loss: -1.285
===> Total for class ihm: 53.760
=> Class sdm1
===> autoencoding_recon_loss: 27.442
===> backtranslation_recon_loss: 51.110
===> gan_loss: -1.234
===> Total for class sdm1: 77.318
TOTAL: 131.078
GENERATOR Train epoch 2: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 20.274
===> backtranslation_recon_loss: 34.133
===> gan_loss: -1.286
===> Total for class ihm: 53.121
=> Class sdm1
===> autoencoding_recon_loss: 27.210
===> backtranslation_recon_loss: 50.729
===> gan_loss: -1.234
===> Total for class sdm1: 76.705
TOTAL: 129.826
GENERATOR Train epoch 2: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 20.011
===> backtranslation_recon_loss: 33.691
===> gan_loss: -1.287
===> Total for class ihm: 52.414
=> Class sdm1
===> autoencoding_recon_loss: 26.953
===> backtranslation_recon_loss: 50.279
===> gan_loss: -1.233
===> Total for class sdm1: 75.999
TOTAL: 128.413
GENERATOR Train epoch 2: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 19.752
===> backtranslation_recon_loss: 33.250
===> gan_loss: -1.288
===> Total for class ihm: 51.714
=> Class sdm1
===> autoencoding_recon_loss: 26.721
===> backtranslation_recon_loss: 49.863
===> gan_loss: -1.234
===> Total for class sdm1: 75.350
TOTAL: 127.064
GENERATOR Train epoch 2: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 19.608
===> backtranslation_recon_loss: 33.066
===> gan_loss: -1.288
===> Total for class ihm: 51.385
=> Class sdm1
===> autoencoding_recon_loss: 26.638
===> backtranslation_recon_loss: 49.600
===> gan_loss: -1.233
===> Total for class sdm1: 75.005
TOTAL: 126.390
GENERATOR Train epoch 2: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 19.420
===> backtranslation_recon_loss: 32.769
===> gan_loss: -1.288
===> Total for class ihm: 50.901
=> Class sdm1
===> autoencoding_recon_loss: 26.368
===> backtranslation_recon_loss: 49.154
===> gan_loss: -1.232
===> Total for class sdm1: 74.290
TOTAL: 125.191
GENERATOR Train epoch 2: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 19.255
===> backtranslation_recon_loss: 32.506
===> gan_loss: -1.289
===> Total for class ihm: 50.472
=> Class sdm1
===> autoencoding_recon_loss: 26.108
===> backtranslation_recon_loss: 48.704
===> gan_loss: -1.232
===> Total for class sdm1: 73.580
TOTAL: 124.052
GENERATOR Train epoch 2: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 19.042
===> backtranslation_recon_loss: 32.184
===> gan_loss: -1.289
===> Total for class ihm: 49.937
=> Class sdm1
===> autoencoding_recon_loss: 25.897
===> backtranslation_recon_loss: 48.324
===> gan_loss: -1.233
===> Total for class sdm1: 72.988
TOTAL: 122.925
GENERATOR Train epoch 2: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 18.842
===> backtranslation_recon_loss: 31.870
===> gan_loss: -1.290
===> Total for class ihm: 49.422
=> Class sdm1
===> autoencoding_recon_loss: 25.694
===> backtranslation_recon_loss: 47.972
===> gan_loss: -1.233
===> Total for class sdm1: 72.433
TOTAL: 121.855
GENERATOR Train epoch 2: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 18.714
===> backtranslation_recon_loss: 31.656
===> gan_loss: -1.290
===> Total for class ihm: 49.080
=> Class sdm1
===> autoencoding_recon_loss: 25.518
===> backtranslation_recon_loss: 47.658
===> gan_loss: -1.232
===> Total for class sdm1: 71.944
TOTAL: 121.024
GENERATOR Train epoch 2: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 18.605
===> backtranslation_recon_loss: 31.458
===> gan_loss: -1.290
===> Total for class ihm: 48.772
=> Class sdm1
===> autoencoding_recon_loss: 25.372
===> backtranslation_recon_loss: 47.384
===> gan_loss: -1.232
===> Total for class sdm1: 71.524
TOTAL: 120.296

EPOCH 2 TRAIN (6900.674s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 18.505
===> backtranslation_recon_loss: 31.304
===> gan_loss: -1.290
===> Total for class ihm: 48.518
=> Class sdm1
===> autoencoding_recon_loss: 25.217
===> backtranslation_recon_loss: 47.136
===> gan_loss: -1.232
===> Total for class sdm1: 71.121
TOTAL: 119.639

EPOCH 2 DEV (146.511s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 26.351
===> backtranslation_recon_loss: 35.345
===> gan_loss: -1.305
===> Total for class ihm: 60.391
=> Class sdm1
===> autoencoding_recon_loss: 21.450
===> backtranslation_recon_loss: 45.468
===> gan_loss: -1.279
===> Total for class sdm1: 65.638
TOTAL: 126.030

New best dev set loss: 126.029585
Saved checkpoint for model

STARTING EPOCH 3
GENERATOR Train epoch 3: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.792
===> backtranslation_recon_loss: 27.216
===> gan_loss: -1.293
===> Total for class ihm: 41.716
=> Class sdm1
===> autoencoding_recon_loss: 23.223
===> backtranslation_recon_loss: 43.826
===> gan_loss: -1.235
===> Total for class sdm1: 65.814
TOTAL: 107.530
GENERATOR Train epoch 3: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.906
===> backtranslation_recon_loss: 27.314
===> gan_loss: -1.290
===> Total for class ihm: 41.930
=> Class sdm1
===> autoencoding_recon_loss: 22.709
===> backtranslation_recon_loss: 42.972
===> gan_loss: -1.233
===> Total for class sdm1: 64.448
TOTAL: 106.378
GENERATOR Train epoch 3: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.669
===> backtranslation_recon_loss: 26.957
===> gan_loss: -1.295
===> Total for class ihm: 41.331
=> Class sdm1
===> autoencoding_recon_loss: 22.345
===> backtranslation_recon_loss: 42.409
===> gan_loss: -1.234
===> Total for class sdm1: 63.520
TOTAL: 104.851
GENERATOR Train epoch 3: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.864
===> backtranslation_recon_loss: 27.139
===> gan_loss: -1.293
===> Total for class ihm: 41.709
=> Class sdm1
===> autoencoding_recon_loss: 22.189
===> backtranslation_recon_loss: 41.970
===> gan_loss: -1.235
===> Total for class sdm1: 62.924
TOTAL: 104.633
GENERATOR Train epoch 3: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.861
===> backtranslation_recon_loss: 27.181
===> gan_loss: -1.292
===> Total for class ihm: 41.750
=> Class sdm1
===> autoencoding_recon_loss: 21.964
===> backtranslation_recon_loss: 41.583
===> gan_loss: -1.235
===> Total for class sdm1: 62.312
TOTAL: 104.062
GENERATOR Train epoch 3: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.587
===> backtranslation_recon_loss: 26.757
===> gan_loss: -1.293
===> Total for class ihm: 41.052
=> Class sdm1
===> autoencoding_recon_loss: 21.771
===> backtranslation_recon_loss: 41.266
===> gan_loss: -1.236
===> Total for class sdm1: 61.801
TOTAL: 102.852
GENERATOR Train epoch 3: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.556
===> backtranslation_recon_loss: 26.655
===> gan_loss: -1.292
===> Total for class ihm: 40.920
=> Class sdm1
===> autoencoding_recon_loss: 21.729
===> backtranslation_recon_loss: 41.155
===> gan_loss: -1.234
===> Total for class sdm1: 61.650
TOTAL: 102.570
GENERATOR Train epoch 3: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.432
===> backtranslation_recon_loss: 26.464
===> gan_loss: -1.291
===> Total for class ihm: 40.604
=> Class sdm1
===> autoencoding_recon_loss: 21.537
===> backtranslation_recon_loss: 40.873
===> gan_loss: -1.233
===> Total for class sdm1: 61.178
TOTAL: 101.782
GENERATOR Train epoch 3: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.537
===> backtranslation_recon_loss: 26.580
===> gan_loss: -1.291
===> Total for class ihm: 40.825
=> Class sdm1
===> autoencoding_recon_loss: 21.585
===> backtranslation_recon_loss: 40.991
===> gan_loss: -1.233
===> Total for class sdm1: 61.342
TOTAL: 102.168
GENERATOR Train epoch 3: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.401
===> backtranslation_recon_loss: 26.328
===> gan_loss: -1.291
===> Total for class ihm: 40.438
=> Class sdm1
===> autoencoding_recon_loss: 21.474
===> backtranslation_recon_loss: 40.779
===> gan_loss: -1.233
===> Total for class sdm1: 61.020
TOTAL: 101.458
GENERATOR Train epoch 3: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.292
===> backtranslation_recon_loss: 26.193
===> gan_loss: -1.290
===> Total for class ihm: 40.195
=> Class sdm1
===> autoencoding_recon_loss: 21.350
===> backtranslation_recon_loss: 40.584
===> gan_loss: -1.232
===> Total for class sdm1: 60.703
TOTAL: 100.897
GENERATOR Train epoch 3: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.206
===> backtranslation_recon_loss: 26.052
===> gan_loss: -1.290
===> Total for class ihm: 39.968
=> Class sdm1
===> autoencoding_recon_loss: 21.206
===> backtranslation_recon_loss: 40.350
===> gan_loss: -1.231
===> Total for class sdm1: 60.325
TOTAL: 100.293
GENERATOR Train epoch 3: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.203
===> backtranslation_recon_loss: 26.023
===> gan_loss: -1.289
===> Total for class ihm: 39.937
=> Class sdm1
===> autoencoding_recon_loss: 21.139
===> backtranslation_recon_loss: 40.231
===> gan_loss: -1.231
===> Total for class sdm1: 60.139
TOTAL: 100.076
GENERATOR Train epoch 3: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15.137
===> backtranslation_recon_loss: 25.920
===> gan_loss: -1.288
===> Total for class ihm: 39.770
=> Class sdm1
===> autoencoding_recon_loss: 21.010
===> backtranslation_recon_loss: 40.020
===> gan_loss: -1.230
===> Total for class sdm1: 59.800
TOTAL: 99.570
