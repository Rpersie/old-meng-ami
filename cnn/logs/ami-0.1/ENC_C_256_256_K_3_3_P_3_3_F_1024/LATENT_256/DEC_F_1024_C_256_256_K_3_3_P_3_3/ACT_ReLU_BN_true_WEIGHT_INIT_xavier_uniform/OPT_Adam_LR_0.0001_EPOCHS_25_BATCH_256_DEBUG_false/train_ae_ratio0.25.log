Running training with mode ae
Noising 25.000% of input features
Constructing model...
Done constructing model.
CNNMultidecoder(
  (encoder_conv): Sequential(
    (conv2d_0): Conv2d (1, 256, kernel_size=(3, 3), stride=(1, 1))
    (batchnorm2d_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (ReLU_0): ReLU()
    (maxpool2d_0): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
    (batchnorm2d_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (ReLU_1): ReLU()
    (maxpool2d_1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential(
    (lin_0): Linear(in_features=14336, out_features=1024)
    (batchnorm1d_0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)
    (ReLU_0): ReLU()
    (lin_final): Linear(in_features=1024, out_features=256)
    (ReLU_final): ReLU()
  )
  (decoder_fc_ihm): Sequential(
    (ReLU_0): ReLU()
    (lin_0): Linear(in_features=256, out_features=1024)
    (batchnorm1d_0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)
    (ReLU_final): ReLU()
    (lin_final): Linear(in_features=1024, out_features=14336)
  )
  (decoder_deconv_ihm): Sequential(
    (ReLU_0): ReLU()
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (batchnorm2d_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (ReLU_1): ReLU()
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
  )
  (decoder_fc_sdm1): Sequential(
    (ReLU_0): ReLU()
    (lin_0): Linear(in_features=256, out_features=1024)
    (batchnorm1d_0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)
    (ReLU_final): ReLU()
    (lin_final): Linear(in_features=1024, out_features=14336)
  )
  (decoder_deconv_sdm1): Sequential(
    (ReLU_0): ReLU()
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (batchnorm2d_0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
    (ReLU_1): ReLU()
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
  )
)
Model has 46644226 trainable parameters
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Completed setup in 135.293 seconds
Starting training!

STARTING EPOCH 1
GENERATOR Train epoch 1: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 465.807
===> backtranslation_recon_loss: 477.588
===> Total for class ihm: 943.394
=> Class sdm1
===> autoencoding_recon_loss: 507.037
===> backtranslation_recon_loss: 535.720
===> Total for class sdm1: 1042.757
TOTAL: 1986.151
GENERATOR Train epoch 1: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 340.324
===> backtranslation_recon_loss: 351.791
===> Total for class ihm: 692.115
=> Class sdm1
===> autoencoding_recon_loss: 380.139
===> backtranslation_recon_loss: 408.206
===> Total for class sdm1: 788.345
TOTAL: 1480.460
GENERATOR Train epoch 1: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 278.644
===> backtranslation_recon_loss: 288.759
===> Total for class ihm: 567.402
=> Class sdm1
===> autoencoding_recon_loss: 322.431
===> backtranslation_recon_loss: 347.206
===> Total for class sdm1: 669.637
TOTAL: 1237.040
GENERATOR Train epoch 1: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 244.472
===> backtranslation_recon_loss: 252.582
===> Total for class ihm: 497.054
=> Class sdm1
===> autoencoding_recon_loss: 286.852
===> backtranslation_recon_loss: 308.910
===> Total for class sdm1: 595.762
TOTAL: 1092.816
GENERATOR Train epoch 1: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 221.611
===> backtranslation_recon_loss: 228.739
===> Total for class ihm: 450.350
=> Class sdm1
===> autoencoding_recon_loss: 265.441
===> backtranslation_recon_loss: 285.650
===> Total for class sdm1: 551.091
TOTAL: 1001.441
GENERATOR Train epoch 1: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 206.156
===> backtranslation_recon_loss: 211.881
===> Total for class ihm: 418.037
=> Class sdm1
===> autoencoding_recon_loss: 249.227
===> backtranslation_recon_loss: 267.979
===> Total for class sdm1: 517.206
TOTAL: 935.243
GENERATOR Train epoch 1: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 194.029
===> backtranslation_recon_loss: 198.975
===> Total for class ihm: 393.004
=> Class sdm1
===> autoencoding_recon_loss: 236.851
===> backtranslation_recon_loss: 253.610
===> Total for class sdm1: 490.461
TOTAL: 883.465
GENERATOR Train epoch 1: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 184.389
===> backtranslation_recon_loss: 188.975
===> Total for class ihm: 373.364
=> Class sdm1
===> autoencoding_recon_loss: 226.135
===> backtranslation_recon_loss: 241.864
===> Total for class sdm1: 467.999
TOTAL: 841.363
GENERATOR Train epoch 1: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 176.162
===> backtranslation_recon_loss: 180.130
===> Total for class ihm: 356.292
=> Class sdm1
===> autoencoding_recon_loss: 217.549
===> backtranslation_recon_loss: 232.039
===> Total for class sdm1: 449.587
TOTAL: 805.879
GENERATOR Train epoch 1: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 168.884
===> backtranslation_recon_loss: 172.413
===> Total for class ihm: 341.297
=> Class sdm1
===> autoencoding_recon_loss: 209.980
===> backtranslation_recon_loss: 223.393
===> Total for class sdm1: 433.373
TOTAL: 774.670
GENERATOR Train epoch 1: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 162.746
===> backtranslation_recon_loss: 165.909
===> Total for class ihm: 328.655
=> Class sdm1
===> autoencoding_recon_loss: 203.786
===> backtranslation_recon_loss: 216.063
===> Total for class sdm1: 419.849
TOTAL: 748.503
GENERATOR Train epoch 1: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 157.304
===> backtranslation_recon_loss: 160.136
===> Total for class ihm: 317.439
=> Class sdm1
===> autoencoding_recon_loss: 198.185
===> backtranslation_recon_loss: 209.726
===> Total for class sdm1: 407.911
TOTAL: 725.351
GENERATOR Train epoch 1: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 152.626
===> backtranslation_recon_loss: 155.204
===> Total for class ihm: 307.830
=> Class sdm1
===> autoencoding_recon_loss: 193.358
===> backtranslation_recon_loss: 204.020
===> Total for class sdm1: 397.378
TOTAL: 705.208
GENERATOR Train epoch 1: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 148.260
===> backtranslation_recon_loss: 150.771
===> Total for class ihm: 299.031
=> Class sdm1
===> autoencoding_recon_loss: 189.016
===> backtranslation_recon_loss: 198.877
===> Total for class sdm1: 387.894
TOTAL: 686.925
GENERATOR Train epoch 1: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 144.768
===> backtranslation_recon_loss: 147.202
===> Total for class ihm: 291.971
=> Class sdm1
===> autoencoding_recon_loss: 184.466
===> backtranslation_recon_loss: 193.990
===> Total for class sdm1: 378.456
TOTAL: 670.427
GENERATOR Train epoch 1: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 141.697
===> backtranslation_recon_loss: 144.069
===> Total for class ihm: 285.766
=> Class sdm1
===> autoencoding_recon_loss: 180.459
===> backtranslation_recon_loss: 189.585
===> Total for class sdm1: 370.043
TOTAL: 655.810
GENERATOR Train epoch 1: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 138.925
===> backtranslation_recon_loss: 141.130
===> Total for class ihm: 280.055
=> Class sdm1
===> autoencoding_recon_loss: 177.140
===> backtranslation_recon_loss: 185.801
===> Total for class sdm1: 362.940
TOTAL: 642.995
GENERATOR Train epoch 1: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 136.219
===> backtranslation_recon_loss: 138.612
===> Total for class ihm: 274.831
=> Class sdm1
===> autoencoding_recon_loss: 174.326
===> backtranslation_recon_loss: 182.597
===> Total for class sdm1: 356.923
TOTAL: 631.754

EPOCH 1 TRAIN (5164.414s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 34368.139
===> backtranslation_recon_loss: 34958.534
===> Total for class ihm: 69326.672
=> Class sdm1
===> autoencoding_recon_loss: 44051.968
===> backtranslation_recon_loss: 46076.713
===> Total for class sdm1: 90128.681
TOTAL: 159455.353

EPOCH 1 DEV (169.067s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 32538.467
===> backtranslation_recon_loss: 26219.070
===> Total for class ihm: 58757.537
=> Class sdm1
===> autoencoding_recon_loss: 44298.584
===> backtranslation_recon_loss: 33652.106
===> Total for class sdm1: 77950.690
TOTAL: 136708.227

New best dev set loss: 136708.227047
Saved checkpoint for model

STARTING EPOCH 2
GENERATOR Train epoch 2: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 88.438
===> backtranslation_recon_loss: 90.000
===> Total for class ihm: 178.438
=> Class sdm1
===> autoencoding_recon_loss: 127.954
===> backtranslation_recon_loss: 129.096
===> Total for class sdm1: 257.049
TOTAL: 435.488
GENERATOR Train epoch 2: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 90.349
===> backtranslation_recon_loss: 91.328
===> Total for class ihm: 181.678
=> Class sdm1
===> autoencoding_recon_loss: 125.415
===> backtranslation_recon_loss: 128.636
===> Total for class sdm1: 254.051
TOTAL: 435.729
GENERATOR Train epoch 2: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 87.363
===> backtranslation_recon_loss: 88.400
===> Total for class ihm: 175.762
=> Class sdm1
===> autoencoding_recon_loss: 124.340
===> backtranslation_recon_loss: 126.068
===> Total for class sdm1: 250.408
TOTAL: 426.171
GENERATOR Train epoch 2: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 86.484
===> backtranslation_recon_loss: 87.132
===> Total for class ihm: 173.616
=> Class sdm1
===> autoencoding_recon_loss: 123.255
===> backtranslation_recon_loss: 124.429
===> Total for class sdm1: 247.684
TOTAL: 421.300
GENERATOR Train epoch 2: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 86.130
===> backtranslation_recon_loss: 86.748
===> Total for class ihm: 172.878
=> Class sdm1
===> autoencoding_recon_loss: 122.422
===> backtranslation_recon_loss: 124.191
===> Total for class sdm1: 246.613
TOTAL: 419.490
GENERATOR Train epoch 2: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 85.627
===> backtranslation_recon_loss: 85.922
===> Total for class ihm: 171.549
=> Class sdm1
===> autoencoding_recon_loss: 121.686
===> backtranslation_recon_loss: 123.296
===> Total for class sdm1: 244.982
TOTAL: 416.531
GENERATOR Train epoch 2: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 85.153
===> backtranslation_recon_loss: 85.381
===> Total for class ihm: 170.533
=> Class sdm1
===> autoencoding_recon_loss: 120.758
===> backtranslation_recon_loss: 122.166
===> Total for class sdm1: 242.924
TOTAL: 413.457
GENERATOR Train epoch 2: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 84.851
===> backtranslation_recon_loss: 85.175
===> Total for class ihm: 170.026
=> Class sdm1
===> autoencoding_recon_loss: 120.156
===> backtranslation_recon_loss: 121.474
===> Total for class sdm1: 241.629
TOTAL: 411.655
GENERATOR Train epoch 2: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 84.249
===> backtranslation_recon_loss: 84.532
===> Total for class ihm: 168.781
=> Class sdm1
===> autoencoding_recon_loss: 118.996
===> backtranslation_recon_loss: 120.244
===> Total for class sdm1: 239.240
TOTAL: 408.021
GENERATOR Train epoch 2: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 83.744
===> backtranslation_recon_loss: 83.888
===> Total for class ihm: 167.633
=> Class sdm1
===> autoencoding_recon_loss: 118.017
===> backtranslation_recon_loss: 118.918
===> Total for class sdm1: 236.934
TOTAL: 404.567
GENERATOR Train epoch 2: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 83.289
===> backtranslation_recon_loss: 83.426
===> Total for class ihm: 166.715
=> Class sdm1
===> autoencoding_recon_loss: 117.388
===> backtranslation_recon_loss: 117.942
===> Total for class sdm1: 235.330
TOTAL: 402.045
GENERATOR Train epoch 2: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 82.609
===> backtranslation_recon_loss: 82.758
===> Total for class ihm: 165.368
=> Class sdm1
===> autoencoding_recon_loss: 116.750
===> backtranslation_recon_loss: 117.364
===> Total for class sdm1: 234.114
TOTAL: 399.482
GENERATOR Train epoch 2: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 82.256
===> backtranslation_recon_loss: 82.414
===> Total for class ihm: 164.670
=> Class sdm1
===> autoencoding_recon_loss: 116.622
===> backtranslation_recon_loss: 117.106
===> Total for class sdm1: 233.728
TOTAL: 398.398
GENERATOR Train epoch 2: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 81.723
===> backtranslation_recon_loss: 81.838
===> Total for class ihm: 163.561
=> Class sdm1
===> autoencoding_recon_loss: 115.729
===> backtranslation_recon_loss: 116.119
===> Total for class sdm1: 231.848
TOTAL: 395.409
GENERATOR Train epoch 2: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 81.197
===> backtranslation_recon_loss: 81.284
===> Total for class ihm: 162.481
=> Class sdm1
===> autoencoding_recon_loss: 114.964
===> backtranslation_recon_loss: 115.445
===> Total for class sdm1: 230.409
TOTAL: 392.891
GENERATOR Train epoch 2: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 81.041
===> backtranslation_recon_loss: 81.153
===> Total for class ihm: 162.194
=> Class sdm1
===> autoencoding_recon_loss: 114.341
===> backtranslation_recon_loss: 114.977
===> Total for class sdm1: 229.318
TOTAL: 391.512
GENERATOR Train epoch 2: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 80.814
===> backtranslation_recon_loss: 80.887
===> Total for class ihm: 161.701
=> Class sdm1
===> autoencoding_recon_loss: 113.728
===> backtranslation_recon_loss: 114.429
===> Total for class sdm1: 228.157
TOTAL: 389.858
GENERATOR Train epoch 2: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 80.402
===> backtranslation_recon_loss: 80.425
===> Total for class ihm: 160.828
=> Class sdm1
===> autoencoding_recon_loss: 113.387
===> backtranslation_recon_loss: 113.997
===> Total for class sdm1: 227.385
TOTAL: 388.212

EPOCH 2 TRAIN (5159.690s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 20504.909
===> backtranslation_recon_loss: 20525.357
===> Total for class ihm: 41030.266
=> Class sdm1
===> autoencoding_recon_loss: 28921.919
===> backtranslation_recon_loss: 29082.641
===> Total for class sdm1: 58004.560
TOTAL: 99034.826

EPOCH 2 DEV (168.389s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 38686.404
===> backtranslation_recon_loss: 32675.046
===> Total for class ihm: 71361.450
=> Class sdm1
===> autoencoding_recon_loss: 29882.132
===> backtranslation_recon_loss: 40622.507
===> Total for class sdm1: 70504.639
TOTAL: 141866.089

No improvement in 1 epochs (best dev set loss: 136708.227047)
Not saving checkpoint; no improvement made

STARTING EPOCH 3
GENERATOR Train epoch 3: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 74.300
===> backtranslation_recon_loss: 72.645
===> Total for class ihm: 146.944
=> Class sdm1
===> autoencoding_recon_loss: 107.934
===> backtranslation_recon_loss: 107.788
===> Total for class sdm1: 215.723
TOTAL: 362.667
GENERATOR Train epoch 3: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 74.531
===> backtranslation_recon_loss: 73.284
===> Total for class ihm: 147.815
=> Class sdm1
===> autoencoding_recon_loss: 106.629
===> backtranslation_recon_loss: 106.564
===> Total for class sdm1: 213.193
TOTAL: 361.008
GENERATOR Train epoch 3: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 73.280
===> backtranslation_recon_loss: 72.179
===> Total for class ihm: 145.460
=> Class sdm1
===> autoencoding_recon_loss: 106.216
===> backtranslation_recon_loss: 105.992
===> Total for class sdm1: 212.209
TOTAL: 357.668
GENERATOR Train epoch 3: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 72.717
===> backtranslation_recon_loss: 71.502
===> Total for class ihm: 144.219
=> Class sdm1
===> autoencoding_recon_loss: 104.592
===> backtranslation_recon_loss: 103.963
===> Total for class sdm1: 208.556
TOTAL: 352.775
GENERATOR Train epoch 3: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 72.799
===> backtranslation_recon_loss: 71.813
===> Total for class ihm: 144.613
=> Class sdm1
===> autoencoding_recon_loss: 104.288
===> backtranslation_recon_loss: 103.282
===> Total for class sdm1: 207.570
TOTAL: 352.183
GENERATOR Train epoch 3: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 72.485
===> backtranslation_recon_loss: 71.366
===> Total for class ihm: 143.851
=> Class sdm1
===> autoencoding_recon_loss: 104.365
===> backtranslation_recon_loss: 103.429
===> Total for class sdm1: 207.794
TOTAL: 351.645
GENERATOR Train epoch 3: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 72.246
===> backtranslation_recon_loss: 70.995
===> Total for class ihm: 143.241
=> Class sdm1
===> autoencoding_recon_loss: 103.809
===> backtranslation_recon_loss: 103.000
===> Total for class sdm1: 206.809
TOTAL: 350.050
GENERATOR Train epoch 3: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 71.910
===> backtranslation_recon_loss: 70.634
===> Total for class ihm: 142.544
=> Class sdm1
===> autoencoding_recon_loss: 103.532
===> backtranslation_recon_loss: 102.437
===> Total for class sdm1: 205.970
TOTAL: 348.513
GENERATOR Train epoch 3: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 71.610
===> backtranslation_recon_loss: 70.294
===> Total for class ihm: 141.904
=> Class sdm1
===> autoencoding_recon_loss: 102.891
===> backtranslation_recon_loss: 101.950
===> Total for class sdm1: 204.840
TOTAL: 346.744
GENERATOR Train epoch 3: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 71.234
===> backtranslation_recon_loss: 69.798
===> Total for class ihm: 141.032
=> Class sdm1
===> autoencoding_recon_loss: 102.124
===> backtranslation_recon_loss: 101.034
===> Total for class sdm1: 203.159
TOTAL: 344.190
GENERATOR Train epoch 3: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 71.063
===> backtranslation_recon_loss: 69.770
===> Total for class ihm: 140.833
=> Class sdm1
===> autoencoding_recon_loss: 101.769
===> backtranslation_recon_loss: 100.664
===> Total for class sdm1: 202.433
TOTAL: 343.266
GENERATOR Train epoch 3: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 70.677
===> backtranslation_recon_loss: 69.425
===> Total for class ihm: 140.101
=> Class sdm1
===> autoencoding_recon_loss: 101.617
===> backtranslation_recon_loss: 100.482
===> Total for class sdm1: 202.099
TOTAL: 342.200
GENERATOR Train epoch 3: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 70.344
===> backtranslation_recon_loss: 69.096
===> Total for class ihm: 139.440
=> Class sdm1
===> autoencoding_recon_loss: 101.661
===> backtranslation_recon_loss: 100.168
===> Total for class sdm1: 201.829
TOTAL: 341.269
GENERATOR Train epoch 3: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 70.109
===> backtranslation_recon_loss: 68.841
===> Total for class ihm: 138.950
=> Class sdm1
===> autoencoding_recon_loss: 101.191
===> backtranslation_recon_loss: 99.722
===> Total for class sdm1: 200.913
TOTAL: 339.862
GENERATOR Train epoch 3: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 69.781
===> backtranslation_recon_loss: 68.503
===> Total for class ihm: 138.284
=> Class sdm1
===> autoencoding_recon_loss: 100.665
===> backtranslation_recon_loss: 99.214
===> Total for class sdm1: 199.880
TOTAL: 338.163
GENERATOR Train epoch 3: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 69.599
===> backtranslation_recon_loss: 68.352
===> Total for class ihm: 137.951
=> Class sdm1
===> autoencoding_recon_loss: 100.359
===> backtranslation_recon_loss: 98.806
===> Total for class sdm1: 199.164
TOTAL: 337.115
GENERATOR Train epoch 3: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 69.546
===> backtranslation_recon_loss: 68.210
===> Total for class ihm: 137.756
=> Class sdm1
===> autoencoding_recon_loss: 100.066
===> backtranslation_recon_loss: 98.517
===> Total for class sdm1: 198.583
TOTAL: 336.339
GENERATOR Train epoch 3: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 69.382
===> backtranslation_recon_loss: 68.095
===> Total for class ihm: 137.476
=> Class sdm1
===> autoencoding_recon_loss: 99.894
===> backtranslation_recon_loss: 98.236
===> Total for class sdm1: 198.130
TOTAL: 335.606

EPOCH 3 TRAIN (5168.115s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 17726.885
===> backtranslation_recon_loss: 17411.394
===> Total for class ihm: 35138.279
=> Class sdm1
===> autoencoding_recon_loss: 25522.495
===> backtranslation_recon_loss: 25119.418
===> Total for class sdm1: 50641.913
TOTAL: 85780.191

EPOCH 3 DEV (166.752s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 29712.559
===> backtranslation_recon_loss: 21598.325
===> Total for class ihm: 51310.884
=> Class sdm1
===> autoencoding_recon_loss: 43135.463
===> backtranslation_recon_loss: 28385.263
===> Total for class sdm1: 71520.725
TOTAL: 122831.609

New best dev set loss: 122831.609291
Saved checkpoint for model

STARTING EPOCH 4
GENERATOR Train epoch 4: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 66.199
===> backtranslation_recon_loss: 63.262
===> Total for class ihm: 129.461
=> Class sdm1
===> autoencoding_recon_loss: 98.392
===> backtranslation_recon_loss: 96.035
===> Total for class sdm1: 194.427
TOTAL: 323.888
GENERATOR Train epoch 4: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 66.863
===> backtranslation_recon_loss: 64.553
===> Total for class ihm: 131.416
=> Class sdm1
===> autoencoding_recon_loss: 96.094
===> backtranslation_recon_loss: 94.880
===> Total for class sdm1: 190.974
TOTAL: 322.390
GENERATOR Train epoch 4: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.728
===> backtranslation_recon_loss: 64.023
===> Total for class ihm: 129.751
=> Class sdm1
===> autoencoding_recon_loss: 96.593
===> backtranslation_recon_loss: 95.251
===> Total for class sdm1: 191.844
TOTAL: 321.595
GENERATOR Train epoch 4: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.495
===> backtranslation_recon_loss: 63.583
===> Total for class ihm: 129.078
=> Class sdm1
===> autoencoding_recon_loss: 95.217
===> backtranslation_recon_loss: 93.694
===> Total for class sdm1: 188.911
TOTAL: 317.989
GENERATOR Train epoch 4: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.422
===> backtranslation_recon_loss: 63.531
===> Total for class ihm: 128.954
=> Class sdm1
===> autoencoding_recon_loss: 95.323
===> backtranslation_recon_loss: 94.005
===> Total for class sdm1: 189.328
TOTAL: 318.282
GENERATOR Train epoch 4: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.304
===> backtranslation_recon_loss: 63.403
===> Total for class ihm: 128.707
=> Class sdm1
===> autoencoding_recon_loss: 95.642
===> backtranslation_recon_loss: 94.184
===> Total for class sdm1: 189.826
TOTAL: 318.533
GENERATOR Train epoch 4: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.100
===> backtranslation_recon_loss: 63.200
===> Total for class ihm: 128.300
=> Class sdm1
===> autoencoding_recon_loss: 95.178
===> backtranslation_recon_loss: 93.380
===> Total for class sdm1: 188.558
TOTAL: 316.858
GENERATOR Train epoch 4: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.041
===> backtranslation_recon_loss: 63.134
===> Total for class ihm: 128.175
=> Class sdm1
===> autoencoding_recon_loss: 95.095
===> backtranslation_recon_loss: 93.055
===> Total for class sdm1: 188.150
TOTAL: 316.326
GENERATOR Train epoch 4: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 64.719
===> backtranslation_recon_loss: 62.764
===> Total for class ihm: 127.483
=> Class sdm1
===> autoencoding_recon_loss: 94.652
===> backtranslation_recon_loss: 92.696
===> Total for class sdm1: 187.348
TOTAL: 314.830
GENERATOR Train epoch 4: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 64.495
===> backtranslation_recon_loss: 62.444
===> Total for class ihm: 126.939
=> Class sdm1
===> autoencoding_recon_loss: 94.221
===> backtranslation_recon_loss: 92.219
===> Total for class sdm1: 186.439
TOTAL: 313.379
GENERATOR Train epoch 4: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 64.383
===> backtranslation_recon_loss: 62.464
===> Total for class ihm: 126.847
=> Class sdm1
===> autoencoding_recon_loss: 94.036
===> backtranslation_recon_loss: 91.993
===> Total for class sdm1: 186.028
TOTAL: 312.875
GENERATOR Train epoch 4: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 64.126
===> backtranslation_recon_loss: 62.232
===> Total for class ihm: 126.358
=> Class sdm1
===> autoencoding_recon_loss: 93.908
===> backtranslation_recon_loss: 91.792
===> Total for class sdm1: 185.700
TOTAL: 312.059
GENERATOR Train epoch 4: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 63.993
===> backtranslation_recon_loss: 62.174
===> Total for class ihm: 126.167
=> Class sdm1
===> autoencoding_recon_loss: 93.939
===> backtranslation_recon_loss: 91.812
===> Total for class sdm1: 185.751
TOTAL: 311.918
GENERATOR Train epoch 4: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 63.852
===> backtranslation_recon_loss: 61.957
===> Total for class ihm: 125.809
=> Class sdm1
===> autoencoding_recon_loss: 93.619
===> backtranslation_recon_loss: 91.461
===> Total for class sdm1: 185.080
TOTAL: 310.889
GENERATOR Train epoch 4: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 63.661
===> backtranslation_recon_loss: 61.780
===> Total for class ihm: 125.442
=> Class sdm1
===> autoencoding_recon_loss: 93.242
===> backtranslation_recon_loss: 91.265
===> Total for class sdm1: 184.507
TOTAL: 309.948
GENERATOR Train epoch 4: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 63.504
===> backtranslation_recon_loss: 61.649
===> Total for class ihm: 125.153
=> Class sdm1
===> autoencoding_recon_loss: 92.974
===> backtranslation_recon_loss: 91.044
===> Total for class sdm1: 184.019
TOTAL: 309.172
GENERATOR Train epoch 4: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 63.595
===> backtranslation_recon_loss: 61.748
===> Total for class ihm: 125.343
=> Class sdm1
===> autoencoding_recon_loss: 92.756
===> backtranslation_recon_loss: 90.904
===> Total for class sdm1: 183.659
TOTAL: 309.003
GENERATOR Train epoch 4: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 63.510
===> backtranslation_recon_loss: 61.681
===> Total for class ihm: 125.191
=> Class sdm1
===> autoencoding_recon_loss: 92.766
===> backtranslation_recon_loss: 90.856
===> Total for class sdm1: 183.622
TOTAL: 308.813

EPOCH 4 TRAIN (5149.941s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 16222.880
===> backtranslation_recon_loss: 15749.546
===> Total for class ihm: 31972.426
=> Class sdm1
===> autoencoding_recon_loss: 23733.055
===> backtranslation_recon_loss: 23248.199
===> Total for class sdm1: 46981.254
TOTAL: 78953.680

EPOCH 4 DEV (167.189s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 52065.973
===> backtranslation_recon_loss: 39946.390
===> Total for class ihm: 92012.363
=> Class sdm1
===> autoencoding_recon_loss: 26591.431
===> backtranslation_recon_loss: 41019.029
===> Total for class sdm1: 67610.460
TOTAL: 159622.823

No improvement in 1 epochs (best dev set loss: 122831.609291)
Not saving checkpoint; no improvement made

STARTING EPOCH 5
GENERATOR Train epoch 5: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 62.893
===> backtranslation_recon_loss: 59.352
===> Total for class ihm: 122.244
=> Class sdm1
===> autoencoding_recon_loss: 94.128
===> backtranslation_recon_loss: 90.500
===> Total for class sdm1: 184.628
TOTAL: 306.872
GENERATOR Train epoch 5: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 62.856
===> backtranslation_recon_loss: 59.616
===> Total for class ihm: 122.472
=> Class sdm1
===> autoencoding_recon_loss: 91.873
===> backtranslation_recon_loss: 88.828
===> Total for class sdm1: 180.701
TOTAL: 303.173
GENERATOR Train epoch 5: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 62.211
===> backtranslation_recon_loss: 59.643
===> Total for class ihm: 121.854
=> Class sdm1
===> autoencoding_recon_loss: 92.051
===> backtranslation_recon_loss: 88.909
===> Total for class sdm1: 180.959
TOTAL: 302.813
GENERATOR Train epoch 5: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.829
===> backtranslation_recon_loss: 59.106
===> Total for class ihm: 120.935
=> Class sdm1
===> autoencoding_recon_loss: 90.876
===> backtranslation_recon_loss: 87.616
===> Total for class sdm1: 178.492
TOTAL: 299.427
GENERATOR Train epoch 5: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.839
===> backtranslation_recon_loss: 59.096
===> Total for class ihm: 120.935
=> Class sdm1
===> autoencoding_recon_loss: 91.074
===> backtranslation_recon_loss: 88.026
===> Total for class sdm1: 179.101
TOTAL: 300.036
GENERATOR Train epoch 5: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.827
===> backtranslation_recon_loss: 58.728
===> Total for class ihm: 120.555
=> Class sdm1
===> autoencoding_recon_loss: 91.094
===> backtranslation_recon_loss: 87.845
===> Total for class sdm1: 178.939
TOTAL: 299.494
GENERATOR Train epoch 5: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.716
===> backtranslation_recon_loss: 58.882
===> Total for class ihm: 120.597
=> Class sdm1
===> autoencoding_recon_loss: 90.757
===> backtranslation_recon_loss: 87.500
===> Total for class sdm1: 178.257
TOTAL: 298.854
GENERATOR Train epoch 5: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.621
===> backtranslation_recon_loss: 58.875
===> Total for class ihm: 120.495
=> Class sdm1
===> autoencoding_recon_loss: 90.678
===> backtranslation_recon_loss: 87.290
===> Total for class sdm1: 177.968
TOTAL: 298.463
GENERATOR Train epoch 5: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.458
===> backtranslation_recon_loss: 58.729
===> Total for class ihm: 120.188
=> Class sdm1
===> autoencoding_recon_loss: 90.359
===> backtranslation_recon_loss: 86.912
===> Total for class sdm1: 177.270
TOTAL: 297.458
GENERATOR Train epoch 5: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.345
===> backtranslation_recon_loss: 58.592
===> Total for class ihm: 119.937
=> Class sdm1
===> autoencoding_recon_loss: 90.012
===> backtranslation_recon_loss: 86.645
===> Total for class sdm1: 176.657
TOTAL: 296.594
GENERATOR Train epoch 5: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.301
===> backtranslation_recon_loss: 58.575
===> Total for class ihm: 119.876
=> Class sdm1
===> autoencoding_recon_loss: 89.951
===> backtranslation_recon_loss: 86.442
===> Total for class sdm1: 176.394
TOTAL: 296.270
GENERATOR Train epoch 5: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.022
===> backtranslation_recon_loss: 58.322
===> Total for class ihm: 119.344
=> Class sdm1
===> autoencoding_recon_loss: 89.768
===> backtranslation_recon_loss: 86.243
===> Total for class sdm1: 176.012
TOTAL: 295.356
GENERATOR Train epoch 5: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.927
===> backtranslation_recon_loss: 58.091
===> Total for class ihm: 119.018
=> Class sdm1
===> autoencoding_recon_loss: 89.873
===> backtranslation_recon_loss: 86.097
===> Total for class sdm1: 175.971
TOTAL: 294.988
GENERATOR Train epoch 5: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.791
===> backtranslation_recon_loss: 57.981
===> Total for class ihm: 118.773
=> Class sdm1
===> autoencoding_recon_loss: 89.586
===> backtranslation_recon_loss: 85.874
===> Total for class sdm1: 175.460
TOTAL: 294.233
GENERATOR Train epoch 5: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.594
===> backtranslation_recon_loss: 57.764
===> Total for class ihm: 118.358
=> Class sdm1
===> autoencoding_recon_loss: 89.207
===> backtranslation_recon_loss: 85.593
===> Total for class sdm1: 174.800
TOTAL: 293.158
GENERATOR Train epoch 5: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.564
===> backtranslation_recon_loss: 57.783
===> Total for class ihm: 118.348
=> Class sdm1
===> autoencoding_recon_loss: 89.040
===> backtranslation_recon_loss: 85.479
===> Total for class sdm1: 174.519
TOTAL: 292.867
GENERATOR Train epoch 5: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.665
===> backtranslation_recon_loss: 57.897
===> Total for class ihm: 118.561
=> Class sdm1
===> autoencoding_recon_loss: 88.935
===> backtranslation_recon_loss: 85.342
===> Total for class sdm1: 174.276
TOTAL: 292.838
GENERATOR Train epoch 5: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.649
===> backtranslation_recon_loss: 57.957
===> Total for class ihm: 118.607
=> Class sdm1
===> autoencoding_recon_loss: 89.034
===> backtranslation_recon_loss: 85.381
===> Total for class sdm1: 174.415
TOTAL: 293.021

EPOCH 5 TRAIN (5158.361s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 15505.411
===> backtranslation_recon_loss: 14826.389
===> Total for class ihm: 30331.800
=> Class sdm1
===> autoencoding_recon_loss: 22786.782
===> backtranslation_recon_loss: 21831.802
===> Total for class sdm1: 44618.584
TOTAL: 74950.385

EPOCH 5 DEV (166.825s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 45079.977
===> backtranslation_recon_loss: 34187.646
===> Total for class ihm: 79267.623
=> Class sdm1
===> autoencoding_recon_loss: 24282.844
===> backtranslation_recon_loss: 37923.026
===> Total for class sdm1: 62205.871
TOTAL: 141473.494

No improvement in 2 epochs (best dev set loss: 122831.609291)
Not saving checkpoint; no improvement made

STARTING EPOCH 6
GENERATOR Train epoch 6: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.019
===> backtranslation_recon_loss: 57.139
===> Total for class ihm: 117.158
=> Class sdm1
===> autoencoding_recon_loss: 92.160
===> backtranslation_recon_loss: 88.641
===> Total for class sdm1: 180.800
TOTAL: 297.958
GENERATOR Train epoch 6: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.478
===> backtranslation_recon_loss: 56.372
===> Total for class ihm: 115.850
=> Class sdm1
===> autoencoding_recon_loss: 89.683
===> backtranslation_recon_loss: 86.650
===> Total for class sdm1: 176.333
TOTAL: 292.183
GENERATOR Train epoch 6: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.768
===> backtranslation_recon_loss: 55.740
===> Total for class ihm: 114.509
=> Class sdm1
===> autoencoding_recon_loss: 89.358
===> backtranslation_recon_loss: 85.580
===> Total for class sdm1: 174.938
TOTAL: 289.446
GENERATOR Train epoch 6: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.835
===> backtranslation_recon_loss: 55.695
===> Total for class ihm: 114.530
=> Class sdm1
===> autoencoding_recon_loss: 88.403
===> backtranslation_recon_loss: 84.694
===> Total for class sdm1: 173.098
TOTAL: 287.628
GENERATOR Train epoch 6: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.992
===> backtranslation_recon_loss: 55.994
===> Total for class ihm: 114.987
=> Class sdm1
===> autoencoding_recon_loss: 88.262
===> backtranslation_recon_loss: 84.770
===> Total for class sdm1: 173.032
TOTAL: 288.019
GENERATOR Train epoch 6: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.991
===> backtranslation_recon_loss: 56.018
===> Total for class ihm: 115.009
=> Class sdm1
===> autoencoding_recon_loss: 88.627
===> backtranslation_recon_loss: 84.835
===> Total for class sdm1: 173.462
TOTAL: 288.471
GENERATOR Train epoch 6: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.000
===> backtranslation_recon_loss: 55.957
===> Total for class ihm: 114.958
=> Class sdm1
===> autoencoding_recon_loss: 88.307
===> backtranslation_recon_loss: 84.591
===> Total for class sdm1: 172.898
TOTAL: 287.855
GENERATOR Train epoch 6: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.075
===> backtranslation_recon_loss: 56.054
===> Total for class ihm: 115.128
=> Class sdm1
===> autoencoding_recon_loss: 88.252
===> backtranslation_recon_loss: 84.541
===> Total for class sdm1: 172.793
TOTAL: 287.922
GENERATOR Train epoch 6: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.002
===> backtranslation_recon_loss: 55.966
===> Total for class ihm: 114.968
=> Class sdm1
===> autoencoding_recon_loss: 87.964
===> backtranslation_recon_loss: 84.384
===> Total for class sdm1: 172.349
TOTAL: 287.316
GENERATOR Train epoch 6: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.908
===> backtranslation_recon_loss: 55.855
===> Total for class ihm: 114.763
=> Class sdm1
===> autoencoding_recon_loss: 87.621
===> backtranslation_recon_loss: 83.958
===> Total for class sdm1: 171.579
TOTAL: 286.342
GENERATOR Train epoch 6: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.906
===> backtranslation_recon_loss: 55.788
===> Total for class ihm: 114.695
=> Class sdm1
===> autoencoding_recon_loss: 87.430
===> backtranslation_recon_loss: 83.817
===> Total for class sdm1: 171.247
TOTAL: 285.941
GENERATOR Train epoch 6: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.693
===> backtranslation_recon_loss: 55.549
===> Total for class ihm: 114.242
=> Class sdm1
===> autoencoding_recon_loss: 87.373
===> backtranslation_recon_loss: 83.699
===> Total for class sdm1: 171.072
TOTAL: 285.314
GENERATOR Train epoch 6: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.572
===> backtranslation_recon_loss: 55.454
===> Total for class ihm: 114.026
=> Class sdm1
===> autoencoding_recon_loss: 87.450
===> backtranslation_recon_loss: 83.632
===> Total for class sdm1: 171.082
TOTAL: 285.108
GENERATOR Train epoch 6: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.540
===> backtranslation_recon_loss: 55.363
===> Total for class ihm: 113.902
=> Class sdm1
===> autoencoding_recon_loss: 87.151
===> backtranslation_recon_loss: 83.341
===> Total for class sdm1: 170.493
TOTAL: 284.395
GENERATOR Train epoch 6: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.364
===> backtranslation_recon_loss: 55.179
===> Total for class ihm: 113.542
=> Class sdm1
===> autoencoding_recon_loss: 86.846
===> backtranslation_recon_loss: 83.031
===> Total for class sdm1: 169.877
TOTAL: 283.419
GENERATOR Train epoch 6: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.299
===> backtranslation_recon_loss: 55.158
===> Total for class ihm: 113.457
=> Class sdm1
===> autoencoding_recon_loss: 86.638
===> backtranslation_recon_loss: 82.799
===> Total for class sdm1: 169.437
TOTAL: 282.894
GENERATOR Train epoch 6: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.435
===> backtranslation_recon_loss: 55.309
===> Total for class ihm: 113.744
=> Class sdm1
===> autoencoding_recon_loss: 86.526
===> backtranslation_recon_loss: 82.764
===> Total for class sdm1: 169.290
TOTAL: 283.034
GENERATOR Train epoch 6: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 58.430
===> backtranslation_recon_loss: 55.319
===> Total for class ihm: 113.749
=> Class sdm1
===> autoencoding_recon_loss: 86.469
===> backtranslation_recon_loss: 82.702
===> Total for class sdm1: 169.171
TOTAL: 282.920

EPOCH 6 TRAIN (5160.547s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 14958.090
===> backtranslation_recon_loss: 14154.737
===> Total for class ihm: 29112.827
=> Class sdm1
===> autoencoding_recon_loss: 22125.732
===> backtranslation_recon_loss: 21151.721
===> Total for class sdm1: 43277.452
TOTAL: 72390.279

EPOCH 6 DEV (166.735s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 43218.930
===> backtranslation_recon_loss: 30065.318
===> Total for class ihm: 73284.248
=> Class sdm1
===> autoencoding_recon_loss: 26391.846
===> backtranslation_recon_loss: 32161.202
===> Total for class sdm1: 58553.048
TOTAL: 131837.296

No improvement in 3 epochs (best dev set loss: 122831.609291)
STOPPING EARLY
Computing reconstruction loss...
Loaded checkpoint; best model ready now.

TRAINING SET
Losses:
=> Class ihm
===> autoencoding_recon_loss: 81.383
===> backtranslation_recon_loss: 82.120
===> Total for class ihm: 163.503
=> Class sdm1
===> autoencoding_recon_loss: 107.778
===> backtranslation_recon_loss: 115.262
===> Total for class sdm1: 223.040
TOTAL: 386.543

DEV SET
Losses:
=> Class ihm
===> autoencoding_recon_loss: 85.484
===> backtranslation_recon_loss: 84.416
===> Total for class ihm: 169.900
=> Class sdm1
===> autoencoding_recon_loss: 102.499
===> backtranslation_recon_loss: 110.930
===> Total for class sdm1: 213.429
TOTAL: 383.329

Completed training run in 33764.298 seconds
