Running training with mode ae
Noising 25.000% of input features
Constructing model...
Done constructing model.
CNNAdversarialMultidecoder(
  (encoder_conv): Sequential(
    (conv2d_0): Conv2d (1, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_0): SELU
    (maxpool2d_0): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_1): SELU
    (maxpool2d_1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential(
    (lin_0): Linear(in_features=14336, out_features=2048)
    (SELU_0): SELU
    (lin_1): Linear(in_features=2048, out_features=2048)
    (SELU_1): SELU
    (lin_final): Linear(in_features=2048, out_features=256)
    (SELU_final): SELU
  )
  (decoder_fc_ihm): Sequential(
    (lin_0): Linear(in_features=256, out_features=2048)
    (SELU_0): SELU
    (lin_1): Linear(in_features=2048, out_features=2048)
    (SELU_1): SELU
    (lin_final): Linear(in_features=2048, out_features=14336)
    (SELU_final): SELU
  )
  (decoder_deconv_ihm): Sequential(
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (decoder_fc_sdm1): Sequential(
    (lin_0): Linear(in_features=256, out_features=2048)
    (SELU_0): SELU
    (lin_1): Linear(in_features=2048, out_features=2048)
    (SELU_1): SELU
    (lin_final): Linear(in_features=2048, out_features=14336)
    (SELU_final): SELU
  )
  (decoder_deconv_sdm1): Sequential(
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (adversary): Sequential(
    (lin_0): Linear(in_features=256, out_features=256)
    (Sigmoid_0): Sigmoid()
    (lin_final): Linear(in_features=256, out_features=1)
    (Sigmoid_final): Sigmoid()
  )
)
Model has 104120835 trainable parameters
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Completed setup in 118.028 seconds
Starting training!

STARTING EPOCH 1
Train epoch 1: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.714
===> backtranslation_recon_loss: 0.759
===> adversarial_loss: -0.788
===> Total for class ihm: 0.685
=> Class sdm1
===> autoencoding_recon_loss: 0.656
===> backtranslation_recon_loss: 0.715
===> adversarial_loss: -0.768
===> Total for class sdm1: 0.603
TOTAL: 1.288
Train epoch 1: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.638
===> backtranslation_recon_loss: 0.672
===> adversarial_loss: -0.786
===> Total for class ihm: 0.524
=> Class sdm1
===> autoencoding_recon_loss: 0.569
===> backtranslation_recon_loss: 0.618
===> adversarial_loss: -0.767
===> Total for class sdm1: 0.420
TOTAL: 0.944
Train epoch 1: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.588
===> backtranslation_recon_loss: 0.617
===> adversarial_loss: -0.807
===> Total for class ihm: 0.398
=> Class sdm1
===> autoencoding_recon_loss: 0.518
===> backtranslation_recon_loss: 0.560
===> adversarial_loss: -0.788
===> Total for class sdm1: 0.290
TOTAL: 0.687
Train epoch 1: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.549
===> backtranslation_recon_loss: 0.576
===> adversarial_loss: -0.797
===> Total for class ihm: 0.329
=> Class sdm1
===> autoencoding_recon_loss: 0.488
===> backtranslation_recon_loss: 0.523
===> adversarial_loss: -0.794
===> Total for class sdm1: 0.218
TOTAL: 0.546
Train epoch 1: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.510
===> backtranslation_recon_loss: 0.537
===> adversarial_loss: -0.778
===> Total for class ihm: 0.270
=> Class sdm1
===> autoencoding_recon_loss: 0.459
===> backtranslation_recon_loss: 0.491
===> adversarial_loss: -0.788
===> Total for class sdm1: 0.162
TOTAL: 0.432
Train epoch 1: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.470
===> backtranslation_recon_loss: 0.495
===> adversarial_loss: -0.765
===> Total for class ihm: 0.200
=> Class sdm1
===> autoencoding_recon_loss: 0.431
===> backtranslation_recon_loss: 0.460
===> adversarial_loss: -0.775
===> Total for class sdm1: 0.116
TOTAL: 0.316
Train epoch 1: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.431
===> backtranslation_recon_loss: 0.454
===> adversarial_loss: -0.751
===> Total for class ihm: 0.133
=> Class sdm1
===> autoencoding_recon_loss: 0.402
===> backtranslation_recon_loss: 0.430
===> adversarial_loss: -0.768
===> Total for class sdm1: 0.064
TOTAL: 0.197
Train epoch 1: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.399
===> backtranslation_recon_loss: 0.420
===> adversarial_loss: -0.748
===> Total for class ihm: 0.070
=> Class sdm1
===> autoencoding_recon_loss: 0.376
===> backtranslation_recon_loss: 0.401
===> adversarial_loss: -0.755
===> Total for class sdm1: 0.022
TOTAL: 0.092
Train epoch 1: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.369
===> backtranslation_recon_loss: 0.388
===> adversarial_loss: -0.743
===> Total for class ihm: 0.015
=> Class sdm1
===> autoencoding_recon_loss: 0.353
===> backtranslation_recon_loss: 0.376
===> adversarial_loss: -0.748
===> Total for class sdm1: -0.019
TOTAL: -0.004
Train epoch 1: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.344
===> backtranslation_recon_loss: 0.361
===> adversarial_loss: -0.736
===> Total for class ihm: -0.031
=> Class sdm1
===> autoencoding_recon_loss: 0.334
===> backtranslation_recon_loss: 0.355
===> adversarial_loss: -0.745
===> Total for class sdm1: -0.056
TOTAL: -0.087
Train epoch 1: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.321
===> backtranslation_recon_loss: 0.336
===> adversarial_loss: -0.729
===> Total for class ihm: -0.072
=> Class sdm1
===> autoencoding_recon_loss: 0.318
===> backtranslation_recon_loss: 0.337
===> adversarial_loss: -0.743
===> Total for class sdm1: -0.088
TOTAL: -0.160
Train epoch 1: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.303
===> backtranslation_recon_loss: 0.316
===> adversarial_loss: -0.724
===> Total for class ihm: -0.105
=> Class sdm1
===> autoencoding_recon_loss: 0.303
===> backtranslation_recon_loss: 0.321
===> adversarial_loss: -0.742
===> Total for class sdm1: -0.117
TOTAL: -0.222
Train epoch 1: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.288
===> backtranslation_recon_loss: 0.299
===> adversarial_loss: -0.722
===> Total for class ihm: -0.135
=> Class sdm1
===> autoencoding_recon_loss: 0.291
===> backtranslation_recon_loss: 0.307
===> adversarial_loss: -0.738
===> Total for class sdm1: -0.140
TOTAL: -0.275
Train epoch 1: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.274
===> backtranslation_recon_loss: 0.284
===> adversarial_loss: -0.717
===> Total for class ihm: -0.159
=> Class sdm1
===> autoencoding_recon_loss: 0.280
===> backtranslation_recon_loss: 0.295
===> adversarial_loss: -0.738
===> Total for class sdm1: -0.163
TOTAL: -0.322
Train epoch 1: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.262
===> backtranslation_recon_loss: 0.272
===> adversarial_loss: -0.718
===> Total for class ihm: -0.184
=> Class sdm1
===> autoencoding_recon_loss: 0.270
===> backtranslation_recon_loss: 0.283
===> adversarial_loss: -0.733
===> Total for class sdm1: -0.180
TOTAL: -0.364
Train epoch 1: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.252
===> backtranslation_recon_loss: 0.261
===> adversarial_loss: -0.718
===> Total for class ihm: -0.205
=> Class sdm1
===> autoencoding_recon_loss: 0.261
===> backtranslation_recon_loss: 0.273
===> adversarial_loss: -0.728
===> Total for class sdm1: -0.195
TOTAL: -0.400
Train epoch 1: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.243
===> backtranslation_recon_loss: 0.250
===> adversarial_loss: -0.718
===> Total for class ihm: -0.225
=> Class sdm1
===> autoencoding_recon_loss: 0.253
===> backtranslation_recon_loss: 0.264
===> adversarial_loss: -0.726
===> Total for class sdm1: -0.208
TOTAL: -0.433
Train epoch 1: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.235
===> backtranslation_recon_loss: 0.241
===> adversarial_loss: -0.717
===> Total for class ihm: -0.242
=> Class sdm1
===> autoencoding_recon_loss: 0.246
===> backtranslation_recon_loss: 0.256
===> adversarial_loss: -0.723
===> Total for class sdm1: -0.220
TOTAL: -0.462

EPOCH 1 TRAIN (7312.649s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.229
===> backtranslation_recon_loss: 0.235
===> adversarial_loss: -0.718
===> Total for class ihm: -0.254
=> Class sdm1
===> autoencoding_recon_loss: 0.241
===> backtranslation_recon_loss: 0.250
===> adversarial_loss: -0.720
===> Total for class sdm1: -0.229
TOTAL: -0.484

EPOCH 1 DEV (208.338s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.088
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.718
===> Total for class ihm: -0.542
=> Class sdm1
===> autoencoding_recon_loss: 0.120
===> backtranslation_recon_loss: 0.121
===> adversarial_loss: -0.672
===> Total for class sdm1: -0.431
TOTAL: -0.972

New best dev set loss: -0.972187
Saved checkpoint for model

STARTING EPOCH 2
Train epoch 2: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.084
===> backtranslation_recon_loss: 0.076
===> adversarial_loss: -0.743
===> Total for class ihm: -0.583
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.108
===> adversarial_loss: -0.648
===> Total for class sdm1: -0.424
TOTAL: -1.007
Train epoch 2: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.078
===> adversarial_loss: -0.699
===> Total for class ihm: -0.536
=> Class sdm1
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.110
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.463
TOTAL: -0.999
Train epoch 2: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.075
===> adversarial_loss: -0.696
===> Total for class ihm: -0.538
=> Class sdm1
===> autoencoding_recon_loss: 0.114
===> backtranslation_recon_loss: 0.107
===> adversarial_loss: -0.693
===> Total for class sdm1: -0.472
TOTAL: -1.010
Train epoch 2: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.082
===> backtranslation_recon_loss: 0.075
===> adversarial_loss: -0.699
===> Total for class ihm: -0.542
=> Class sdm1
===> autoencoding_recon_loss: 0.114
===> backtranslation_recon_loss: 0.107
===> adversarial_loss: -0.691
===> Total for class sdm1: -0.469
TOTAL: -1.011
Train epoch 2: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.082
===> backtranslation_recon_loss: 0.075
===> adversarial_loss: -0.701
===> Total for class ihm: -0.544
=> Class sdm1
===> autoencoding_recon_loss: 0.114
===> backtranslation_recon_loss: 0.108
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.467
TOTAL: -1.011
Train epoch 2: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.080
===> backtranslation_recon_loss: 0.073
===> adversarial_loss: -0.701
===> Total for class ihm: -0.548
=> Class sdm1
===> autoencoding_recon_loss: 0.112
===> backtranslation_recon_loss: 0.106
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.471
TOTAL: -1.019
Train epoch 2: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.079
===> backtranslation_recon_loss: 0.071
===> adversarial_loss: -0.693
===> Total for class ihm: -0.542
=> Class sdm1
===> autoencoding_recon_loss: 0.111
===> backtranslation_recon_loss: 0.104
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.482
TOTAL: -1.025
Train epoch 2: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.078
===> backtranslation_recon_loss: 0.070
===> adversarial_loss: -0.694
===> Total for class ihm: -0.546
=> Class sdm1
===> autoencoding_recon_loss: 0.109
===> backtranslation_recon_loss: 0.102
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.485
TOTAL: -1.031
Train epoch 2: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.076
===> backtranslation_recon_loss: 0.068
===> adversarial_loss: -0.696
===> Total for class ihm: -0.551
=> Class sdm1
===> autoencoding_recon_loss: 0.108
===> backtranslation_recon_loss: 0.100
===> adversarial_loss: -0.694
===> Total for class sdm1: -0.486
TOTAL: -1.037
Train epoch 2: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.075
===> backtranslation_recon_loss: 0.067
===> adversarial_loss: -0.695
===> Total for class ihm: -0.552
=> Class sdm1
===> autoencoding_recon_loss: 0.107
===> backtranslation_recon_loss: 0.099
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.489
TOTAL: -1.041
Train epoch 2: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.074
===> backtranslation_recon_loss: 0.066
===> adversarial_loss: -0.694
===> Total for class ihm: -0.553
=> Class sdm1
===> autoencoding_recon_loss: 0.106
===> backtranslation_recon_loss: 0.098
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.493
TOTAL: -1.046
Train epoch 2: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.073
===> backtranslation_recon_loss: 0.065
===> adversarial_loss: -0.692
===> Total for class ihm: -0.554
=> Class sdm1
===> autoencoding_recon_loss: 0.105
===> backtranslation_recon_loss: 0.096
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.497
TOTAL: -1.051
Train epoch 2: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.072
===> backtranslation_recon_loss: 0.064
===> adversarial_loss: -0.694
===> Total for class ihm: -0.558
=> Class sdm1
===> autoencoding_recon_loss: 0.104
===> backtranslation_recon_loss: 0.095
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.497
TOTAL: -1.055
Train epoch 2: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.072
===> backtranslation_recon_loss: 0.063
===> adversarial_loss: -0.696
===> Total for class ihm: -0.561
=> Class sdm1
===> autoencoding_recon_loss: 0.102
===> backtranslation_recon_loss: 0.094
===> adversarial_loss: -0.694
===> Total for class sdm1: -0.498
TOTAL: -1.059
Train epoch 2: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.071
===> backtranslation_recon_loss: 0.062
===> adversarial_loss: -0.692
===> Total for class ihm: -0.559
=> Class sdm1
===> autoencoding_recon_loss: 0.101
===> backtranslation_recon_loss: 0.093
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.504
TOTAL: -1.063
Train epoch 2: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.070
===> backtranslation_recon_loss: 0.062
===> adversarial_loss: -0.691
===> Total for class ihm: -0.560
=> Class sdm1
===> autoencoding_recon_loss: 0.101
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.506
TOTAL: -1.066
Train epoch 2: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.070
===> backtranslation_recon_loss: 0.061
===> adversarial_loss: -0.692
===> Total for class ihm: -0.562
=> Class sdm1
===> autoencoding_recon_loss: 0.100
===> backtranslation_recon_loss: 0.091
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.507
TOTAL: -1.069
Train epoch 2: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.069
===> backtranslation_recon_loss: 0.060
===> adversarial_loss: -0.693
===> Total for class ihm: -0.564
=> Class sdm1
===> autoencoding_recon_loss: 0.099
===> backtranslation_recon_loss: 0.090
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.508
TOTAL: -1.072

EPOCH 2 TRAIN (7320.924s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.069
===> backtranslation_recon_loss: 0.060
===> adversarial_loss: -0.695
===> Total for class ihm: -0.567
=> Class sdm1
===> autoencoding_recon_loss: 0.099
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.507
TOTAL: -1.074

EPOCH 2 DEV (208.347s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.059
===> backtranslation_recon_loss: 0.049
===> adversarial_loss: -0.669
===> Total for class ihm: -0.561
=> Class sdm1
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.071
===> adversarial_loss: -0.718
===> Total for class sdm1: -0.564
TOTAL: -1.126

New best dev set loss: -1.125650
Saved checkpoint for model

STARTING EPOCH 3
Train epoch 3: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.057
===> backtranslation_recon_loss: 0.048
===> adversarial_loss: -0.704
===> Total for class ihm: -0.599
=> Class sdm1
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.071
===> adversarial_loss: -0.688
===> Total for class sdm1: -0.534
TOTAL: -1.133
