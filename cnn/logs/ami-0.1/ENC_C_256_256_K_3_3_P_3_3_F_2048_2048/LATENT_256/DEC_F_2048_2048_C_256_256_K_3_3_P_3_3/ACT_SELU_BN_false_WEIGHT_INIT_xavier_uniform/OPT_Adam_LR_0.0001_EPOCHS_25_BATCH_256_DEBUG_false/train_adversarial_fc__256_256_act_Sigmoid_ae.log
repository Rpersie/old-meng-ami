Running training with mode ae
Using adversarial loss
Noising 25.000% of input features
Constructing model...
Done constructing model.
CNNAdversarialMultidecoder(
  (encoder_conv): Sequential(
    (conv2d_0): Conv2d (1, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_0): SELU
    (maxpool2d_0): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
    (conv2d_1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1))
    (SELU_1): SELU
    (maxpool2d_1): MaxPool2d(kernel_size=(1, 3), stride=(1, 3), dilation=(1, 1))
  )
  (encoder_fc): Sequential(
    (lin_0): Linear(in_features=14336, out_features=2048)
    (SELU_0): SELU
    (lin_1): Linear(in_features=2048, out_features=2048)
    (SELU_1): SELU
    (lin_final): Linear(in_features=2048, out_features=256)
    (SELU_final): SELU
  )
  (decoder_fc_ihm): Sequential(
    (lin_0): Linear(in_features=256, out_features=2048)
    (SELU_0): SELU
    (lin_1): Linear(in_features=2048, out_features=2048)
    (SELU_1): SELU
    (lin_final): Linear(in_features=2048, out_features=14336)
    (SELU_final): SELU
  )
  (decoder_deconv_ihm): Sequential(
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (decoder_fc_sdm1): Sequential(
    (lin_0): Linear(in_features=256, out_features=2048)
    (SELU_0): SELU
    (lin_1): Linear(in_features=2048, out_features=2048)
    (SELU_1): SELU
    (lin_final): Linear(in_features=2048, out_features=14336)
    (SELU_final): SELU
  )
  (decoder_deconv_sdm1): Sequential(
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_0): SELU
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 3), stride=(1, 3), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))
    (SELU_1): SELU
  )
  (adversary): Sequential(
    (lin_0): Linear(in_features=256, out_features=256)
    (Sigmoid_0): Sigmoid()
    (lin_1): Linear(in_features=256, out_features=256)
    (Sigmoid_1): Sigmoid()
    (lin_final): Linear(in_features=256, out_features=1)
    (Sigmoid_final): Sigmoid()
  )
)
Model has 104186627 trainable parameters
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Completed setup in 146.042 seconds
Starting training!

STARTING EPOCH 1
Train epoch 1: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.768
===> backtranslation_recon_loss: 0.782
===> adversarial_loss: -0.702
===> Total for class ihm: 0.847
=> Class sdm1
===> autoencoding_recon_loss: 0.673
===> backtranslation_recon_loss: 0.707
===> adversarial_loss: -0.697
===> Total for class sdm1: 0.683
TOTAL: 1.530
Train epoch 1: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.661
===> backtranslation_recon_loss: 0.678
===> adversarial_loss: -0.704
===> Total for class ihm: 0.635
=> Class sdm1
===> autoencoding_recon_loss: 0.582
===> backtranslation_recon_loss: 0.616
===> adversarial_loss: -0.697
===> Total for class sdm1: 0.500
TOTAL: 1.136
Train epoch 1: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.599
===> backtranslation_recon_loss: 0.615
===> adversarial_loss: -0.704
===> Total for class ihm: 0.510
=> Class sdm1
===> autoencoding_recon_loss: 0.528
===> backtranslation_recon_loss: 0.562
===> adversarial_loss: -0.694
===> Total for class sdm1: 0.396
TOTAL: 0.906
Train epoch 1: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.527
===> backtranslation_recon_loss: 0.544
===> adversarial_loss: -0.701
===> Total for class ihm: 0.370
=> Class sdm1
===> autoencoding_recon_loss: 0.475
===> backtranslation_recon_loss: 0.506
===> adversarial_loss: -0.695
===> Total for class sdm1: 0.287
TOTAL: 0.657
Train epoch 1: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.469
===> backtranslation_recon_loss: 0.486
===> adversarial_loss: -0.694
===> Total for class ihm: 0.261
=> Class sdm1
===> autoencoding_recon_loss: 0.437
===> backtranslation_recon_loss: 0.466
===> adversarial_loss: -0.701
===> Total for class sdm1: 0.202
TOTAL: 0.463
Train epoch 1: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.428
===> backtranslation_recon_loss: 0.444
===> adversarial_loss: -0.694
===> Total for class ihm: 0.177
=> Class sdm1
===> autoencoding_recon_loss: 0.409
===> backtranslation_recon_loss: 0.436
===> adversarial_loss: -0.700
===> Total for class sdm1: 0.144
TOTAL: 0.322
Train epoch 1: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.393
===> backtranslation_recon_loss: 0.408
===> adversarial_loss: -0.691
===> Total for class ihm: 0.110
=> Class sdm1
===> autoencoding_recon_loss: 0.382
===> backtranslation_recon_loss: 0.406
===> adversarial_loss: -0.703
===> Total for class sdm1: 0.086
TOTAL: 0.196
Train epoch 1: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.367
===> backtranslation_recon_loss: 0.380
===> adversarial_loss: -0.697
===> Total for class ihm: 0.050
=> Class sdm1
===> autoencoding_recon_loss: 0.360
===> backtranslation_recon_loss: 0.382
===> adversarial_loss: -0.697
===> Total for class sdm1: 0.046
TOTAL: 0.096
Train epoch 1: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.344
===> backtranslation_recon_loss: 0.355
===> adversarial_loss: -0.697
===> Total for class ihm: 0.002
=> Class sdm1
===> autoencoding_recon_loss: 0.342
===> backtranslation_recon_loss: 0.362
===> adversarial_loss: -0.697
===> Total for class sdm1: 0.008
TOTAL: 0.010
Train epoch 1: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.325
===> backtranslation_recon_loss: 0.334
===> adversarial_loss: -0.694
===> Total for class ihm: -0.036
=> Class sdm1
===> autoencoding_recon_loss: 0.327
===> backtranslation_recon_loss: 0.346
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.027
TOTAL: -0.062
Train epoch 1: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.308
===> backtranslation_recon_loss: 0.316
===> adversarial_loss: -0.692
===> Total for class ihm: -0.068
=> Class sdm1
===> autoencoding_recon_loss: 0.314
===> backtranslation_recon_loss: 0.331
===> adversarial_loss: -0.702
===> Total for class sdm1: -0.057
TOTAL: -0.124
Train epoch 1: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.294
===> backtranslation_recon_loss: 0.301
===> adversarial_loss: -0.690
===> Total for class ihm: -0.095
=> Class sdm1
===> autoencoding_recon_loss: 0.304
===> backtranslation_recon_loss: 0.319
===> adversarial_loss: -0.703
===> Total for class sdm1: -0.081
TOTAL: -0.175
Train epoch 1: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.283
===> backtranslation_recon_loss: 0.289
===> adversarial_loss: -0.691
===> Total for class ihm: -0.119
=> Class sdm1
===> autoencoding_recon_loss: 0.294
===> backtranslation_recon_loss: 0.308
===> adversarial_loss: -0.703
===> Total for class sdm1: -0.100
TOTAL: -0.219
Train epoch 1: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.272
===> backtranslation_recon_loss: 0.277
===> adversarial_loss: -0.688
===> Total for class ihm: -0.138
=> Class sdm1
===> autoencoding_recon_loss: 0.285
===> backtranslation_recon_loss: 0.299
===> adversarial_loss: -0.705
===> Total for class sdm1: -0.121
TOTAL: -0.259
Train epoch 1: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.263
===> backtranslation_recon_loss: 0.268
===> adversarial_loss: -0.691
===> Total for class ihm: -0.159
=> Class sdm1
===> autoencoding_recon_loss: 0.277
===> backtranslation_recon_loss: 0.290
===> adversarial_loss: -0.702
===> Total for class sdm1: -0.135
TOTAL: -0.295
Train epoch 1: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.256
===> backtranslation_recon_loss: 0.259
===> adversarial_loss: -0.693
===> Total for class ihm: -0.178
=> Class sdm1
===> autoencoding_recon_loss: 0.270
===> backtranslation_recon_loss: 0.282
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.148
TOTAL: -0.326
Train epoch 1: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.248
===> backtranslation_recon_loss: 0.251
===> adversarial_loss: -0.694
===> Total for class ihm: -0.194
=> Class sdm1
===> autoencoding_recon_loss: 0.264
===> backtranslation_recon_loss: 0.275
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.160
TOTAL: -0.354
Train epoch 1: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.242
===> backtranslation_recon_loss: 0.244
===> adversarial_loss: -0.695
===> Total for class ihm: -0.209
=> Class sdm1
===> autoencoding_recon_loss: 0.258
===> backtranslation_recon_loss: 0.269
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.171
TOTAL: -0.380

EPOCH 1 TRAIN (7411.455s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.237
===> backtranslation_recon_loss: 0.239
===> adversarial_loss: -0.696
===> Total for class ihm: -0.221
=> Class sdm1
===> autoencoding_recon_loss: 0.254
===> backtranslation_recon_loss: 0.264
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.179
TOTAL: -0.399

EPOCH 1 DEV (216.623s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.116
===> adversarial_loss: -0.708
===> Total for class ihm: -0.468
=> Class sdm1
===> autoencoding_recon_loss: 0.152
===> backtranslation_recon_loss: 0.156
===> adversarial_loss: -0.678
===> Total for class sdm1: -0.371
TOTAL: -0.839

New best dev set loss: -0.839103
Saved checkpoint for model

STARTING EPOCH 2
Train epoch 2: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.120
===> backtranslation_recon_loss: 0.117
===> adversarial_loss: -0.738
===> Total for class ihm: -0.501
=> Class sdm1
===> autoencoding_recon_loss: 0.158
===> backtranslation_recon_loss: 0.158
===> adversarial_loss: -0.654
===> Total for class sdm1: -0.338
TOTAL: -0.839
Train epoch 2: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.120
===> backtranslation_recon_loss: 0.116
===> adversarial_loss: -0.703
===> Total for class ihm: -0.468
=> Class sdm1
===> autoencoding_recon_loss: 0.155
===> backtranslation_recon_loss: 0.156
===> adversarial_loss: -0.687
===> Total for class sdm1: -0.376
TOTAL: -0.844
Train epoch 2: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.114
===> adversarial_loss: -0.697
===> Total for class ihm: -0.465
=> Class sdm1
===> autoencoding_recon_loss: 0.154
===> backtranslation_recon_loss: 0.155
===> adversarial_loss: -0.692
===> Total for class sdm1: -0.384
TOTAL: -0.849
Train epoch 2: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.113
===> adversarial_loss: -0.701
===> Total for class ihm: -0.471
=> Class sdm1
===> autoencoding_recon_loss: 0.152
===> backtranslation_recon_loss: 0.153
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.384
TOTAL: -0.855
Train epoch 2: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.113
===> adversarial_loss: -0.703
===> Total for class ihm: -0.474
=> Class sdm1
===> autoencoding_recon_loss: 0.152
===> backtranslation_recon_loss: 0.153
===> adversarial_loss: -0.688
===> Total for class sdm1: -0.383
TOTAL: -0.857
Train epoch 2: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.114
===> adversarial_loss: -0.703
===> Total for class ihm: -0.471
=> Class sdm1
===> autoencoding_recon_loss: 0.153
===> backtranslation_recon_loss: 0.154
===> adversarial_loss: -0.688
===> Total for class sdm1: -0.381
TOTAL: -0.852
Train epoch 2: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.113
===> adversarial_loss: -0.694
===> Total for class ihm: -0.465
=> Class sdm1
===> autoencoding_recon_loss: 0.152
===> backtranslation_recon_loss: 0.153
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.392
TOTAL: -0.857
Train epoch 2: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.112
===> adversarial_loss: -0.695
===> Total for class ihm: -0.467
=> Class sdm1
===> autoencoding_recon_loss: 0.152
===> backtranslation_recon_loss: 0.153
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.391
TOTAL: -0.858
Train epoch 2: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.115
===> backtranslation_recon_loss: 0.112
===> adversarial_loss: -0.698
===> Total for class ihm: -0.471
=> Class sdm1
===> autoencoding_recon_loss: 0.151
===> backtranslation_recon_loss: 0.153
===> adversarial_loss: -0.693
===> Total for class sdm1: -0.389
TOTAL: -0.861
Train epoch 2: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.114
===> backtranslation_recon_loss: 0.111
===> adversarial_loss: -0.697
===> Total for class ihm: -0.472
=> Class sdm1
===> autoencoding_recon_loss: 0.150
===> backtranslation_recon_loss: 0.151
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.393
TOTAL: -0.865
Train epoch 2: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.114
===> backtranslation_recon_loss: 0.110
===> adversarial_loss: -0.695
===> Total for class ihm: -0.471
=> Class sdm1
===> autoencoding_recon_loss: 0.149
===> backtranslation_recon_loss: 0.151
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.397
TOTAL: -0.868
Train epoch 2: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.113
===> backtranslation_recon_loss: 0.110
===> adversarial_loss: -0.694
===> Total for class ihm: -0.471
=> Class sdm1
===> autoencoding_recon_loss: 0.149
===> backtranslation_recon_loss: 0.150
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.400
TOTAL: -0.871
Train epoch 2: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.112
===> backtranslation_recon_loss: 0.109
===> adversarial_loss: -0.696
===> Total for class ihm: -0.474
=> Class sdm1
===> autoencoding_recon_loss: 0.148
===> backtranslation_recon_loss: 0.150
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.399
TOTAL: -0.873
Train epoch 2: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.112
===> backtranslation_recon_loss: 0.109
===> adversarial_loss: -0.698
===> Total for class ihm: -0.477
=> Class sdm1
===> autoencoding_recon_loss: 0.147
===> backtranslation_recon_loss: 0.149
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.398
TOTAL: -0.875
Train epoch 2: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.112
===> backtranslation_recon_loss: 0.109
===> adversarial_loss: -0.694
===> Total for class ihm: -0.473
=> Class sdm1
===> autoencoding_recon_loss: 0.147
===> backtranslation_recon_loss: 0.149
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.402
TOTAL: -0.874
Train epoch 2: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.111
===> backtranslation_recon_loss: 0.108
===> adversarial_loss: -0.693
===> Total for class ihm: -0.473
=> Class sdm1
===> autoencoding_recon_loss: 0.146
===> backtranslation_recon_loss: 0.148
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.404
TOTAL: -0.878
Train epoch 2: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.111
===> backtranslation_recon_loss: 0.108
===> adversarial_loss: -0.694
===> Total for class ihm: -0.475
=> Class sdm1
===> autoencoding_recon_loss: 0.146
===> backtranslation_recon_loss: 0.148
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.404
TOTAL: -0.879
Train epoch 2: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.110
===> backtranslation_recon_loss: 0.108
===> adversarial_loss: -0.695
===> Total for class ihm: -0.477
=> Class sdm1
===> autoencoding_recon_loss: 0.145
===> backtranslation_recon_loss: 0.148
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.404
TOTAL: -0.881

EPOCH 2 TRAIN (7363.927s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.110
===> backtranslation_recon_loss: 0.107
===> adversarial_loss: -0.697
===> Total for class ihm: -0.480
=> Class sdm1
===> autoencoding_recon_loss: 0.145
===> backtranslation_recon_loss: 0.148
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.403
TOTAL: -0.883

EPOCH 2 DEV (209.748s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.103
===> backtranslation_recon_loss: 0.104
===> adversarial_loss: -0.659
===> Total for class ihm: -0.452
=> Class sdm1
===> autoencoding_recon_loss: 0.132
===> backtranslation_recon_loss: 0.136
===> adversarial_loss: -0.728
===> Total for class sdm1: -0.460
TOTAL: -0.913

New best dev set loss: -0.912826
Saved checkpoint for model

STARTING EPOCH 3
Train epoch 3: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.103
===> backtranslation_recon_loss: 0.104
===> adversarial_loss: -0.702
===> Total for class ihm: -0.494
=> Class sdm1
===> autoencoding_recon_loss: 0.139
===> backtranslation_recon_loss: 0.143
===> adversarial_loss: -0.691
===> Total for class sdm1: -0.409
TOTAL: -0.904
Train epoch 3: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.101
===> backtranslation_recon_loss: 0.101
===> adversarial_loss: -0.692
===> Total for class ihm: -0.490
=> Class sdm1
===> autoencoding_recon_loss: 0.136
===> backtranslation_recon_loss: 0.140
===> adversarial_loss: -0.700
===> Total for class sdm1: -0.424
TOTAL: -0.915
Train epoch 3: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.100
===> backtranslation_recon_loss: 0.100
===> adversarial_loss: -0.686
===> Total for class ihm: -0.486
=> Class sdm1
===> autoencoding_recon_loss: 0.135
===> backtranslation_recon_loss: 0.139
===> adversarial_loss: -0.707
===> Total for class sdm1: -0.433
TOTAL: -0.919
Train epoch 3: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.099
===> backtranslation_recon_loss: 0.099
===> adversarial_loss: -0.695
===> Total for class ihm: -0.497
=> Class sdm1
===> autoencoding_recon_loss: 0.133
===> backtranslation_recon_loss: 0.138
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.426
TOTAL: -0.923
Train epoch 3: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.099
===> backtranslation_recon_loss: 0.099
===> adversarial_loss: -0.698
===> Total for class ihm: -0.499
=> Class sdm1
===> autoencoding_recon_loss: 0.133
===> backtranslation_recon_loss: 0.138
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.424
TOTAL: -0.923
Train epoch 3: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.099
===> backtranslation_recon_loss: 0.100
===> adversarial_loss: -0.686
===> Total for class ihm: -0.487
=> Class sdm1
===> autoencoding_recon_loss: 0.134
===> backtranslation_recon_loss: 0.139
===> adversarial_loss: -0.705
===> Total for class sdm1: -0.432
TOTAL: -0.919
Train epoch 3: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.099
===> backtranslation_recon_loss: 0.100
===> adversarial_loss: -0.685
===> Total for class ihm: -0.487
=> Class sdm1
===> autoencoding_recon_loss: 0.134
===> backtranslation_recon_loss: 0.138
===> adversarial_loss: -0.707
===> Total for class sdm1: -0.435
TOTAL: -0.922
Train epoch 3: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.098
===> backtranslation_recon_loss: 0.099
===> adversarial_loss: -0.690
===> Total for class ihm: -0.493
=> Class sdm1
===> autoencoding_recon_loss: 0.133
===> backtranslation_recon_loss: 0.139
===> adversarial_loss: -0.702
===> Total for class sdm1: -0.430
TOTAL: -0.922
Train epoch 3: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.098
===> backtranslation_recon_loss: 0.099
===> adversarial_loss: -0.697
===> Total for class ihm: -0.499
=> Class sdm1
===> autoencoding_recon_loss: 0.133
===> backtranslation_recon_loss: 0.138
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.424
TOTAL: -0.923
Train epoch 3: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.098
===> backtranslation_recon_loss: 0.099
===> adversarial_loss: -0.694
===> Total for class ihm: -0.497
=> Class sdm1
===> autoencoding_recon_loss: 0.132
===> backtranslation_recon_loss: 0.138
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.428
TOTAL: -0.925
Train epoch 3: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.097
===> backtranslation_recon_loss: 0.098
===> adversarial_loss: -0.698
===> Total for class ihm: -0.502
=> Class sdm1
===> autoencoding_recon_loss: 0.132
===> backtranslation_recon_loss: 0.137
===> adversarial_loss: -0.694
===> Total for class sdm1: -0.425
TOTAL: -0.927
Train epoch 3: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.097
===> backtranslation_recon_loss: 0.098
===> adversarial_loss: -0.697
===> Total for class ihm: -0.502
=> Class sdm1
===> autoencoding_recon_loss: 0.131
===> backtranslation_recon_loss: 0.137
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.426
TOTAL: -0.929
Train epoch 3: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.097
===> backtranslation_recon_loss: 0.098
===> adversarial_loss: -0.700
===> Total for class ihm: -0.505
=> Class sdm1
===> autoencoding_recon_loss: 0.131
===> backtranslation_recon_loss: 0.137
===> adversarial_loss: -0.692
===> Total for class sdm1: -0.424
TOTAL: -0.929
Train epoch 3: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.097
===> backtranslation_recon_loss: 0.098
===> adversarial_loss: -0.699
===> Total for class ihm: -0.505
=> Class sdm1
===> autoencoding_recon_loss: 0.131
===> backtranslation_recon_loss: 0.136
===> adversarial_loss: -0.693
===> Total for class sdm1: -0.426
TOTAL: -0.931
Train epoch 3: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.096
===> backtranslation_recon_loss: 0.098
===> adversarial_loss: -0.697
===> Total for class ihm: -0.503
=> Class sdm1
===> autoencoding_recon_loss: 0.131
===> backtranslation_recon_loss: 0.136
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.428
TOTAL: -0.931
Train epoch 3: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.096
===> backtranslation_recon_loss: 0.097
===> adversarial_loss: -0.695
===> Total for class ihm: -0.502
=> Class sdm1
===> autoencoding_recon_loss: 0.130
===> backtranslation_recon_loss: 0.136
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.430
TOTAL: -0.932
Train epoch 3: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.096
===> backtranslation_recon_loss: 0.097
===> adversarial_loss: -0.693
===> Total for class ihm: -0.500
=> Class sdm1
===> autoencoding_recon_loss: 0.130
===> backtranslation_recon_loss: 0.136
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.433
TOTAL: -0.934
Train epoch 3: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.096
===> backtranslation_recon_loss: 0.097
===> adversarial_loss: -0.694
===> Total for class ihm: -0.502
=> Class sdm1
===> autoencoding_recon_loss: 0.130
===> backtranslation_recon_loss: 0.136
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.433
TOTAL: -0.934

EPOCH 3 TRAIN (7351.160s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.095
===> backtranslation_recon_loss: 0.096
===> adversarial_loss: -0.696
===> Total for class ihm: -0.504
=> Class sdm1
===> autoencoding_recon_loss: 0.129
===> backtranslation_recon_loss: 0.135
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.431
TOTAL: -0.935

EPOCH 3 DEV (209.082s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.095
===> backtranslation_recon_loss: 0.098
===> adversarial_loss: -0.653
===> Total for class ihm: -0.459
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.133
===> adversarial_loss: -0.735
===> Total for class sdm1: -0.482
TOTAL: -0.941

New best dev set loss: -0.941380
Saved checkpoint for model

STARTING EPOCH 4
Train epoch 4: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.092
===> backtranslation_recon_loss: 0.094
===> adversarial_loss: -0.695
===> Total for class ihm: -0.509
=> Class sdm1
===> autoencoding_recon_loss: 0.125
===> backtranslation_recon_loss: 0.132
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.439
TOTAL: -0.948
Train epoch 4: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.092
===> backtranslation_recon_loss: 0.095
===> adversarial_loss: -0.713
===> Total for class ihm: -0.526
=> Class sdm1
===> autoencoding_recon_loss: 0.124
===> backtranslation_recon_loss: 0.131
===> adversarial_loss: -0.679
===> Total for class sdm1: -0.424
TOTAL: -0.950
Train epoch 4: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.090
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.702
===> Total for class ihm: -0.520
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.435
TOTAL: -0.955
Train epoch 4: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.090
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.706
===> Total for class ihm: -0.525
=> Class sdm1
===> autoencoding_recon_loss: 0.122
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.685
===> Total for class sdm1: -0.433
TOTAL: -0.958
Train epoch 4: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.090
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.693
===> Total for class ihm: -0.511
=> Class sdm1
===> autoencoding_recon_loss: 0.122
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.445
TOTAL: -0.956
Train epoch 4: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.697
===> Total for class ihm: -0.515
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.694
===> Total for class sdm1: -0.441
TOTAL: -0.956
Train epoch 4: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.696
===> Total for class ihm: -0.515
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.442
TOTAL: -0.957
Train epoch 4: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.694
===> Total for class ihm: -0.513
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.444
TOTAL: -0.957
Train epoch 4: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.697
===> Total for class ihm: -0.515
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.131
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.441
TOTAL: -0.957
Train epoch 4: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.091
===> adversarial_loss: -0.694
===> Total for class ihm: -0.514
=> Class sdm1
===> autoencoding_recon_loss: 0.122
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.445
TOTAL: -0.959
Train epoch 4: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.694
===> Total for class ihm: -0.513
=> Class sdm1
===> autoencoding_recon_loss: 0.122
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.445
TOTAL: -0.958
Train epoch 4: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.692
===> Total for class ihm: -0.511
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.131
===> adversarial_loss: -0.700
===> Total for class sdm1: -0.446
TOTAL: -0.958
Train epoch 4: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.693
===> Total for class ihm: -0.512
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.446
TOTAL: -0.958
Train epoch 4: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.694
===> Total for class ihm: -0.514
=> Class sdm1
===> autoencoding_recon_loss: 0.122
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.445
TOTAL: -0.959
Train epoch 4: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.698
===> Total for class ihm: -0.517
=> Class sdm1
===> autoencoding_recon_loss: 0.122
===> backtranslation_recon_loss: 0.130
===> adversarial_loss: -0.694
===> Total for class sdm1: -0.441
TOTAL: -0.959
Train epoch 4: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.698
===> Total for class ihm: -0.517
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.131
===> adversarial_loss: -0.694
===> Total for class sdm1: -0.440
TOTAL: -0.957
Train epoch 4: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.700
===> Total for class ihm: -0.518
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.131
===> adversarial_loss: -0.692
===> Total for class sdm1: -0.438
TOTAL: -0.955
Train epoch 4: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.698
===> Total for class ihm: -0.516
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.131
===> adversarial_loss: -0.694
===> Total for class sdm1: -0.440
TOTAL: -0.956

EPOCH 4 TRAIN (7350.869s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.089
===> backtranslation_recon_loss: 0.092
===> adversarial_loss: -0.696
===> Total for class ihm: -0.515
=> Class sdm1
===> autoencoding_recon_loss: 0.123
===> backtranslation_recon_loss: 0.131
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.442
TOTAL: -0.957

EPOCH 4 DEV (209.582s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.093
===> backtranslation_recon_loss: 0.094
===> adversarial_loss: -0.580
===> Total for class ihm: -0.394
=> Class sdm1
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.821
===> Total for class sdm1: -0.576
TOTAL: -0.970

New best dev set loss: -0.970214
Saved checkpoint for model

STARTING EPOCH 5
Train epoch 5: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.675
===> Total for class ihm: -0.503
=> Class sdm1
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.718
===> Total for class sdm1: -0.476
TOTAL: -0.979
Train epoch 5: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.703
===> Total for class ihm: -0.529
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.446
TOTAL: -0.975
Train epoch 5: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.704
===> Total for class ihm: -0.530
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.688
===> Total for class sdm1: -0.443
TOTAL: -0.972
Train epoch 5: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.712
===> Total for class ihm: -0.538
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.126
===> adversarial_loss: -0.680
===> Total for class sdm1: -0.436
TOTAL: -0.974
Train epoch 5: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.708
===> Total for class ihm: -0.534
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.683
===> Total for class sdm1: -0.439
TOTAL: -0.973
Train epoch 5: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.086
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.705
===> Total for class ihm: -0.530
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.128
===> adversarial_loss: -0.686
===> Total for class sdm1: -0.438
TOTAL: -0.969
Train epoch 5: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.702
===> Total for class ihm: -0.527
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.128
===> adversarial_loss: -0.690
===> Total for class sdm1: -0.443
TOTAL: -0.970
Train epoch 5: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.086
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.701
===> Total for class ihm: -0.526
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.128
===> adversarial_loss: -0.690
===> Total for class sdm1: -0.443
TOTAL: -0.969
Train epoch 5: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.699
===> Total for class ihm: -0.524
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.128
===> adversarial_loss: -0.692
===> Total for class sdm1: -0.445
TOTAL: -0.969
Train epoch 5: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.695
===> Total for class ihm: -0.521
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.128
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.449
TOTAL: -0.970
Train epoch 5: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.689
===> Total for class ihm: -0.515
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.701
===> Total for class sdm1: -0.456
TOTAL: -0.970
Train epoch 5: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.691
===> Total for class ihm: -0.517
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.128
===> adversarial_loss: -0.700
===> Total for class sdm1: -0.453
TOTAL: -0.970
Train epoch 5: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.691
===> Total for class ihm: -0.516
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.700
===> Total for class sdm1: -0.454
TOTAL: -0.970
Train epoch 5: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.694
===> Total for class ihm: -0.519
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.451
TOTAL: -0.970
Train epoch 5: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.086
===> backtranslation_recon_loss: 0.090
===> adversarial_loss: -0.691
===> Total for class ihm: -0.516
=> Class sdm1
===> autoencoding_recon_loss: 0.119
===> backtranslation_recon_loss: 0.128
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.453
TOTAL: -0.969
Train epoch 5: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.692
===> Total for class ihm: -0.517
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.699
===> Total for class sdm1: -0.453
TOTAL: -0.970
Train epoch 5: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.693
===> Total for class ihm: -0.518
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.452
TOTAL: -0.970
Train epoch 5: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.693
===> Total for class ihm: -0.518
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.698
===> Total for class sdm1: -0.452
TOTAL: -0.970

EPOCH 5 TRAIN (7353.840s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.085
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.694
===> Total for class ihm: -0.520
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.127
===> adversarial_loss: -0.697
===> Total for class sdm1: -0.451
TOTAL: -0.971

EPOCH 5 DEV (209.314s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.086
===> backtranslation_recon_loss: 0.091
===> adversarial_loss: -0.674
===> Total for class ihm: -0.497
=> Class sdm1
===> autoencoding_recon_loss: 0.114
===> backtranslation_recon_loss: 0.124
===> adversarial_loss: -0.712
===> Total for class sdm1: -0.474
TOTAL: -0.972

New best dev set loss: -0.971698
Saved checkpoint for model

STARTING EPOCH 6
Train epoch 6: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.084
===> backtranslation_recon_loss: 0.090
===> adversarial_loss: -0.633
===> Total for class ihm: -0.459
=> Class sdm1
===> autoencoding_recon_loss: 0.118
===> backtranslation_recon_loss: 0.126
===> adversarial_loss: -0.761
===> Total for class sdm1: -0.518
TOTAL: -0.976
Train epoch 6: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.084
===> backtranslation_recon_loss: 0.089
===> adversarial_loss: -0.683
===> Total for class ihm: -0.510
=> Class sdm1
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.705
===> Total for class sdm1: -0.463
TOTAL: -0.973
Train epoch 6: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.687
===> Total for class ihm: -0.516
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.701
===> Total for class sdm1: -0.460
TOTAL: -0.976
Train epoch 6: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.087
===> adversarial_loss: -0.693
===> Total for class ihm: -0.523
=> Class sdm1
===> autoencoding_recon_loss: 0.115
===> backtranslation_recon_loss: 0.124
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.457
TOTAL: -0.980
Train epoch 6: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.694
===> Total for class ihm: -0.523
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.455
TOTAL: -0.979
Train epoch 6: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.697
===> Total for class ihm: -0.525
=> Class sdm1
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.126
===> adversarial_loss: -0.694
===> Total for class sdm1: -0.451
TOTAL: -0.977
Train epoch 6: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.700
===> Total for class ihm: -0.529
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.691
===> Total for class sdm1: -0.449
TOTAL: -0.978
Train epoch 6: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.698
===> Total for class ihm: -0.527
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.693
===> Total for class sdm1: -0.451
TOTAL: -0.977
Train epoch 6: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.703
===> Total for class ihm: -0.532
=> Class sdm1
===> autoencoding_recon_loss: 0.117
===> backtranslation_recon_loss: 0.126
===> adversarial_loss: -0.687
===> Total for class sdm1: -0.445
TOTAL: -0.977
Train epoch 6: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.701
===> Total for class ihm: -0.530
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.448
TOTAL: -0.978
Train epoch 6: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.702
===> Total for class ihm: -0.531
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.448
TOTAL: -0.978
Train epoch 6: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.699
===> Total for class ihm: -0.528
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.126
===> adversarial_loss: -0.691
===> Total for class sdm1: -0.450
TOTAL: -0.977
Train epoch 6: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.701
===> Total for class ihm: -0.529
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.690
===> Total for class sdm1: -0.449
TOTAL: -0.978
Train epoch 6: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.702
===> Total for class ihm: -0.531
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.689
===> Total for class sdm1: -0.448
TOTAL: -0.978
Train epoch 6: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.700
===> Total for class ihm: -0.529
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.690
===> Total for class sdm1: -0.449
TOTAL: -0.978
Train epoch 6: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.694
===> Total for class ihm: -0.523
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.696
===> Total for class sdm1: -0.455
TOTAL: -0.978
Train epoch 6: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.695
===> Total for class ihm: -0.524
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.454
TOTAL: -0.978
Train epoch 6: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.695
===> Total for class ihm: -0.524
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.454
TOTAL: -0.978

EPOCH 6 TRAIN (7366.029s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.088
===> adversarial_loss: -0.695
===> Total for class ihm: -0.525
=> Class sdm1
===> autoencoding_recon_loss: 0.116
===> backtranslation_recon_loss: 0.125
===> adversarial_loss: -0.695
===> Total for class sdm1: -0.454
TOTAL: -0.979

EPOCH 6 DEV (210.549s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.083
===> backtranslation_recon_loss: 0.090
===> adversarial_loss: -0.635
===> Total for class ihm: -0.462
=> Class sdm1
===> autoencoding_recon_loss: 0.111
===> backtranslation_recon_loss: 0.123
===> adversarial_loss: -0.754
===> Total for class sdm1: -0.520
TOTAL: -0.982

New best dev set loss: -0.982450
Saved checkpoint for model

STARTING EPOCH 7
Train epoch 7: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.080
===> backtranslation_recon_loss: 0.084
===> adversarial_loss: -0.678
===> Total for class ihm: -0.515
=> Class sdm1
===> autoencoding_recon_loss: 0.113
===> backtranslation_recon_loss: 0.122
===> adversarial_loss: -0.711
===> Total for class sdm1: -0.477
TOTAL: -0.991
Train epoch 7: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 0.081
===> backtranslation_recon_loss: 0.086
===> adversarial_loss: -0.680
===> Total for class ihm: -0.513
=> Class sdm1
===> autoencoding_recon_loss: 0.114
===> backtranslation_recon_loss: 0.124
===> adversarial_loss: -0.711
===> Total for class sdm1: -0.473
TOTAL: -0.987
