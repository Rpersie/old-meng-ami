Running training with mode ae
Noising 25.000% of input features
Constructing model...
Done constructing model.
CNNMultidecoder(
  (encoder_conv): Sequential(
    (conv2d_0): Conv2d (1, 256, kernel_size=(5, 5), stride=(1, 1))
    (ReLU_0): ReLU()
    (maxpool2d_0): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), dilation=(1, 1))
    (conv2d_1): Conv2d (256, 256, kernel_size=(5, 5), stride=(1, 1))
    (ReLU_1): ReLU()
    (maxpool2d_1): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), dilation=(1, 1))
  )
  (encoder_fc): Sequential(
    (lin_0): Linear(in_features=13056, out_features=1024)
    (ReLU_0): ReLU()
    (lin_final): Linear(in_features=1024, out_features=256)
    (ReLU_final): ReLU()
  )
  (decoder_fc_ihm): Sequential(
    (ReLU_0): ReLU()
    (lin_0): Linear(in_features=256, out_features=1024)
    (ReLU_final): ReLU()
    (lin_final): Linear(in_features=1024, out_features=13056)
  )
  (decoder_deconv_ihm): Sequential(
    (ReLU_0): ReLU()
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))
    (ReLU_1): ReLU()
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))
  )
  (decoder_fc_sdm1): Sequential(
    (ReLU_0): ReLU()
    (lin_0): Linear(in_features=256, out_features=1024)
    (ReLU_final): ReLU()
    (lin_final): Linear(in_features=1024, out_features=13056)
  )
  (decoder_deconv_sdm1): Sequential(
    (ReLU_0): ReLU()
    (maxunpool2d_0): MaxUnpool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0))
    (conv2d_0): Conv2d (256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))
    (ReLU_1): ReLU()
    (maxunpool2d_1): MaxUnpool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0))
    (conv2d_1): Conv2d (256, 1, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))
  )
)
Model has 45859330 trainable parameters
Setting up data...
Setting up training datasets...
Using 2407138 training features (9403 batches) for class ihm
Using 2407138 training features (9403 batches) for class sdm1
Setting up dev datasets...
Using 249565 dev features (975 batches) for class ihm
Using 249565 dev features (975 batches) for class sdm1
Setting up minibatch shuffling for training...
18806 total batches: {'ihm': 9403, 'sdm1': 9403}
Done setting up data.
Completed setup in 129.750 seconds
Starting training!

STARTING EPOCH 1
GENERATOR Train epoch 1: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 584.441
===> backtranslation_recon_loss: 593.864
===> Total for class ihm: 1178.305
=> Class sdm1
===> autoencoding_recon_loss: 526.306
===> backtranslation_recon_loss: 538.055
===> Total for class sdm1: 1064.361
TOTAL: 2242.667
GENERATOR Train epoch 1: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 519.280
===> backtranslation_recon_loss: 531.231
===> Total for class ihm: 1050.511
=> Class sdm1
===> autoencoding_recon_loss: 480.919
===> backtranslation_recon_loss: 499.109
===> Total for class sdm1: 980.028
TOTAL: 2030.539
GENERATOR Train epoch 1: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 457.138
===> backtranslation_recon_loss: 467.609
===> Total for class ihm: 924.747
=> Class sdm1
===> autoencoding_recon_loss: 424.186
===> backtranslation_recon_loss: 442.014
===> Total for class sdm1: 866.200
TOTAL: 1790.946
GENERATOR Train epoch 1: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 398.947
===> backtranslation_recon_loss: 410.471
===> Total for class ihm: 809.418
=> Class sdm1
===> autoencoding_recon_loss: 380.025
===> backtranslation_recon_loss: 396.818
===> Total for class sdm1: 776.843
TOTAL: 1586.261
GENERATOR Train epoch 1: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 347.626
===> backtranslation_recon_loss: 358.407
===> Total for class ihm: 706.032
=> Class sdm1
===> autoencoding_recon_loss: 342.438
===> backtranslation_recon_loss: 357.775
===> Total for class sdm1: 700.213
TOTAL: 1406.245
GENERATOR Train epoch 1: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 310.535
===> backtranslation_recon_loss: 319.085
===> Total for class ihm: 629.619
=> Class sdm1
===> autoencoding_recon_loss: 313.207
===> backtranslation_recon_loss: 326.335
===> Total for class sdm1: 639.542
TOTAL: 1269.161
GENERATOR Train epoch 1: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 282.453
===> backtranslation_recon_loss: 288.772
===> Total for class ihm: 571.226
=> Class sdm1
===> autoencoding_recon_loss: 290.055
===> backtranslation_recon_loss: 300.926
===> Total for class sdm1: 590.981
TOTAL: 1162.206
GENERATOR Train epoch 1: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 261.392
===> backtranslation_recon_loss: 265.848
===> Total for class ihm: 527.240
=> Class sdm1
===> autoencoding_recon_loss: 271.625
===> backtranslation_recon_loss: 280.443
===> Total for class sdm1: 552.068
TOTAL: 1079.308
GENERATOR Train epoch 1: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 243.784
===> backtranslation_recon_loss: 246.743
===> Total for class ihm: 490.527
=> Class sdm1
===> autoencoding_recon_loss: 257.201
===> backtranslation_recon_loss: 264.042
===> Total for class sdm1: 521.243
TOTAL: 1011.770
GENERATOR Train epoch 1: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 229.193
===> backtranslation_recon_loss: 231.019
===> Total for class ihm: 460.212
=> Class sdm1
===> autoencoding_recon_loss: 245.731
===> backtranslation_recon_loss: 250.993
===> Total for class sdm1: 496.724
TOTAL: 956.936
GENERATOR Train epoch 1: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 216.345
===> backtranslation_recon_loss: 216.727
===> Total for class ihm: 433.071
=> Class sdm1
===> autoencoding_recon_loss: 235.549
===> backtranslation_recon_loss: 239.183
===> Total for class sdm1: 474.732
TOTAL: 907.803
GENERATOR Train epoch 1: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 205.920
===> backtranslation_recon_loss: 205.173
===> Total for class ihm: 411.093
=> Class sdm1
===> autoencoding_recon_loss: 226.601
===> backtranslation_recon_loss: 228.810
===> Total for class sdm1: 455.411
TOTAL: 866.504
GENERATOR Train epoch 1: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 197.051
===> backtranslation_recon_loss: 195.321
===> Total for class ihm: 392.372
=> Class sdm1
===> autoencoding_recon_loss: 218.732
===> backtranslation_recon_loss: 219.656
===> Total for class sdm1: 438.387
TOTAL: 830.759
GENERATOR Train epoch 1: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 189.061
===> backtranslation_recon_loss: 186.407
===> Total for class ihm: 375.468
=> Class sdm1
===> autoencoding_recon_loss: 212.246
===> backtranslation_recon_loss: 211.989
===> Total for class sdm1: 424.236
TOTAL: 799.704
GENERATOR Train epoch 1: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 182.891
===> backtranslation_recon_loss: 179.741
===> Total for class ihm: 362.632
=> Class sdm1
===> autoencoding_recon_loss: 206.116
===> backtranslation_recon_loss: 205.070
===> Total for class sdm1: 411.186
TOTAL: 773.818
GENERATOR Train epoch 1: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 176.851
===> backtranslation_recon_loss: 173.040
===> Total for class ihm: 349.891
=> Class sdm1
===> autoencoding_recon_loss: 200.220
===> backtranslation_recon_loss: 198.268
===> Total for class sdm1: 398.487
TOTAL: 748.378
GENERATOR Train epoch 1: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 171.377
===> backtranslation_recon_loss: 167.081
===> Total for class ihm: 338.458
=> Class sdm1
===> autoencoding_recon_loss: 195.501
===> backtranslation_recon_loss: 192.890
===> Total for class sdm1: 388.392
TOTAL: 726.850
GENERATOR Train epoch 1: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 166.401
===> backtranslation_recon_loss: 161.700
===> Total for class ihm: 328.101
=> Class sdm1
===> autoencoding_recon_loss: 191.152
===> backtranslation_recon_loss: 187.971
===> Total for class sdm1: 379.123
TOTAL: 707.224

EPOCH 1 TRAIN (15445.462s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 162.837
===> backtranslation_recon_loss: 157.831
===> Total for class ihm: 320.668
=> Class sdm1
===> autoencoding_recon_loss: 187.859
===> backtranslation_recon_loss: 184.319
===> Total for class sdm1: 372.179
TOTAL: 692.846

EPOCH 1 DEV (335.024s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 89.579
===> backtranslation_recon_loss: 95.135
===> Total for class ihm: 184.714
=> Class sdm1
===> autoencoding_recon_loss: 122.057
===> backtranslation_recon_loss: 122.740
===> Total for class sdm1: 244.798
TOTAL: 429.511

New best dev set loss: 429.511387
Saved checkpoint for model

STARTING EPOCH 2
GENERATOR Train epoch 2: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 89.207
===> backtranslation_recon_loss: 83.678
===> Total for class ihm: 172.885
=> Class sdm1
===> autoencoding_recon_loss: 121.863
===> backtranslation_recon_loss: 117.254
===> Total for class sdm1: 239.117
TOTAL: 412.001
GENERATOR Train epoch 2: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 84.065
===> backtranslation_recon_loss: 74.941
===> Total for class ihm: 159.006
=> Class sdm1
===> autoencoding_recon_loss: 118.628
===> backtranslation_recon_loss: 110.434
===> Total for class sdm1: 229.062
TOTAL: 388.068
GENERATOR Train epoch 2: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 81.536
===> backtranslation_recon_loss: 71.484
===> Total for class ihm: 153.019
=> Class sdm1
===> autoencoding_recon_loss: 115.874
===> backtranslation_recon_loss: 106.736
===> Total for class sdm1: 222.610
TOTAL: 375.630
GENERATOR Train epoch 2: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 80.237
===> backtranslation_recon_loss: 69.704
===> Total for class ihm: 149.941
=> Class sdm1
===> autoencoding_recon_loss: 114.809
===> backtranslation_recon_loss: 105.086
===> Total for class sdm1: 219.894
TOTAL: 369.835
GENERATOR Train epoch 2: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 79.328
===> backtranslation_recon_loss: 68.947
===> Total for class ihm: 148.276
=> Class sdm1
===> autoencoding_recon_loss: 114.237
===> backtranslation_recon_loss: 104.348
===> Total for class sdm1: 218.585
TOTAL: 366.861
GENERATOR Train epoch 2: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 78.187
===> backtranslation_recon_loss: 67.618
===> Total for class ihm: 145.805
=> Class sdm1
===> autoencoding_recon_loss: 113.241
===> backtranslation_recon_loss: 103.131
===> Total for class sdm1: 216.372
TOTAL: 362.177
GENERATOR Train epoch 2: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 77.397
===> backtranslation_recon_loss: 66.811
===> Total for class ihm: 144.208
=> Class sdm1
===> autoencoding_recon_loss: 112.543
===> backtranslation_recon_loss: 102.540
===> Total for class sdm1: 215.083
TOTAL: 359.291
GENERATOR Train epoch 2: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 76.778
===> backtranslation_recon_loss: 66.184
===> Total for class ihm: 142.962
=> Class sdm1
===> autoencoding_recon_loss: 112.012
===> backtranslation_recon_loss: 102.147
===> Total for class sdm1: 214.159
TOTAL: 357.121
GENERATOR Train epoch 2: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 76.432
===> backtranslation_recon_loss: 66.133
===> Total for class ihm: 142.566
=> Class sdm1
===> autoencoding_recon_loss: 111.822
===> backtranslation_recon_loss: 102.219
===> Total for class sdm1: 214.040
TOTAL: 356.606
GENERATOR Train epoch 2: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 75.819
===> backtranslation_recon_loss: 65.531
===> Total for class ihm: 141.350
=> Class sdm1
===> autoencoding_recon_loss: 111.147
===> backtranslation_recon_loss: 101.529
===> Total for class sdm1: 212.676
TOTAL: 354.026
GENERATOR Train epoch 2: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 75.442
===> backtranslation_recon_loss: 65.296
===> Total for class ihm: 140.738
=> Class sdm1
===> autoencoding_recon_loss: 110.843
===> backtranslation_recon_loss: 101.457
===> Total for class sdm1: 212.300
TOTAL: 353.038
GENERATOR Train epoch 2: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 75.158
===> backtranslation_recon_loss: 65.167
===> Total for class ihm: 140.324
=> Class sdm1
===> autoencoding_recon_loss: 110.469
===> backtranslation_recon_loss: 101.340
===> Total for class sdm1: 211.810
TOTAL: 352.134
GENERATOR Train epoch 2: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 77.298
===> backtranslation_recon_loss: 68.181
===> Total for class ihm: 145.479
=> Class sdm1
===> autoencoding_recon_loss: 111.598
===> backtranslation_recon_loss: 104.156
===> Total for class sdm1: 215.754
TOTAL: 361.233
GENERATOR Train epoch 2: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 77.041
===> backtranslation_recon_loss: 67.977
===> Total for class ihm: 145.017
=> Class sdm1
===> autoencoding_recon_loss: 111.338
===> backtranslation_recon_loss: 104.155
===> Total for class sdm1: 215.492
TOTAL: 360.510
GENERATOR Train epoch 2: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 76.514
===> backtranslation_recon_loss: 67.405
===> Total for class ihm: 143.918
=> Class sdm1
===> autoencoding_recon_loss: 110.868
===> backtranslation_recon_loss: 103.752
===> Total for class sdm1: 214.620
TOTAL: 358.538
GENERATOR Train epoch 2: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 76.232
===> backtranslation_recon_loss: 67.199
===> Total for class ihm: 143.431
=> Class sdm1
===> autoencoding_recon_loss: 110.614
===> backtranslation_recon_loss: 103.691
===> Total for class sdm1: 214.305
TOTAL: 357.736
GENERATOR Train epoch 2: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 75.769
===> backtranslation_recon_loss: 66.713
===> Total for class ihm: 142.482
=> Class sdm1
===> autoencoding_recon_loss: 110.171
===> backtranslation_recon_loss: 103.299
===> Total for class sdm1: 213.470
TOTAL: 355.952
GENERATOR Train epoch 2: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 75.315
===> backtranslation_recon_loss: 66.227
===> Total for class ihm: 141.542
=> Class sdm1
===> autoencoding_recon_loss: 109.776
===> backtranslation_recon_loss: 102.888
===> Total for class sdm1: 212.664
TOTAL: 354.206

EPOCH 2 TRAIN (15462.615s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 75.071
===> backtranslation_recon_loss: 65.993
===> Total for class ihm: 141.065
=> Class sdm1
===> autoencoding_recon_loss: 109.509
===> backtranslation_recon_loss: 102.665
===> Total for class sdm1: 212.174
TOTAL: 353.238

EPOCH 2 DEV (334.028s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 90.109
===> backtranslation_recon_loss: 91.579
===> Total for class ihm: 181.688
=> Class sdm1
===> autoencoding_recon_loss: 125.679
===> backtranslation_recon_loss: 118.390
===> Total for class sdm1: 244.068
TOTAL: 425.756

New best dev set loss: 425.756300
Saved checkpoint for model

STARTING EPOCH 3
GENERATOR Train epoch 3: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 67.232
===> backtranslation_recon_loss: 58.660
===> Total for class ihm: 125.892
=> Class sdm1
===> autoencoding_recon_loss: 99.782
===> backtranslation_recon_loss: 95.154
===> Total for class sdm1: 194.935
TOTAL: 320.828
GENERATOR Train epoch 3: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 68.146
===> backtranslation_recon_loss: 59.684
===> Total for class ihm: 127.829
=> Class sdm1
===> autoencoding_recon_loss: 101.658
===> backtranslation_recon_loss: 96.084
===> Total for class sdm1: 197.742
TOTAL: 325.571
GENERATOR Train epoch 3: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 67.759
===> backtranslation_recon_loss: 59.161
===> Total for class ihm: 126.919
=> Class sdm1
===> autoencoding_recon_loss: 100.713
===> backtranslation_recon_loss: 95.158
===> Total for class sdm1: 195.871
TOTAL: 322.790
GENERATOR Train epoch 3: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 67.714
===> backtranslation_recon_loss: 59.055
===> Total for class ihm: 126.769
=> Class sdm1
===> autoencoding_recon_loss: 100.935
===> backtranslation_recon_loss: 95.418
===> Total for class sdm1: 196.353
TOTAL: 323.122
GENERATOR Train epoch 3: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 67.213
===> backtranslation_recon_loss: 58.397
===> Total for class ihm: 125.609
=> Class sdm1
===> autoencoding_recon_loss: 100.649
===> backtranslation_recon_loss: 94.915
===> Total for class sdm1: 195.564
TOTAL: 321.173
GENERATOR Train epoch 3: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 66.949
===> backtranslation_recon_loss: 58.188
===> Total for class ihm: 125.137
=> Class sdm1
===> autoencoding_recon_loss: 100.482
===> backtranslation_recon_loss: 94.622
===> Total for class sdm1: 195.104
TOTAL: 320.241
GENERATOR Train epoch 3: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 66.646
===> backtranslation_recon_loss: 57.953
===> Total for class ihm: 124.599
=> Class sdm1
===> autoencoding_recon_loss: 100.311
===> backtranslation_recon_loss: 94.605
===> Total for class sdm1: 194.916
TOTAL: 319.515
GENERATOR Train epoch 3: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 66.488
===> backtranslation_recon_loss: 57.928
===> Total for class ihm: 124.417
=> Class sdm1
===> autoencoding_recon_loss: 100.313
===> backtranslation_recon_loss: 94.590
===> Total for class sdm1: 194.902
TOTAL: 319.319
GENERATOR Train epoch 3: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 66.337
===> backtranslation_recon_loss: 57.855
===> Total for class ihm: 124.192
=> Class sdm1
===> autoencoding_recon_loss: 100.300
===> backtranslation_recon_loss: 94.596
===> Total for class sdm1: 194.897
TOTAL: 319.089
GENERATOR Train epoch 3: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.974
===> backtranslation_recon_loss: 57.444
===> Total for class ihm: 123.418
=> Class sdm1
===> autoencoding_recon_loss: 99.939
===> backtranslation_recon_loss: 94.053
===> Total for class sdm1: 193.992
TOTAL: 317.410
GENERATOR Train epoch 3: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.628
===> backtranslation_recon_loss: 57.042
===> Total for class ihm: 122.670
=> Class sdm1
===> autoencoding_recon_loss: 99.577
===> backtranslation_recon_loss: 93.536
===> Total for class sdm1: 193.113
TOTAL: 315.783
GENERATOR Train epoch 3: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.421
===> backtranslation_recon_loss: 56.842
===> Total for class ihm: 122.263
=> Class sdm1
===> autoencoding_recon_loss: 99.294
===> backtranslation_recon_loss: 93.147
===> Total for class sdm1: 192.441
TOTAL: 314.704
GENERATOR Train epoch 3: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.485
===> backtranslation_recon_loss: 57.101
===> Total for class ihm: 122.586
=> Class sdm1
===> autoencoding_recon_loss: 99.507
===> backtranslation_recon_loss: 93.411
===> Total for class sdm1: 192.918
TOTAL: 315.503
GENERATOR Train epoch 3: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.486
===> backtranslation_recon_loss: 57.203
===> Total for class ihm: 122.690
=> Class sdm1
===> autoencoding_recon_loss: 99.514
===> backtranslation_recon_loss: 93.461
===> Total for class sdm1: 192.975
TOTAL: 315.665
GENERATOR Train epoch 3: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.198
===> backtranslation_recon_loss: 56.891
===> Total for class ihm: 122.088
=> Class sdm1
===> autoencoding_recon_loss: 99.258
===> backtranslation_recon_loss: 93.156
===> Total for class sdm1: 192.414
TOTAL: 314.502
GENERATOR Train epoch 3: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 65.082
===> backtranslation_recon_loss: 56.824
===> Total for class ihm: 121.906
=> Class sdm1
===> autoencoding_recon_loss: 99.028
===> backtranslation_recon_loss: 92.865
===> Total for class sdm1: 191.894
TOTAL: 313.800
GENERATOR Train epoch 3: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 64.999
===> backtranslation_recon_loss: 56.823
===> Total for class ihm: 121.821
=> Class sdm1
===> autoencoding_recon_loss: 99.127
===> backtranslation_recon_loss: 92.922
===> Total for class sdm1: 192.049
TOTAL: 313.870
GENERATOR Train epoch 3: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 64.741
===> backtranslation_recon_loss: 56.548
===> Total for class ihm: 121.289
=> Class sdm1
===> autoencoding_recon_loss: 98.904
===> backtranslation_recon_loss: 92.609
===> Total for class sdm1: 191.513
TOTAL: 312.802

EPOCH 3 TRAIN (15464.504s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 64.613
===> backtranslation_recon_loss: 56.432
===> Total for class ihm: 121.045
=> Class sdm1
===> autoencoding_recon_loss: 98.782
===> backtranslation_recon_loss: 92.489
===> Total for class sdm1: 191.271
TOTAL: 312.316

EPOCH 3 DEV (336.628s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 82.769
===> backtranslation_recon_loss: 88.912
===> Total for class ihm: 171.681
=> Class sdm1
===> autoencoding_recon_loss: 95.834
===> backtranslation_recon_loss: 114.259
===> Total for class sdm1: 210.093
TOTAL: 381.774

New best dev set loss: 381.774214
Saved checkpoint for model

STARTING EPOCH 4
GENERATOR Train epoch 4: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 63.321
===> backtranslation_recon_loss: 56.088
===> Total for class ihm: 119.409
=> Class sdm1
===> autoencoding_recon_loss: 95.130
===> backtranslation_recon_loss: 88.945
===> Total for class sdm1: 184.074
TOTAL: 303.483
GENERATOR Train epoch 4: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 62.710
===> backtranslation_recon_loss: 54.524
===> Total for class ihm: 117.234
=> Class sdm1
===> autoencoding_recon_loss: 95.894
===> backtranslation_recon_loss: 88.884
===> Total for class sdm1: 184.778
TOTAL: 302.012
GENERATOR Train epoch 4: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.493
===> backtranslation_recon_loss: 53.081
===> Total for class ihm: 114.574
=> Class sdm1
===> autoencoding_recon_loss: 94.429
===> backtranslation_recon_loss: 87.367
===> Total for class sdm1: 181.796
TOTAL: 296.370
GENERATOR Train epoch 4: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.599
===> backtranslation_recon_loss: 53.278
===> Total for class ihm: 114.877
=> Class sdm1
===> autoencoding_recon_loss: 94.868
===> backtranslation_recon_loss: 88.163
===> Total for class sdm1: 183.032
TOTAL: 297.908
GENERATOR Train epoch 4: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 61.172
===> backtranslation_recon_loss: 52.885
===> Total for class ihm: 114.057
=> Class sdm1
===> autoencoding_recon_loss: 94.648
===> backtranslation_recon_loss: 88.004
===> Total for class sdm1: 182.652
TOTAL: 296.709
GENERATOR Train epoch 4: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.737
===> backtranslation_recon_loss: 52.410
===> Total for class ihm: 113.146
=> Class sdm1
===> autoencoding_recon_loss: 94.227
===> backtranslation_recon_loss: 87.447
===> Total for class sdm1: 181.674
TOTAL: 294.820
GENERATOR Train epoch 4: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.511
===> backtranslation_recon_loss: 52.182
===> Total for class ihm: 112.693
=> Class sdm1
===> autoencoding_recon_loss: 94.004
===> backtranslation_recon_loss: 87.203
===> Total for class sdm1: 181.207
TOTAL: 293.900
GENERATOR Train epoch 4: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.226
===> backtranslation_recon_loss: 51.853
===> Total for class ihm: 112.079
=> Class sdm1
===> autoencoding_recon_loss: 93.913
===> backtranslation_recon_loss: 87.062
===> Total for class sdm1: 180.974
TOTAL: 293.053
GENERATOR Train epoch 4: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 60.247
===> backtranslation_recon_loss: 51.978
===> Total for class ihm: 112.225
=> Class sdm1
===> autoencoding_recon_loss: 93.985
===> backtranslation_recon_loss: 87.308
===> Total for class sdm1: 181.294
TOTAL: 293.519
GENERATOR Train epoch 4: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.996
===> backtranslation_recon_loss: 51.679
===> Total for class ihm: 111.675
=> Class sdm1
===> autoencoding_recon_loss: 93.662
===> backtranslation_recon_loss: 86.865
===> Total for class sdm1: 180.527
TOTAL: 292.202
GENERATOR Train epoch 4: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.787
===> backtranslation_recon_loss: 51.491
===> Total for class ihm: 111.278
=> Class sdm1
===> autoencoding_recon_loss: 93.442
===> backtranslation_recon_loss: 86.675
===> Total for class sdm1: 180.117
TOTAL: 291.395
GENERATOR Train epoch 4: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.675
===> backtranslation_recon_loss: 51.377
===> Total for class ihm: 111.052
=> Class sdm1
===> autoencoding_recon_loss: 93.259
===> backtranslation_recon_loss: 86.469
===> Total for class sdm1: 179.728
TOTAL: 290.780
GENERATOR Train epoch 4: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.679
===> backtranslation_recon_loss: 51.467
===> Total for class ihm: 111.147
=> Class sdm1
===> autoencoding_recon_loss: 93.227
===> backtranslation_recon_loss: 86.491
===> Total for class sdm1: 179.718
TOTAL: 290.864
GENERATOR Train epoch 4: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.584
===> backtranslation_recon_loss: 51.373
===> Total for class ihm: 110.957
=> Class sdm1
===> autoencoding_recon_loss: 93.144
===> backtranslation_recon_loss: 86.416
===> Total for class sdm1: 179.561
TOTAL: 290.518
GENERATOR Train epoch 4: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.538
===> backtranslation_recon_loss: 51.332
===> Total for class ihm: 110.869
=> Class sdm1
===> autoencoding_recon_loss: 93.027
===> backtranslation_recon_loss: 86.334
===> Total for class sdm1: 179.361
TOTAL: 290.230
GENERATOR Train epoch 4: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.503
===> backtranslation_recon_loss: 51.305
===> Total for class ihm: 110.808
=> Class sdm1
===> autoencoding_recon_loss: 92.836
===> backtranslation_recon_loss: 86.163
===> Total for class sdm1: 178.999
TOTAL: 289.807
GENERATOR Train epoch 4: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.379
===> backtranslation_recon_loss: 51.198
===> Total for class ihm: 110.577
=> Class sdm1
===> autoencoding_recon_loss: 92.727
===> backtranslation_recon_loss: 86.079
===> Total for class sdm1: 178.806
TOTAL: 289.383
GENERATOR Train epoch 4: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.242
===> backtranslation_recon_loss: 51.070
===> Total for class ihm: 110.312
=> Class sdm1
===> autoencoding_recon_loss: 92.645
===> backtranslation_recon_loss: 85.960
===> Total for class sdm1: 178.605
TOTAL: 288.916

EPOCH 4 TRAIN (15464.577s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.061
===> backtranslation_recon_loss: 50.874
===> Total for class ihm: 109.935
=> Class sdm1
===> autoencoding_recon_loss: 92.487
===> backtranslation_recon_loss: 85.764
===> Total for class sdm1: 178.251
TOTAL: 288.186

EPOCH 4 DEV (337.519s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 67.971
===> backtranslation_recon_loss: 54.594
===> Total for class ihm: 122.565
=> Class sdm1
===> autoencoding_recon_loss: 89.397
===> backtranslation_recon_loss: 84.407
===> Total for class sdm1: 173.804
TOTAL: 296.370

New best dev set loss: 296.369575
Saved checkpoint for model

STARTING EPOCH 5
GENERATOR Train epoch 5: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 57.819
===> backtranslation_recon_loss: 50.886
===> Total for class ihm: 108.705
=> Class sdm1
===> autoencoding_recon_loss: 90.072
===> backtranslation_recon_loss: 83.228
===> Total for class sdm1: 173.300
TOTAL: 282.005
GENERATOR Train epoch 5: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 57.260
===> backtranslation_recon_loss: 49.370
===> Total for class ihm: 106.630
=> Class sdm1
===> autoencoding_recon_loss: 89.758
===> backtranslation_recon_loss: 82.447
===> Total for class sdm1: 172.205
TOTAL: 278.835
GENERATOR Train epoch 5: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 57.438
===> backtranslation_recon_loss: 49.716
===> Total for class ihm: 107.154
=> Class sdm1
===> autoencoding_recon_loss: 89.050
===> backtranslation_recon_loss: 82.131
===> Total for class sdm1: 171.181
TOTAL: 278.335
GENERATOR Train epoch 5: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 57.078
===> backtranslation_recon_loss: 49.107
===> Total for class ihm: 106.185
=> Class sdm1
===> autoencoding_recon_loss: 89.036
===> backtranslation_recon_loss: 82.191
===> Total for class sdm1: 171.227
TOTAL: 277.412
GENERATOR Train epoch 5: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 56.953
===> backtranslation_recon_loss: 48.971
===> Total for class ihm: 105.924
=> Class sdm1
===> autoencoding_recon_loss: 89.298
===> backtranslation_recon_loss: 82.702
===> Total for class sdm1: 172.000
TOTAL: 277.924
GENERATOR Train epoch 5: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 56.746
===> backtranslation_recon_loss: 48.660
===> Total for class ihm: 105.406
=> Class sdm1
===> autoencoding_recon_loss: 88.991
===> backtranslation_recon_loss: 82.321
===> Total for class sdm1: 171.312
TOTAL: 276.717
GENERATOR Train epoch 5: [7000/18806 (37.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 56.446
===> backtranslation_recon_loss: 48.404
===> Total for class ihm: 104.851
=> Class sdm1
===> autoencoding_recon_loss: 88.671
===> backtranslation_recon_loss: 82.041
===> Total for class sdm1: 170.712
TOTAL: 275.562
GENERATOR Train epoch 5: [8000/18806 (42.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 56.356
===> backtranslation_recon_loss: 48.312
===> Total for class ihm: 104.668
=> Class sdm1
===> autoencoding_recon_loss: 88.616
===> backtranslation_recon_loss: 82.058
===> Total for class sdm1: 170.674
TOTAL: 275.342
GENERATOR Train epoch 5: [9000/18806 (47.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 56.154
===> backtranslation_recon_loss: 48.120
===> Total for class ihm: 104.274
=> Class sdm1
===> autoencoding_recon_loss: 88.552
===> backtranslation_recon_loss: 82.061
===> Total for class sdm1: 170.613
TOTAL: 274.887
GENERATOR Train epoch 5: [10000/18806 (53.2%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.956
===> backtranslation_recon_loss: 47.948
===> Total for class ihm: 103.904
=> Class sdm1
===> autoencoding_recon_loss: 88.327
===> backtranslation_recon_loss: 81.767
===> Total for class sdm1: 170.094
TOTAL: 273.998
GENERATOR Train epoch 5: [11000/18806 (58.5%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.725
===> backtranslation_recon_loss: 47.667
===> Total for class ihm: 103.392
=> Class sdm1
===> autoencoding_recon_loss: 88.102
===> backtranslation_recon_loss: 81.485
===> Total for class sdm1: 169.587
TOTAL: 272.979
GENERATOR Train epoch 5: [12000/18806 (63.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.664
===> backtranslation_recon_loss: 47.597
===> Total for class ihm: 103.261
=> Class sdm1
===> autoencoding_recon_loss: 87.887
===> backtranslation_recon_loss: 81.234
===> Total for class sdm1: 169.122
TOTAL: 272.383
GENERATOR Train epoch 5: [13000/18806 (69.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.731
===> backtranslation_recon_loss: 47.748
===> Total for class ihm: 103.480
=> Class sdm1
===> autoencoding_recon_loss: 87.858
===> backtranslation_recon_loss: 81.314
===> Total for class sdm1: 169.173
TOTAL: 272.652
GENERATOR Train epoch 5: [14000/18806 (74.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.741
===> backtranslation_recon_loss: 47.775
===> Total for class ihm: 103.516
=> Class sdm1
===> autoencoding_recon_loss: 87.834
===> backtranslation_recon_loss: 81.317
===> Total for class sdm1: 169.151
TOTAL: 272.667
GENERATOR Train epoch 5: [15000/18806 (79.8%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.539
===> backtranslation_recon_loss: 47.542
===> Total for class ihm: 103.081
=> Class sdm1
===> autoencoding_recon_loss: 87.612
===> backtranslation_recon_loss: 81.014
===> Total for class sdm1: 168.626
TOTAL: 271.707
GENERATOR Train epoch 5: [16000/18806 (85.1%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.415
===> backtranslation_recon_loss: 47.393
===> Total for class ihm: 102.808
=> Class sdm1
===> autoencoding_recon_loss: 87.361
===> backtranslation_recon_loss: 80.669
===> Total for class sdm1: 168.030
TOTAL: 270.838
GENERATOR Train epoch 5: [17000/18806 (90.4%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.503
===> backtranslation_recon_loss: 47.526
===> Total for class ihm: 103.029
=> Class sdm1
===> autoencoding_recon_loss: 87.404
===> backtranslation_recon_loss: 80.763
===> Total for class sdm1: 168.167
TOTAL: 271.196
GENERATOR Train epoch 5: [18000/18806 (95.7%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.413
===> backtranslation_recon_loss: 47.454
===> Total for class ihm: 102.867
=> Class sdm1
===> autoencoding_recon_loss: 87.346
===> backtranslation_recon_loss: 80.682
===> Total for class sdm1: 168.028
TOTAL: 270.895

EPOCH 5 TRAIN (15464.344s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 55.281
===> backtranslation_recon_loss: 47.298
===> Total for class ihm: 102.579
=> Class sdm1
===> autoencoding_recon_loss: 87.239
===> backtranslation_recon_loss: 80.528
===> Total for class sdm1: 167.767
TOTAL: 270.346

EPOCH 5 DEV (336.711s)
Losses:
=> Class ihm
===> autoencoding_recon_loss: 59.888
===> backtranslation_recon_loss: 48.806
===> Total for class ihm: 108.694
=> Class sdm1
===> autoencoding_recon_loss: 86.505
===> backtranslation_recon_loss: 77.370
===> Total for class sdm1: 163.875
TOTAL: 272.569

New best dev set loss: 272.569421
Saved checkpoint for model

STARTING EPOCH 6
GENERATOR Train epoch 6: [1000/18806 (5.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 52.455
===> backtranslation_recon_loss: 44.251
===> Total for class ihm: 96.707
=> Class sdm1
===> autoencoding_recon_loss: 83.229
===> backtranslation_recon_loss: 76.358
===> Total for class sdm1: 159.587
TOTAL: 256.294
GENERATOR Train epoch 6: [2000/18806 (10.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 53.319
===> backtranslation_recon_loss: 45.163
===> Total for class ihm: 98.482
=> Class sdm1
===> autoencoding_recon_loss: 85.547
===> backtranslation_recon_loss: 78.588
===> Total for class sdm1: 164.135
TOTAL: 262.617
GENERATOR Train epoch 6: [3000/18806 (16.0%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 54.001
===> backtranslation_recon_loss: 46.133
===> Total for class ihm: 100.134
=> Class sdm1
===> autoencoding_recon_loss: 84.937
===> backtranslation_recon_loss: 78.157
===> Total for class sdm1: 163.094
TOTAL: 263.228
GENERATOR Train epoch 6: [4000/18806 (21.3%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 53.598
===> backtranslation_recon_loss: 45.612
===> Total for class ihm: 99.210
=> Class sdm1
===> autoencoding_recon_loss: 84.763
===> backtranslation_recon_loss: 77.989
===> Total for class sdm1: 162.752
TOTAL: 261.962
GENERATOR Train epoch 6: [5000/18806 (26.6%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 53.647
===> backtranslation_recon_loss: 45.759
===> Total for class ihm: 99.406
=> Class sdm1
===> autoencoding_recon_loss: 84.753
===> backtranslation_recon_loss: 78.034
===> Total for class sdm1: 162.787
TOTAL: 262.193
GENERATOR Train epoch 6: [6000/18806 (31.9%)]
Losses:
=> Class ihm
===> autoencoding_recon_loss: 53.499
===> backtranslation_recon_loss: 45.580
===> Total for class ihm: 99.078
=> Class sdm1
===> autoencoding_recon_loss: 84.513
===> backtranslation_recon_loss: 77.733
===> Total for class sdm1: 162.246
TOTAL: 261.324
